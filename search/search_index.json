{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Photoelastimetry Documentation","text":"<p>Photoelastimetry processes polarimetric images into stress fields and generates synthetic photoelastic images from stress fields.</p> <p>Use this site by audience:</p> <ul> <li>Users: task-first guides for CLI workflows, JSON5 configs, and troubleshooting.</li> <li>Developers: setup, tests, architecture, contribution workflow, and docs/release maintenance.</li> <li>Reference: auto-generated API docs for package modules.</li> </ul>"},{"location":"#start-here","title":"Start Here","text":"<ul> <li>New user: Installation -&gt; Quickstart</li> <li>Existing user: Workflow guides</li> <li>Contributor: Developer overview</li> <li>API lookup: Reference index</li> </ul>"},{"location":"#command-line-tools","title":"Command-Line Tools","text":"<ul> <li><code>image-to-stress</code>: invert photoelastic images to stress map</li> <li><code>stress-to-image</code>: forward-simulate photoelastic images from stress map</li> <li><code>demosaic-raw</code>: convert Bayer+polarisation raw files into channel stacks</li> <li><code>calibrate-photoelastimetry</code>: fit calibration profile from known-load data</li> </ul> <p>For exact config keys and aliases, use the canonical Configuration Reference.</p>"},{"location":"contributing/","title":"This Page Moved","text":"<p>Contributing guidance is now maintained in:</p> <ul> <li>Developer Contributing</li> </ul>"},{"location":"examples/","title":"This Page Moved","text":"<p>Examples are now embedded in each canonical workflow page:</p> <ul> <li>image-to-stress workflow</li> <li>stress-to-image workflow</li> <li>demosaic-raw workflow</li> <li>calibration workflow</li> </ul>"},{"location":"getting-started/","title":"This Page Moved","text":"<p>Getting started content now lives in:</p> <ul> <li>User Quickstart</li> <li>User Installation</li> </ul>"},{"location":"testing/","title":"This Page Moved","text":"<p>Testing documentation is now in the developer area:</p> <ul> <li>Developer Testing</li> </ul>"},{"location":"user-guide/","title":"This Page Moved","text":"<p>The user guide was split into canonical task-first pages:</p> <ul> <li>User Overview</li> <li>Workflow: image-to-stress</li> <li>Workflow: stress-to-image</li> <li>Workflow: demosaic-raw</li> <li>Workflow: calibration</li> <li>Configuration Reference</li> </ul>"},{"location":"developer/","title":"Developer Documentation","text":"<p>This area is for contributors and maintainers.</p>"},{"location":"developer/#start-here","title":"Start Here","text":"<ul> <li>Setup: local environment for development, tests, and docs</li> <li>Testing: pytest commands, coverage gate, and smoke tests</li> <li>Architecture: pipeline and data flow through core modules</li> <li>Module Map: where features live</li> <li>Contributing: PR workflow and expectations</li> <li>Release and Docs: versioning and docs publishing checklist</li> </ul>"},{"location":"developer/architecture/","title":"Architecture","text":""},{"location":"developer/architecture/#high-level-pipelines","title":"High-Level Pipelines","text":"<pre><code>flowchart TD\n    A[\"Raw or stacked image data\"] --&gt; B[\"IO loading and optional preprocessing\"]\n    B --&gt; C[\"Stokes extraction and seeding\"]\n    C --&gt; D[\"Mean-stress recovery optimise solver\"]\n    D --&gt; E[\"Stress map output\"]\n\n    F[\"Stress map input\"] --&gt; G[\"Forward model via Mueller simulation\"]\n    G --&gt; H[\"Synthetic image stack or plot output\"]\n\n    I[\"Known-load calibration images\"] --&gt; J[\"Calibration dataset builder\"]\n    J --&gt; K[\"Least-squares fit for C and S_i_hat\"]\n    K --&gt; L[\"Calibration profile + diagnostics\"]\n</code></pre>"},{"location":"developer/architecture/#main-runtime-paths","title":"Main Runtime Paths","text":"<ul> <li><code>image-to-stress</code> (<code>photoelastimetry.main:image_to_stress</code>)</li> <li>load image stack (<code>io</code>)</li> <li>apply optional calibration blank correction (<code>calibrate</code>)</li> <li>run phase-decomposed seeding (<code>seeding</code>)</li> <li>recover mean stress (<code>optimise</code>)</li> <li>save <code>[H, W, 3]</code> stress map (<code>io</code>)</li> <li><code>stress-to-image</code> (<code>photoelastimetry.main:stress_to_image</code>)</li> <li>load stress map (<code>io</code>)</li> <li>parse aliases / fallback params</li> <li>simulate multi-wavelength polarimetry (<code>image</code>)</li> <li>save stack or plot (<code>io</code>, <code>plotting</code>)</li> <li><code>calibrate-photoelastimetry</code> (<code>photoelastimetry.main:cli_calibrate</code>)</li> <li>validate config + build dataset (<code>calibrate</code>)</li> <li>robust least-squares fit (<code>scipy.optimize.least_squares</code>)</li> <li>write profile/report/diagnostics</li> </ul>"},{"location":"developer/architecture/#data-shapes","title":"Data Shapes","text":"<ul> <li>Stress map: <code>[H, W, 3]</code></li> <li>Polarimetric image stack: <code>[H, W, n_wavelengths, 4]</code></li> <li>Demosaiced raw output path in <code>main.py</code>: TIFF exported as <code>TCYX</code> for compatibility</li> </ul>"},{"location":"developer/architecture/#key-design-decisions","title":"Key Design Decisions","text":"<ul> <li>Inversion path uses one solver route: optimise mean-stress recovery.</li> <li>Calibration profile can backfill inversion/forward-model optical parameters.</li> <li>Legacy aliases are still accepted where explicitly implemented in <code>main.py</code>.</li> </ul>"},{"location":"developer/contributing/","title":"Contributing","text":""},{"location":"developer/contributing/#workflow","title":"Workflow","text":"<ol> <li>Create a feature branch.</li> <li>Make scoped changes with tests.</li> <li>Run formatters/tests locally.</li> <li>Open a PR with a clear summary and validation notes.</li> </ol>"},{"location":"developer/contributing/#recommended-local-checks","title":"Recommended Local Checks","text":"<pre><code>black photoelastimetry tests\npytest\nmkdocs build --strict\n</code></pre>"},{"location":"developer/contributing/#pr-expectations","title":"PR Expectations","text":"<ul> <li>Explain what changed and why.</li> <li>Include test evidence (command + result summary).</li> <li>Update docs for behavior/config/interface changes.</li> <li>Keep changes focused; avoid unrelated refactors in the same PR.</li> </ul>"},{"location":"developer/contributing/#areas-to-treat-carefully","title":"Areas to Treat Carefully","text":"<ul> <li>Parameter alias/precedence behavior in <code>main.py</code></li> <li>Data shape conventions across IO, calibration, seeding, and solver modules</li> <li>Legacy compatibility keys that are still intentionally supported</li> </ul>"},{"location":"developer/module-map/","title":"Module Map","text":""},{"location":"developer/module-map/#cli-and-orchestration","title":"CLI and Orchestration","text":"<ul> <li><code>photoelastimetry/main.py</code></li> <li>CLI entry points</li> <li>parameter merging and alias handling</li> <li>workflow orchestration</li> </ul>"},{"location":"developer/module-map/#core-numerical-and-physics-modules","title":"Core Numerical and Physics Modules","text":"<ul> <li><code>photoelastimetry/image.py</code></li> <li>Mueller matrix operations</li> <li>Stokes processing</li> <li>forward simulation helpers</li> <li><code>photoelastimetry/seeding.py</code></li> <li>phase-decomposed seeding</li> <li>fringe-order resolution</li> <li><code>photoelastimetry/optimise.py</code></li> <li>pressure/mean-stress recovery</li> <li><code>photoelastimetry/bspline.py</code></li> <li>spline basis and projection utilities</li> <li><code>photoelastimetry/unwrapping.py</code></li> <li>graph-cut angle unwrapping</li> </ul>"},{"location":"developer/module-map/#data-io-and-visualization","title":"Data IO and Visualization","text":"<ul> <li><code>photoelastimetry/io.py</code></li> <li>raw/image load/save</li> <li>Bayer pixel-format support</li> <li>channel split and binning</li> <li><code>photoelastimetry/plotting.py</code></li> <li>plotting and visualization helpers</li> <li><code>photoelastimetry/visualisation.py</code></li> <li>boundary condition ASCII visualization</li> </ul>"},{"location":"developer/module-map/#calibration","title":"Calibration","text":"<ul> <li><code>photoelastimetry/calibrate.py</code></li> <li>calibration config validation</li> <li>blank correction</li> <li>fitting and output generation</li> </ul>"},{"location":"developer/module-map/#synthetic-generators","title":"Synthetic Generators","text":"<ul> <li><code>photoelastimetry/generate/disk.py</code></li> <li><code>photoelastimetry/generate/point_load.py</code></li> <li><code>photoelastimetry/generate/strip_load.py</code></li> <li><code>photoelastimetry/generate/lithostatic.py</code></li> <li><code>photoelastimetry/generate/inclined_plane.py</code></li> </ul>"},{"location":"developer/module-map/#test-coverage-map","title":"Test Coverage Map","text":"<ul> <li>CLI and config behavior: <code>tests/test_main.py</code></li> <li>Calibration: <code>tests/test_calibrate.py</code></li> <li>IO: <code>tests/test_io_functions.py</code></li> <li>Solver: <code>tests/test_optimise.py</code></li> <li>Seeding/unwrapping: <code>tests/test_seeding.py</code>, <code>tests/test_unwrapping.py</code></li> <li>B-spline internals: <code>tests/test_bspline.py</code>, <code>tests/test_bspline_analytical.py</code></li> <li>Generator modules: <code>tests/test_disk.py</code>, <code>tests/test_point_load.py</code>, <code>tests/test_strip_load.py</code>, <code>tests/test_lithostatic.py</code>, <code>tests/test_inclined_plane.py</code></li> </ul>"},{"location":"developer/release-and-docs/","title":"Release and Docs Maintenance","text":""},{"location":"developer/release-and-docs/#versioning-checklist","title":"Versioning Checklist","text":"<ol> <li>Update version in <code>pyproject.toml</code>.</li> <li>Run full tests locally.</li> <li>Build docs with strict link checking.</li> <li>Merge and tag release according to repository process.</li> </ol>"},{"location":"developer/release-and-docs/#docs-qa-checklist","title":"Docs QA Checklist","text":"<pre><code>mkdocs build --strict\n</code></pre> <p>Confirm:</p> <ul> <li>no broken links</li> <li>no stale command/config references</li> <li>new or changed modules reflected in reference nav/pages</li> </ul>"},{"location":"developer/release-and-docs/#keep-docs-in-sync-with-code","title":"Keep Docs in Sync With Code","text":"<ul> <li>CLI changes in <code>photoelastimetry/main.py</code> require updates in:</li> <li><code>docs/user/workflows/*</code></li> <li><code>docs/user/configuration.md</code></li> <li>New modules require:</li> <li>a reference page under <code>docs/reference/</code></li> <li>nav update in <code>mkdocs.yml</code></li> <li>Behavioral changes should add/update tests under <code>tests/</code> and corresponding docs notes.</li> </ul>"},{"location":"developer/setup/","title":"Developer Setup","text":""},{"location":"developer/setup/#clone-and-install","title":"Clone and Install","text":"<pre><code>git clone https://github.com/benjym/photoelastimetry.git\ncd photoelastimetry\npython -m venv .venv\nsource .venv/bin/activate\npip install -e \".[dev,docs]\"\npre-commit install\n</code></pre>"},{"location":"developer/setup/#verify-core-tooling","title":"Verify Core Tooling","text":"<pre><code>pytest --version\nmkdocs --version\nblack --version\n</code></pre>"},{"location":"developer/setup/#useful-entry-points","title":"Useful Entry Points","text":"<ul> <li>CLI orchestration: <code>photoelastimetry/main.py</code></li> <li>Calibration pipeline: <code>photoelastimetry/calibrate.py</code></li> <li>Solver: <code>photoelastimetry/optimise.py</code></li> <li>Data IO: <code>photoelastimetry/io.py</code></li> </ul>"},{"location":"developer/setup/#build-docs-locally","title":"Build Docs Locally","text":"<pre><code>mkdocs serve\n</code></pre> <p>Local docs URL: <code>http://127.0.0.1:8000</code></p>"},{"location":"developer/testing/","title":"Testing","text":""},{"location":"developer/testing/#test-stack","title":"Test Stack","text":"<ul> <li>Test runner: <code>pytest</code></li> <li>Coverage config: <code>pyproject.toml</code> (<code>fail_under = 70</code>)</li> <li>Test roots: <code>tests/test_*.py</code></li> <li>Markers: <code>slow</code>, <code>integration</code>, <code>unit</code>, <code>smoke</code></li> </ul>"},{"location":"developer/testing/#common-commands","title":"Common Commands","text":"<pre><code># Full suite (includes coverage reporting via pytest addopts)\npytest\n\n# Exclude smoke tests\npytest -m \"not smoke\"\n\n# Smoke tests only\npytest -m smoke\n\n# Single test file\npytest tests/test_main.py\n</code></pre>"},{"location":"developer/testing/#what-is-covered","title":"What Is Covered","text":"<ul> <li>CLI behavior and parameter validation (<code>tests/test_main.py</code>)</li> <li>Calibration configuration and fitting (<code>tests/test_calibrate.py</code>)</li> <li>IO format handling and channel mapping (<code>tests/test_io_functions.py</code>)</li> <li>Seeding, unwrapping, B-spline, and optimise solver behavior</li> <li>Generator modules (<code>disk</code>, <code>point_load</code>, <code>strip_load</code>, <code>lithostatic</code>, <code>inclined_plane</code>)</li> </ul>"},{"location":"developer/testing/#quality-expectations","title":"Quality Expectations","text":"<ul> <li>Add tests for new functionality and failure paths.</li> <li>Prefer deterministic arrays and fixed RNG seeds.</li> <li>Assert behavior (not only shape checks).</li> </ul>"},{"location":"reference/","title":"API Reference","text":"<p>This section contains auto-generated API docs from package source.</p>"},{"location":"reference/#core-modules","title":"Core Modules","text":"<ul> <li>main: CLI entry points and workflow orchestration</li> <li>io: image/raw IO and channel operations</li> <li>image: Stokes/Mueller operations and forward model helpers</li> <li>calibrate: calibration profile and fitting workflow</li> <li>optimise: mean-stress recovery solver</li> <li>seeding: phase-decomposed seeding and fringe resolution</li> <li>bspline: B-spline stress/pressure field primitives</li> <li>unwrapping: graph-cut angle unwrapping</li> <li>visualisation: terminal boundary-condition visualizations</li> <li>plotting: plotting utilities</li> </ul>"},{"location":"reference/#generator-modules","title":"Generator Modules","text":"<ul> <li>generate.disk</li> <li>generate.point_load</li> <li>generate.strip_load</li> <li>generate.lithostatic</li> <li>generate.inclined_plane</li> </ul>"},{"location":"reference/#intentionally-omitted","title":"Intentionally Omitted","text":"<ul> <li><code>photoelastimetry.__init__</code></li> <li><code>photoelastimetry.generate.__init__</code></li> </ul> <p>These modules primarily provide package/export scaffolding and do not contain standalone runtime workflows.</p>"},{"location":"reference/bspline/","title":"bspline","text":"<p>B-spline field representations used by stress and pressure recovery routines.</p>"},{"location":"reference/bspline/#photoelastimetry.bspline","title":"<code>bspline</code>","text":""},{"location":"reference/bspline/#photoelastimetry.bspline-classes","title":"Classes","text":""},{"location":"reference/bspline/#photoelastimetry.bspline.BSplineAiry","title":"<code>BSplineAiry</code>","text":"<p>Manages a tensor-product B-spline surface for the Airy stress function.</p> <p>This class pre-computes basis functions to allow fast evaluation of stress fields (derivatives of the Airy function) from a set of control points.</p> <p>The Airy stress function phi(x,y) is represented as:     phi(x,y) = sum_i sum_j C_ij * B_i(x) * B_j(y)</p> <p>Stresses are:     sigma_xx = d^2(phi)/dy^2     sigma_yy = d^2(phi)/dx^2     sigma_xy = -d^2(phi)/dxdy</p> Source code in <code>photoelastimetry/bspline.py</code> <pre><code>class BSplineAiry:\n    \"\"\"\n    Manages a tensor-product B-spline surface for the Airy stress function.\n\n    This class pre-computes basis functions to allow fast evaluation of\n    stress fields (derivatives of the Airy function) from a set of control points.\n\n    The Airy stress function phi(x,y) is represented as:\n        phi(x,y) = sum_i sum_j C_ij * B_i(x) * B_j(y)\n\n    Stresses are:\n        sigma_xx = d^2(phi)/dy^2\n        sigma_yy = d^2(phi)/dx^2\n        sigma_xy = -d^2(phi)/dxdy\n    \"\"\"\n\n    def __init__(self, shape, knot_spacing, degree=3):\n        \"\"\"\n        Initialize the B-spline basis for a given image shape.\n\n        Parameters\n        ----------\n        shape : tuple\n            Image shape (height, width).\n        knot_spacing : int\n            Approximate spacing between knots in pixels.\n        degree : int\n            Degree of the B-spline (default: 3 for cubic).\n        \"\"\"\n        self.ny, self.nx = shape\n        self.degree = degree\n        self.knot_spacing = knot_spacing\n\n        # Generate knots\n        # We need knots to cover the range [0, n] with sufficient padding for the degree\n        # interior knots\n        # tx = np.arange(0, self.nx + knot_spacing, knot_spacing)\n        # ty = np.arange(0, self.ny + knot_spacing, knot_spacing)\n\n        # Add simpler padding\n        # Standard way for clamped B-spline is repeating start/end knots degree+1 times\n        # But for general coverage we just need enough support.\n        # Let's use the standard \"clamped\" knot vector construction for the domain [0, L]\n\n        def make_knots(length, step):\n            # Interior knots\n            interior = np.arange(0, length + step, step)\n            if interior[-1] &lt; length:\n                interior = np.append(interior, length)\n\n            # Pad with clamped ends\n            t = np.concatenate(([interior[0]] * degree, interior, [interior[-1]] * degree))\n            return t\n\n        self.tx = make_knots(self.nx, knot_spacing)\n        self.ty = make_knots(self.ny, knot_spacing)\n\n        # Number of coefficients (control points)\n        self.n_coeffs_x = len(self.tx) - degree - 1\n        self.n_coeffs_y = len(self.ty) - degree - 1\n        self.n_coeffs = self.n_coeffs_x * self.n_coeffs_y\n\n        # Pre-evaluate basis functions on the pixel grid\n        # We evaluate at pixel centers\n        x_grid = np.arange(self.nx)\n        y_grid = np.arange(self.ny)\n\n        # Evaluate basis functions B(x) and derivatives\n        # This creates matrices of shape (width, n_coeffs_x)\n        self.Bx, self.dBx, self.ddBx = self._precompute_basis(x_grid, self.tx, self.n_coeffs_x)\n        self.By, self.dBy, self.ddBy = self._precompute_basis(y_grid, self.ty, self.n_coeffs_y)\n\n    def _precompute_basis(self, coords, knots, n_coeffs):\n        \"\"\"\n        Compute B-spline basis matrix and its 1st and 2nd derivatives.\n        Returns matrices of shape (len(coords), n_coeffs).\n        \"\"\"\n        # We use scipy BSpline.design_matrix-like logic but explicit\n        # We want to know the value of the i-th basis function at each coordinate.\n        # B_mat[k, i] = B_i(coords[k])\n\n        B_mat = np.zeros((len(coords), n_coeffs))\n        dB_mat = np.zeros((len(coords), n_coeffs))\n        ddB_mat = np.zeros((len(coords), n_coeffs))\n\n        # Iterate over each basis function\n        # This might be slow for very large grids, but it's done once.\n        # A faster way is to realize only degree+1 functions are non-zero at any point.\n        # But optimizing this pre-calc is secondary to the main loop speed.\n\n        for i in range(n_coeffs):\n            # Create a localized BSpline for the i-th basis function\n            # The coefficient vector is 1 at i and 0 elsewhere\n            c = np.zeros(n_coeffs)\n            c[i] = 1.0\n            spl = BSpline(knots, c, self.degree)\n\n            B_mat[:, i] = spl(coords)\n            dB_mat[:, i] = spl(coords, nu=1)\n            ddB_mat[:, i] = spl(coords, nu=2)\n\n        return B_mat, dB_mat, ddB_mat\n\n    def get_stress_fields(self, coeffs_flat):\n        \"\"\"\n        Compute stress fields from flat coefficient array.\n\n        Parameters\n        ----------\n        coeffs_flat : array-like\n            Flattened array of coefficients of length n_coeffs_x * n_coeffs_y.\n\n        Returns\n        -------\n        sigma_xx, sigma_yy, sigma_xy : ndarray\n            Stress fields of shape (height, width).\n        \"\"\"\n        C = coeffs_flat.reshape(self.n_coeffs_y, self.n_coeffs_x)\n\n        # sigma_xx = d^2(phi)/dy^2 = By'' * C * Bx.T\n        # Shape: (ny, n_cy) @ (n_cy, n_cx) @ (n_cx, nx) -&gt; (ny, nx)\n        sigma_xx = self.ddBy @ C @ self.Bx.T\n\n        # sigma_yy = d^2(phi)/dx^2 = By * C * Bx''.T\n        sigma_yy = self.By @ C @ self.ddBx.T\n\n        # sigma_xy = -d^2(phi)/dxdy in standard physics convention\n        # However, in image coordinates where y increases downward (y_img),\n        # and physical coordinates have y increasing upward (y_phy):\n        # dy_phy = -dy_img, so d/dy_phy = -d/dy_img\n        # Thus: sigma_xy = -d\u00b2\u03c6/dx_phy dy_phy = -d\u00b2\u03c6/dx_img (-dy_img) = +d\u00b2\u03c6/dx_img dy_img\n        # Result: sigma_xy = dBy @ C @ dBx.T (positive sign in image coordinates)\n        sigma_xy = self.dBy @ C @ self.dBx.T\n\n        return sigma_xx, sigma_yy, sigma_xy\n\n    def project_stress_gradients(self, grad_s_xx, grad_s_yy, grad_s_xy):\n        \"\"\"\n        Project stress field gradients back to B-spline coefficients.\n        This effectively computes d(Loss)/d(Coeffs) given d(Loss)/d(Stress).\n\n        Parameters\n        ----------\n        grad_s_xx, grad_s_yy, grad_s_xy : ndarray\n            Gradients of the loss with respect to stress fields. (ny, nx)\n\n        Returns\n        -------\n        grad_coeffs : ndarray\n            Gradient with respect to flattened coefficients.\n        \"\"\"\n        # The stress field generation is linear: S = A @ C @ B.T\n        # The gradient backprop is: G_C = A.T @ G_S @ B\n\n        # Contributions from sigma_xx = ddBy @ C @ Bx.T\n        grad_C = self.ddBy.T @ grad_s_xx @ self.Bx\n\n        # Contributions from sigma_yy = By @ C @ ddBx.T\n        grad_C += self.By.T @ grad_s_yy @ self.ddBx\n\n        # Contributions from sigma_xy = dBy @ C @ dBx.T\n        # Positive sign maintains consistency with forward pass in get_stress_fields()\n        # (no negative sign due to image coordinate system transformation)\n        grad_C += self.dBy.T @ grad_s_xy @ self.dBx\n\n        return grad_C.flatten()\n\n    def fit_stress_field(self, stress_map):\n        \"\"\"\n        Fit B-spline coefficients to an initial stress map.\n\n        Parameters\n        ----------\n        stress_map : ndarray\n            Target stress map [H, W, 3] usually from seeding.\n\n        Returns\n        -------\n        coeffs_flat : ndarray\n            Flattened coefficients fitting the stress map.\n        \"\"\"\n        target_s_xx = stress_map[:, :, 0]\n        target_s_yy = stress_map[:, :, 1]\n        target_s_xy = stress_map[:, :, 2]\n\n        def loss_and_grad(coeffs):\n            s_xx, s_yy, s_xy = self.get_stress_fields(coeffs)\n\n            diff_xx = s_xx - target_s_xx\n            diff_yy = s_yy - target_s_yy\n            diff_xy = s_xy - target_s_xy\n\n            # Handle NaNs in target (e.g. from failed seeding or masking)\n            if np.isnan(stress_map).any():\n                mask_xx = np.isnan(target_s_xx)\n                mask_yy = np.isnan(target_s_yy)\n                mask_xy = np.isnan(target_s_xy)\n\n                diff_xx[mask_xx] = 0\n                diff_yy[mask_yy] = 0\n                diff_xy[mask_xy] = 0\n\n            loss = np.sum(diff_xx**2 + diff_yy**2 + diff_xy**2)\n\n            # Gradient\n            # d(Loss)/ds = 2 * diff\n            grad = self.project_stress_gradients(2 * diff_xx, 2 * diff_yy, 2 * diff_xy)\n\n            return loss, grad\n\n        from scipy.optimize import minimize\n\n        # Start from zeros\n        res = minimize(\n            loss_and_grad,\n            np.zeros(self.n_coeffs),\n            jac=True,\n            method=\"L-BFGS-B\",\n            options={\"disp\": False, \"maxiter\": 100},  # Quick fit\n        )\n        return res.x\n</code></pre>"},{"location":"reference/bspline/#photoelastimetry.bspline.BSplineAiry-functions","title":"Functions","text":""},{"location":"reference/bspline/#photoelastimetry.bspline.BSplineAiry.get_stress_fields","title":"<code>get_stress_fields(coeffs_flat)</code>","text":"<p>Compute stress fields from flat coefficient array.</p> <p>Parameters:</p> Name Type Description Default <code>coeffs_flat</code> <code>array - like</code> <p>Flattened array of coefficients of length n_coeffs_x * n_coeffs_y.</p> required <p>Returns:</p> Type Description <code>sigma_xx, sigma_yy, sigma_xy : ndarray</code> <p>Stress fields of shape (height, width).</p> Source code in <code>photoelastimetry/bspline.py</code> <pre><code>def get_stress_fields(self, coeffs_flat):\n    \"\"\"\n    Compute stress fields from flat coefficient array.\n\n    Parameters\n    ----------\n    coeffs_flat : array-like\n        Flattened array of coefficients of length n_coeffs_x * n_coeffs_y.\n\n    Returns\n    -------\n    sigma_xx, sigma_yy, sigma_xy : ndarray\n        Stress fields of shape (height, width).\n    \"\"\"\n    C = coeffs_flat.reshape(self.n_coeffs_y, self.n_coeffs_x)\n\n    # sigma_xx = d^2(phi)/dy^2 = By'' * C * Bx.T\n    # Shape: (ny, n_cy) @ (n_cy, n_cx) @ (n_cx, nx) -&gt; (ny, nx)\n    sigma_xx = self.ddBy @ C @ self.Bx.T\n\n    # sigma_yy = d^2(phi)/dx^2 = By * C * Bx''.T\n    sigma_yy = self.By @ C @ self.ddBx.T\n\n    # sigma_xy = -d^2(phi)/dxdy in standard physics convention\n    # However, in image coordinates where y increases downward (y_img),\n    # and physical coordinates have y increasing upward (y_phy):\n    # dy_phy = -dy_img, so d/dy_phy = -d/dy_img\n    # Thus: sigma_xy = -d\u00b2\u03c6/dx_phy dy_phy = -d\u00b2\u03c6/dx_img (-dy_img) = +d\u00b2\u03c6/dx_img dy_img\n    # Result: sigma_xy = dBy @ C @ dBx.T (positive sign in image coordinates)\n    sigma_xy = self.dBy @ C @ self.dBx.T\n\n    return sigma_xx, sigma_yy, sigma_xy\n</code></pre>"},{"location":"reference/bspline/#photoelastimetry.bspline.BSplineAiry.project_stress_gradients","title":"<code>project_stress_gradients(grad_s_xx, grad_s_yy, grad_s_xy)</code>","text":"<p>Project stress field gradients back to B-spline coefficients. This effectively computes d(Loss)/d(Coeffs) given d(Loss)/d(Stress).</p> <p>Parameters:</p> Name Type Description Default <code>grad_s_xx</code> <code>ndarray</code> <p>Gradients of the loss with respect to stress fields. (ny, nx)</p> required <code>grad_s_yy</code> <code>ndarray</code> <p>Gradients of the loss with respect to stress fields. (ny, nx)</p> required <code>grad_s_xy</code> <code>ndarray</code> <p>Gradients of the loss with respect to stress fields. (ny, nx)</p> required <p>Returns:</p> Name Type Description <code>grad_coeffs</code> <code>ndarray</code> <p>Gradient with respect to flattened coefficients.</p> Source code in <code>photoelastimetry/bspline.py</code> <pre><code>def project_stress_gradients(self, grad_s_xx, grad_s_yy, grad_s_xy):\n    \"\"\"\n    Project stress field gradients back to B-spline coefficients.\n    This effectively computes d(Loss)/d(Coeffs) given d(Loss)/d(Stress).\n\n    Parameters\n    ----------\n    grad_s_xx, grad_s_yy, grad_s_xy : ndarray\n        Gradients of the loss with respect to stress fields. (ny, nx)\n\n    Returns\n    -------\n    grad_coeffs : ndarray\n        Gradient with respect to flattened coefficients.\n    \"\"\"\n    # The stress field generation is linear: S = A @ C @ B.T\n    # The gradient backprop is: G_C = A.T @ G_S @ B\n\n    # Contributions from sigma_xx = ddBy @ C @ Bx.T\n    grad_C = self.ddBy.T @ grad_s_xx @ self.Bx\n\n    # Contributions from sigma_yy = By @ C @ ddBx.T\n    grad_C += self.By.T @ grad_s_yy @ self.ddBx\n\n    # Contributions from sigma_xy = dBy @ C @ dBx.T\n    # Positive sign maintains consistency with forward pass in get_stress_fields()\n    # (no negative sign due to image coordinate system transformation)\n    grad_C += self.dBy.T @ grad_s_xy @ self.dBx\n\n    return grad_C.flatten()\n</code></pre>"},{"location":"reference/bspline/#photoelastimetry.bspline.BSplineAiry.fit_stress_field","title":"<code>fit_stress_field(stress_map)</code>","text":"<p>Fit B-spline coefficients to an initial stress map.</p> <p>Parameters:</p> Name Type Description Default <code>stress_map</code> <code>ndarray</code> <p>Target stress map [H, W, 3] usually from seeding.</p> required <p>Returns:</p> Name Type Description <code>coeffs_flat</code> <code>ndarray</code> <p>Flattened coefficients fitting the stress map.</p> Source code in <code>photoelastimetry/bspline.py</code> <pre><code>def fit_stress_field(self, stress_map):\n    \"\"\"\n    Fit B-spline coefficients to an initial stress map.\n\n    Parameters\n    ----------\n    stress_map : ndarray\n        Target stress map [H, W, 3] usually from seeding.\n\n    Returns\n    -------\n    coeffs_flat : ndarray\n        Flattened coefficients fitting the stress map.\n    \"\"\"\n    target_s_xx = stress_map[:, :, 0]\n    target_s_yy = stress_map[:, :, 1]\n    target_s_xy = stress_map[:, :, 2]\n\n    def loss_and_grad(coeffs):\n        s_xx, s_yy, s_xy = self.get_stress_fields(coeffs)\n\n        diff_xx = s_xx - target_s_xx\n        diff_yy = s_yy - target_s_yy\n        diff_xy = s_xy - target_s_xy\n\n        # Handle NaNs in target (e.g. from failed seeding or masking)\n        if np.isnan(stress_map).any():\n            mask_xx = np.isnan(target_s_xx)\n            mask_yy = np.isnan(target_s_yy)\n            mask_xy = np.isnan(target_s_xy)\n\n            diff_xx[mask_xx] = 0\n            diff_yy[mask_yy] = 0\n            diff_xy[mask_xy] = 0\n\n        loss = np.sum(diff_xx**2 + diff_yy**2 + diff_xy**2)\n\n        # Gradient\n        # d(Loss)/ds = 2 * diff\n        grad = self.project_stress_gradients(2 * diff_xx, 2 * diff_yy, 2 * diff_xy)\n\n        return loss, grad\n\n    from scipy.optimize import minimize\n\n    # Start from zeros\n    res = minimize(\n        loss_and_grad,\n        np.zeros(self.n_coeffs),\n        jac=True,\n        method=\"L-BFGS-B\",\n        options={\"disp\": False, \"maxiter\": 100},  # Quick fit\n    )\n    return res.x\n</code></pre>"},{"location":"reference/bspline/#photoelastimetry.bspline.BSplineScalar","title":"<code>BSplineScalar</code>","text":"<p>               Bases: <code>BSplineAiry</code></p> <p>Manages a tensor-product B-spline surface for a scalar field (e.g. Pressure).</p> <p>Inherits pre-computation from BSplineAiry. Computes P, dP/dx, dP/dy.</p> Source code in <code>photoelastimetry/bspline.py</code> <pre><code>class BSplineScalar(BSplineAiry):\n    \"\"\"\n    Manages a tensor-product B-spline surface for a scalar field (e.g. Pressure).\n\n    Inherits pre-computation from BSplineAiry.\n    Computes P, dP/dx, dP/dy.\n    \"\"\"\n\n    def get_scalar_fields(self, coeffs_flat):\n        \"\"\"\n        Compute scalar field and its gradients.\n\n        Parameters\n        ----------\n        coeffs_flat : array-like\n            Flattened array of coefficients.\n\n        Returns\n        -------\n        P, dP_dx, dP_dy : ndarray\n            Scalar field and gradients of shape (height, width).\n        \"\"\"\n        C = coeffs_flat.reshape(self.n_coeffs_y, self.n_coeffs_x)\n\n        # P = By * C * Bx.T\n        P = self.By @ C @ self.Bx.T\n\n        # dP/dx = By * C * dBx.T\n        dP_dx = self.By @ C @ self.dBx.T\n\n        # dP/dy = dBy * C * Bx.T\n        # Note: image coords +y is down. If we need physical gradients, handled outside.\n        # But for consistency with get_stress_fields (which likely uses image gradients)\n        dP_dy = self.dBy @ C @ self.Bx.T\n\n        return P, dP_dx, dP_dy\n\n    def project_scalar_gradients(self, grad_P, grad_dP_dx, grad_dP_dy):\n        \"\"\"\n        Project field gradients back to B-spline coefficients.\n\n        Parameters\n        ----------\n        grad_P : ndarray\n            dL/dP\n        grad_dP_dx : ndarray\n            dL/d(dP/dx)\n        grad_dP_dy : ndarray\n            dL/d(dP/dy)\n\n        Returns\n        -------\n        grad_coeffs : ndarray\n        \"\"\"\n        # P = By @ C @ Bx.T\n        grad_C = self.By.T @ grad_P @ self.Bx\n\n        # dP_dx Contribution\n        if grad_dP_dx is not None:\n            grad_C += self.By.T @ grad_dP_dx @ self.dBx\n\n        # dP_dy Contribution\n        if grad_dP_dy is not None:\n            grad_C += self.dBy.T @ grad_dP_dy @ self.Bx\n\n        return grad_C.flatten()\n\n    def fit_scalar_field(self, scalar_field, mask=None, maxiter=100):\n        \"\"\"\n        Fit B-spline coefficients to a target scalar field.\n\n        Parameters\n        ----------\n        scalar_field : ndarray\n            Target scalar map with shape (ny, nx).\n        mask : ndarray of bool, optional\n            Optional valid-pixel mask with shape (ny, nx). Pixels outside the mask\n            are ignored. NaNs are always ignored.\n        maxiter : int\n            Maximum optimizer iterations.\n\n        Returns\n        -------\n        coeffs_flat : ndarray\n            Flattened coefficients fitting the scalar map.\n        \"\"\"\n        target_P = np.asarray(scalar_field)\n        if target_P.shape != (self.ny, self.nx):\n            raise ValueError(f\"scalar_field shape must be {(self.ny, self.nx)}, got {target_P.shape}\")\n\n        if mask is None:\n            valid = ~np.isnan(target_P)\n        else:\n            valid = mask &amp; ~np.isnan(target_P)\n\n        if not np.any(valid):\n            return np.zeros(self.n_coeffs)\n\n        def loss_and_grad(coeffs):\n            P, _, _ = self.get_scalar_fields(coeffs)\n            diff = np.zeros_like(P)\n            diff[valid] = P[valid] - target_P[valid]\n\n            loss = np.sum(diff[valid] ** 2)\n            grad = self.project_scalar_gradients(2 * diff, None, None)\n            return loss, grad\n\n        from scipy.optimize import minimize\n\n        res = minimize(\n            loss_and_grad,\n            np.zeros(self.n_coeffs),\n            jac=True,\n            method=\"L-BFGS-B\",\n            options={\"disp\": False, \"maxiter\": maxiter},\n        )\n        return res.x\n</code></pre>"},{"location":"reference/bspline/#photoelastimetry.bspline.BSplineScalar-functions","title":"Functions","text":""},{"location":"reference/bspline/#photoelastimetry.bspline.BSplineScalar.get_scalar_fields","title":"<code>get_scalar_fields(coeffs_flat)</code>","text":"<p>Compute scalar field and its gradients.</p> <p>Parameters:</p> Name Type Description Default <code>coeffs_flat</code> <code>array - like</code> <p>Flattened array of coefficients.</p> required <p>Returns:</p> Type Description <code>P, dP_dx, dP_dy : ndarray</code> <p>Scalar field and gradients of shape (height, width).</p> Source code in <code>photoelastimetry/bspline.py</code> <pre><code>def get_scalar_fields(self, coeffs_flat):\n    \"\"\"\n    Compute scalar field and its gradients.\n\n    Parameters\n    ----------\n    coeffs_flat : array-like\n        Flattened array of coefficients.\n\n    Returns\n    -------\n    P, dP_dx, dP_dy : ndarray\n        Scalar field and gradients of shape (height, width).\n    \"\"\"\n    C = coeffs_flat.reshape(self.n_coeffs_y, self.n_coeffs_x)\n\n    # P = By * C * Bx.T\n    P = self.By @ C @ self.Bx.T\n\n    # dP/dx = By * C * dBx.T\n    dP_dx = self.By @ C @ self.dBx.T\n\n    # dP/dy = dBy * C * Bx.T\n    # Note: image coords +y is down. If we need physical gradients, handled outside.\n    # But for consistency with get_stress_fields (which likely uses image gradients)\n    dP_dy = self.dBy @ C @ self.Bx.T\n\n    return P, dP_dx, dP_dy\n</code></pre>"},{"location":"reference/bspline/#photoelastimetry.bspline.BSplineScalar.project_scalar_gradients","title":"<code>project_scalar_gradients(grad_P, grad_dP_dx, grad_dP_dy)</code>","text":"<p>Project field gradients back to B-spline coefficients.</p> <p>Parameters:</p> Name Type Description Default <code>grad_P</code> <code>ndarray</code> <p>dL/dP</p> required <code>grad_dP_dx</code> <code>ndarray</code> <p>dL/d(dP/dx)</p> required <code>grad_dP_dy</code> <code>ndarray</code> <p>dL/d(dP/dy)</p> required <p>Returns:</p> Name Type Description <code>grad_coeffs</code> <code>ndarray</code> Source code in <code>photoelastimetry/bspline.py</code> <pre><code>def project_scalar_gradients(self, grad_P, grad_dP_dx, grad_dP_dy):\n    \"\"\"\n    Project field gradients back to B-spline coefficients.\n\n    Parameters\n    ----------\n    grad_P : ndarray\n        dL/dP\n    grad_dP_dx : ndarray\n        dL/d(dP/dx)\n    grad_dP_dy : ndarray\n        dL/d(dP/dy)\n\n    Returns\n    -------\n    grad_coeffs : ndarray\n    \"\"\"\n    # P = By @ C @ Bx.T\n    grad_C = self.By.T @ grad_P @ self.Bx\n\n    # dP_dx Contribution\n    if grad_dP_dx is not None:\n        grad_C += self.By.T @ grad_dP_dx @ self.dBx\n\n    # dP_dy Contribution\n    if grad_dP_dy is not None:\n        grad_C += self.dBy.T @ grad_dP_dy @ self.Bx\n\n    return grad_C.flatten()\n</code></pre>"},{"location":"reference/bspline/#photoelastimetry.bspline.BSplineScalar.fit_scalar_field","title":"<code>fit_scalar_field(scalar_field, mask=None, maxiter=100)</code>","text":"<p>Fit B-spline coefficients to a target scalar field.</p> <p>Parameters:</p> Name Type Description Default <code>scalar_field</code> <code>ndarray</code> <p>Target scalar map with shape (ny, nx).</p> required <code>mask</code> <code>ndarray of bool</code> <p>Optional valid-pixel mask with shape (ny, nx). Pixels outside the mask are ignored. NaNs are always ignored.</p> <code>None</code> <code>maxiter</code> <code>int</code> <p>Maximum optimizer iterations.</p> <code>100</code> <p>Returns:</p> Name Type Description <code>coeffs_flat</code> <code>ndarray</code> <p>Flattened coefficients fitting the scalar map.</p> Source code in <code>photoelastimetry/bspline.py</code> <pre><code>def fit_scalar_field(self, scalar_field, mask=None, maxiter=100):\n    \"\"\"\n    Fit B-spline coefficients to a target scalar field.\n\n    Parameters\n    ----------\n    scalar_field : ndarray\n        Target scalar map with shape (ny, nx).\n    mask : ndarray of bool, optional\n        Optional valid-pixel mask with shape (ny, nx). Pixels outside the mask\n        are ignored. NaNs are always ignored.\n    maxiter : int\n        Maximum optimizer iterations.\n\n    Returns\n    -------\n    coeffs_flat : ndarray\n        Flattened coefficients fitting the scalar map.\n    \"\"\"\n    target_P = np.asarray(scalar_field)\n    if target_P.shape != (self.ny, self.nx):\n        raise ValueError(f\"scalar_field shape must be {(self.ny, self.nx)}, got {target_P.shape}\")\n\n    if mask is None:\n        valid = ~np.isnan(target_P)\n    else:\n        valid = mask &amp; ~np.isnan(target_P)\n\n    if not np.any(valid):\n        return np.zeros(self.n_coeffs)\n\n    def loss_and_grad(coeffs):\n        P, _, _ = self.get_scalar_fields(coeffs)\n        diff = np.zeros_like(P)\n        diff[valid] = P[valid] - target_P[valid]\n\n        loss = np.sum(diff[valid] ** 2)\n        grad = self.project_scalar_gradients(2 * diff, None, None)\n        return loss, grad\n\n    from scipy.optimize import minimize\n\n    res = minimize(\n        loss_and_grad,\n        np.zeros(self.n_coeffs),\n        jac=True,\n        method=\"L-BFGS-B\",\n        options={\"disp\": False, \"maxiter\": maxiter},\n    )\n    return res.x\n</code></pre>"},{"location":"reference/calibrate/","title":"calibrate","text":"<p>Calibration workflows for <code>brazilian_disk</code> and <code>coupon_test</code> experiments.</p> <p>This module provides:</p> <ul> <li>Calibration profile loading/validation</li> <li>Dark/blank scalar correction estimation</li> <li>Robust fitting of per-channel stress-optic coefficients (<code>C</code>)</li> <li>Fitting of incoming Stokes state (<code>S_i_hat</code>)</li> <li>End-to-end calibration execution and report/profile output</li> </ul>"},{"location":"reference/calibrate/#photoelastimetry.calibrate","title":"<code>calibrate</code>","text":"<p>Calibration workflows for photoelastimetry experiments.</p> <p>This module fits per-wavelength stress-optic coefficients (C), incoming polarisation state (S_i_hat), and optional detector blank correction from a multi-load calibration sequence.</p> <p>Supported calibration methods: - <code>brazilian_disk</code>: diametrically-loaded disk with analytical stress field. - <code>coupon_test</code>: uniaxial coupon with nominal stress in a gauge ROI.</p>"},{"location":"reference/calibrate/#photoelastimetry.calibrate-functions","title":"Functions","text":""},{"location":"reference/calibrate/#photoelastimetry.calibrate.load_calibration_profile","title":"<code>load_calibration_profile(profile_file)</code>","text":"<p>Load and validate a calibration profile.</p> <p>Parameters:</p> Name Type Description Default <code>profile_file</code> <code>str</code> <p>Path to calibration JSON/JSON5 profile.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Validated calibration profile.</p> Source code in <code>photoelastimetry/calibrate.py</code> <pre><code>def load_calibration_profile(profile_file):\n    \"\"\"\n    Load and validate a calibration profile.\n\n    Parameters\n    ----------\n    profile_file : str\n        Path to calibration JSON/JSON5 profile.\n\n    Returns\n    -------\n    dict\n        Validated calibration profile.\n    \"\"\"\n    if not os.path.exists(profile_file):\n        raise ValueError(f\"Calibration file not found: {profile_file}\")\n\n    with open(profile_file, \"r\") as f:\n        profile = json5.load(f)\n\n    required = {\n        \"version\",\n        \"method\",\n        \"wavelengths\",\n        \"C\",\n        \"S_i_hat\",\n        \"blank_correction\",\n        \"fit_metrics\",\n        \"provenance\",\n    }\n    missing = sorted(required.difference(profile.keys()))\n    if missing:\n        raise ValueError(f\"Calibration profile missing required keys: {missing}\")\n\n    supported_methods = {\"brazilian_disk\", \"coupon_test\"}\n    if profile[\"method\"] not in supported_methods:\n        raise ValueError(\n            f\"Unsupported calibration method '{profile['method']}'. \"\n            f\"Supported methods: {sorted(supported_methods)}.\"\n        )\n\n    wavelengths = _normalise_wavelengths(profile[\"wavelengths\"])\n    C = _as_float_array(profile[\"C\"], expected_length=wavelengths.size, name=\"C\")\n\n    S_i_hat = np.asarray(profile[\"S_i_hat\"], dtype=float)\n    if S_i_hat.size == 2:\n        S_i_hat = np.append(S_i_hat, 0.0)\n    if S_i_hat.size != 3:\n        raise ValueError(f\"S_i_hat must have length 2 or 3, got {S_i_hat.size}.\")\n\n    blank = profile[\"blank_correction\"]\n    if \"offset\" not in blank or \"scale\" not in blank:\n        raise ValueError(\"blank_correction must contain 'offset' and 'scale'.\")\n\n    offset = np.asarray(blank[\"offset\"], dtype=float)\n    scale = np.asarray(blank[\"scale\"], dtype=float)\n    if offset.shape != (wavelengths.size, 4) or scale.shape != (wavelengths.size, 4):\n        raise ValueError(\n            \"blank_correction offset/scale must have shape \"\n            f\"({wavelengths.size}, 4); got {offset.shape} and {scale.shape}.\"\n        )\n\n    validated = dict(profile)\n    validated[\"wavelengths\"] = wavelengths.tolist()\n    validated[\"C\"] = C.tolist()\n    validated[\"S_i_hat\"] = S_i_hat.tolist()\n    return validated\n</code></pre>"},{"location":"reference/calibrate/#photoelastimetry.calibrate.compute_blank_correction","title":"<code>compute_blank_correction(dark_frame, blank_frame, eps=1e-06)</code>","text":"<p>Compute per-channel/per-angle scalar blank correction coefficients.</p> <p>Parameters:</p> Name Type Description Default <code>dark_frame</code> <code>ndarray</code> <p>Dark reference image stack [H, W, C, 4].</p> required <code>blank_frame</code> <code>ndarray</code> <p>Blank reference image stack [H, W, C, 4].</p> required <code>eps</code> <code>float</code> <p>Minimum denominator for stability.</p> <code>1e-06</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with <code>offset</code> and <code>scale</code> arrays, each shape [C, 4].</p> Source code in <code>photoelastimetry/calibrate.py</code> <pre><code>def compute_blank_correction(dark_frame, blank_frame, eps=1e-6):\n    \"\"\"\n    Compute per-channel/per-angle scalar blank correction coefficients.\n\n    Parameters\n    ----------\n    dark_frame : ndarray\n        Dark reference image stack [H, W, C, 4].\n    blank_frame : ndarray\n        Blank reference image stack [H, W, C, 4].\n    eps : float\n        Minimum denominator for stability.\n\n    Returns\n    -------\n    dict\n        Dictionary with `offset` and `scale` arrays, each shape [C, 4].\n    \"\"\"\n    dark = np.asarray(dark_frame, dtype=float)\n    blank = np.asarray(blank_frame, dtype=float)\n\n    if dark.shape != blank.shape:\n        raise ValueError(f\"Dark and blank frame shapes must match. Got {dark.shape} and {blank.shape}.\")\n    if dark.ndim != 4 or dark.shape[-1] != 4:\n        raise ValueError(f\"Blank correction frames must have shape [H, W, C, 4], got {dark.shape}.\")\n\n    offset = np.median(dark, axis=(0, 1))\n    denom = np.median(blank, axis=(0, 1)) - offset\n\n    if np.any(denom &lt;= eps):\n        raise ValueError(\"Blank correction denominator is non-positive for at least one channel/polariser.\")\n\n    scale = 1.0 / denom\n    return {\n        \"offset\": offset.tolist(),\n        \"scale\": scale.tolist(),\n        \"mode\": \"dark_blank_scalar\",\n        \"eps\": float(eps),\n    }\n</code></pre>"},{"location":"reference/calibrate/#photoelastimetry.calibrate.apply_blank_correction","title":"<code>apply_blank_correction(data, blank_correction)</code>","text":"<p>Apply per-channel/per-angle blank correction to an image stack.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Image data [H, W, C, 4].</p> required <code>blank_correction</code> <code>dict</code> <p>Blank correction dictionary containing <code>offset</code> and <code>scale</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Corrected image stack with same shape as input.</p> Source code in <code>photoelastimetry/calibrate.py</code> <pre><code>def apply_blank_correction(data, blank_correction):\n    \"\"\"\n    Apply per-channel/per-angle blank correction to an image stack.\n\n    Parameters\n    ----------\n    data : ndarray\n        Image data [H, W, C, 4].\n    blank_correction : dict\n        Blank correction dictionary containing `offset` and `scale`.\n\n    Returns\n    -------\n    ndarray\n        Corrected image stack with same shape as input.\n    \"\"\"\n    arr = np.asarray(data, dtype=float)\n    if arr.ndim != 4 or arr.shape[-1] != 4:\n        raise ValueError(f\"Image data must have shape [H, W, C, 4], got {arr.shape}.\")\n\n    if blank_correction is None:\n        return arr\n\n    if \"offset\" not in blank_correction or \"scale\" not in blank_correction:\n        raise ValueError(\"blank_correction must contain 'offset' and 'scale'.\")\n\n    offset = np.asarray(blank_correction[\"offset\"], dtype=float)\n    scale = np.asarray(blank_correction[\"scale\"], dtype=float)\n\n    if offset.ndim != 2 or scale.ndim != 2 or offset.shape[1] != 4 or scale.shape[1] != 4:\n        raise ValueError(\n            \"blank_correction offset/scale must each have shape [n_wavelengths, 4]. \"\n            f\"Got {offset.shape} and {scale.shape}.\"\n        )\n\n    if offset.shape[0] != arr.shape[2] or scale.shape[0] != arr.shape[2]:\n        raise ValueError(\n            \"blank_correction wavelength count must match data channels. \"\n            f\"Got correction {offset.shape[0]} and data {arr.shape[2]}.\"\n        )\n\n    corrected = (arr - offset[np.newaxis, np.newaxis, :, :]) * scale[np.newaxis, np.newaxis, :, :]\n    return corrected\n</code></pre>"},{"location":"reference/calibrate/#photoelastimetry.calibrate.validate_calibration_config","title":"<code>validate_calibration_config(config)</code>","text":"<p>Validate and normalise calibration configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Calibration configuration loaded from JSON5.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Normalised configuration with defaults.</p> Source code in <code>photoelastimetry/calibrate.py</code> <pre><code>def validate_calibration_config(config):\n    \"\"\"\n    Validate and normalise calibration configuration.\n\n    Parameters\n    ----------\n    config : dict\n        Calibration configuration loaded from JSON5.\n\n    Returns\n    -------\n    dict\n        Normalised configuration with defaults.\n    \"\"\"\n    method = config.get(\"method\", \"brazilian_disk\")\n    supported_methods = {\"brazilian_disk\", \"coupon_test\"}\n    if method not in supported_methods:\n        raise ValueError(f\"Unsupported method='{method}'. Supported methods are {sorted(supported_methods)}.\")\n\n    if \"wavelengths\" not in config:\n        raise ValueError(\"Calibration config must include 'wavelengths'.\")\n    wavelengths = _normalise_wavelengths(config[\"wavelengths\"])\n\n    if \"thickness\" not in config:\n        raise ValueError(\"Calibration config must include 'thickness'.\")\n    thickness = float(config[\"thickness\"])\n    if thickness &lt;= 0:\n        raise ValueError(\"thickness must be positive.\")\n\n    geometry = dict(config.get(\"geometry\", {}))\n    if method == \"brazilian_disk\":\n        for key in (\"radius_m\", \"center_px\", \"pixels_per_meter\"):\n            if key not in geometry:\n                raise ValueError(f\"geometry must include '{key}' for method='brazilian_disk'.\")\n\n        radius_m = float(geometry[\"radius_m\"])\n        pixels_per_meter = float(geometry[\"pixels_per_meter\"])\n        center_px = np.asarray(geometry[\"center_px\"], dtype=float)\n\n        if radius_m &lt;= 0:\n            raise ValueError(\"geometry.radius_m must be positive.\")\n        if pixels_per_meter &lt;= 0:\n            raise ValueError(\"geometry.pixels_per_meter must be positive.\")\n        if center_px.size != 2:\n            raise ValueError(\"geometry.center_px must have two elements [cx, cy].\")\n\n        edge_margin_fraction = float(geometry.get(\"edge_margin_fraction\", 0.9))\n        contact_exclusion_fraction = float(geometry.get(\"contact_exclusion_fraction\", 0.12))\n        if not (0 &lt; edge_margin_fraction &lt;= 1):\n            raise ValueError(\"geometry.edge_margin_fraction must be in (0, 1].\")\n        if not (0 &lt;= contact_exclusion_fraction &lt; 1):\n            raise ValueError(\"geometry.contact_exclusion_fraction must be in [0, 1).\")\n\n        geometry_validated = {\n            \"radius_m\": radius_m,\n            \"center_px\": center_px,\n            \"pixels_per_meter\": pixels_per_meter,\n            \"edge_margin_fraction\": edge_margin_fraction,\n            \"contact_exclusion_fraction\": contact_exclusion_fraction,\n        }\n    else:\n        for key in (\"gauge_roi_px\", \"coupon_width_m\"):\n            if key not in geometry:\n                raise ValueError(f\"geometry must include '{key}' for method='coupon_test'.\")\n\n        gauge_roi_px = np.asarray(geometry[\"gauge_roi_px\"], dtype=int)\n        if gauge_roi_px.size != 4:\n            raise ValueError(\"geometry.gauge_roi_px must be [x0, x1, y0, y1].\")\n        x0, x1, y0, y1 = [int(v) for v in gauge_roi_px]\n        if x0 &gt;= x1 or y0 &gt;= y1:\n            raise ValueError(\"geometry.gauge_roi_px must satisfy x0&lt;x1 and y0&lt;y1.\")\n\n        coupon_width_m = float(geometry[\"coupon_width_m\"])\n        if coupon_width_m &lt;= 0:\n            raise ValueError(\"geometry.coupon_width_m must be positive.\")\n\n        load_axis = str(geometry.get(\"load_axis\", \"x\")).lower()\n        if load_axis not in {\"x\", \"y\"}:\n            raise ValueError(\"geometry.load_axis must be 'x' or 'y'.\")\n\n        transverse_stress_ratio = float(geometry.get(\"transverse_stress_ratio\", 0.0))\n        if not (-1.0 &lt;= transverse_stress_ratio &lt;= 1.0):\n            raise ValueError(\"geometry.transverse_stress_ratio must be in [-1, 1].\")\n\n        roi_margin_px = int(geometry.get(\"roi_margin_px\", 0))\n        if roi_margin_px &lt; 0:\n            raise ValueError(\"geometry.roi_margin_px must be &gt;= 0.\")\n\n        geometry_validated = {\n            \"gauge_roi_px\": np.array([x0, x1, y0, y1], dtype=int),\n            \"coupon_width_m\": coupon_width_m,\n            \"load_axis\": load_axis,\n            \"transverse_stress_ratio\": transverse_stress_ratio,\n            \"roi_margin_px\": roi_margin_px,\n        }\n\n    load_steps = list(config.get(\"load_steps\", []))\n    if len(load_steps) &lt; 4:\n        raise ValueError(\"Calibration requires at least 4 load_steps (including no-load).\")\n\n    normalised_steps = []\n    for step in load_steps:\n        if \"image_file\" not in step or \"load\" not in step:\n            raise ValueError(\"Each load step must include 'image_file' and 'load'.\")\n        image_file = step[\"image_file\"]\n        if not os.path.exists(image_file):\n            raise ValueError(f\"Calibration load-step image not found: {image_file}\")\n        normalised_steps.append({\"image_file\": image_file, \"load\": float(step[\"load\"])})\n\n    load_zero_tolerance = float(config.get(\"load_zero_tolerance\", 1e-9))\n    n_no_load = sum(abs(step[\"load\"]) &lt;= load_zero_tolerance for step in normalised_steps)\n    n_loaded = sum(abs(step[\"load\"]) &gt; load_zero_tolerance for step in normalised_steps)\n    if n_no_load &lt; 1:\n        raise ValueError(\"Calibration requires at least one no-load step (load \u2248 0).\")\n    if n_loaded &lt; 3:\n        raise ValueError(\"Calibration requires at least three non-zero load steps.\")\n\n    fit_cfg = dict(config.get(\"fit\", {}))\n    fit_cfg.setdefault(\"max_points\", 6000)\n    fit_cfg.setdefault(\"loss\", \"soft_l1\")\n    fit_cfg.setdefault(\"f_scale\", 0.05)\n    fit_cfg.setdefault(\"max_nfev\", 300)\n    fit_cfg.setdefault(\"seed\", 0)\n    fit_cfg.setdefault(\"s3_identifiability_threshold\", 0.02)\n    fit_cfg.setdefault(\"prior_weight\", 0.0)\n\n    output_profile = config.get(\"output_profile\", \"calibration_profile.json5\")\n    output_report = config.get(\"output_report\", \"calibration_report.md\")\n    output_diagnostics = config.get(\"output_diagnostics\", \"calibration_diagnostics.npz\")\n\n    validated = {\n        \"method\": method,\n        \"wavelengths\": wavelengths,\n        \"thickness\": thickness,\n        \"nu\": float(config.get(\"nu\", 1.0)),\n        \"geometry\": geometry_validated,\n        \"load_steps\": normalised_steps,\n        \"load_zero_tolerance\": load_zero_tolerance,\n        \"dark_frame_file\": config.get(\"dark_frame_file\"),\n        \"blank_frame_file\": config.get(\"blank_frame_file\"),\n        \"fit\": fit_cfg,\n        \"output_profile\": output_profile,\n        \"output_report\": output_report,\n        \"output_diagnostics\": output_diagnostics,\n        \"provenance\": dict(config.get(\"provenance\", {})),\n    }\n\n    return validated\n</code></pre>"},{"location":"reference/calibrate/#photoelastimetry.calibrate.interactive_geometry_wizard","title":"<code>interactive_geometry_wizard(config)</code>","text":"<p>Interactively pick geometry from the first load-step image.</p> <ul> <li>brazilian_disk: click center, then one edge point on the disk.</li> <li>coupon_test: click top-left then bottom-right gauge ROI corners.</li> </ul> Source code in <code>photoelastimetry/calibrate.py</code> <pre><code>def interactive_geometry_wizard(config):\n    \"\"\"\n    Interactively pick geometry from the first load-step image.\n\n    - brazilian_disk: click center, then one edge point on the disk.\n    - coupon_test: click top-left then bottom-right gauge ROI corners.\n    \"\"\"\n    method = config.get(\"method\", \"brazilian_disk\")\n    if method not in {\"brazilian_disk\", \"coupon_test\"}:\n        raise ValueError(f\"Unsupported method='{method}' for interactive wizard.\")\n\n    steps = list(config.get(\"load_steps\", []))\n    if len(steps) == 0:\n        raise ValueError(\"Interactive wizard requires at least one load step.\")\n    first_image = steps[0].get(\"image_file\")\n    if first_image is None:\n        raise ValueError(\"First load step must include 'image_file'.\")\n    if not os.path.exists(first_image):\n        raise ValueError(f\"Load-step image not found: {first_image}\")\n\n    # Use the same preprocessing path as calibration dataset construction so\n    # interactive geometry coordinates match model coordinates exactly.\n    data = _load_and_validate_image(first_image, expected_shape=None)\n    preview = _build_preview_image(data)\n\n    import matplotlib.pyplot as plt\n\n    cfg = deepcopy(config)\n    geometry = dict(cfg.get(\"geometry\", {}))\n\n    fig, ax = plt.subplots(figsize=(9, 7))\n    fig.subplots_adjust(bottom=0.16)\n    ax.imshow(preview, cmap=\"gray\")\n    ax.set_title(\"Calibration Geometry Wizard\")\n    ax.set_axis_off()\n    if method == \"brazilian_disk\":\n        from matplotlib.patches import Circle\n        from matplotlib.widgets import Button\n\n        ppm = geometry.get(\"pixels_per_meter\")\n        if ppm is None:\n            raise ValueError(\n                \"geometry.pixels_per_meter is required for interactive disk calibration to convert pixels to meters.\"\n            )\n        ppm = float(ppm)\n        if ppm &lt;= 0:\n            raise ValueError(\"geometry.pixels_per_meter must be positive.\")\n        instruction = ax.text(\n            0.01,\n            0.99,\n            \"Left-click circumference points (&gt;=3). Right-click to undo.\\nClick Done when the overlay circle matches.\",\n            transform=ax.transAxes,\n            va=\"top\",\n            ha=\"left\",\n            fontsize=9,\n            color=\"white\",\n            bbox={\"facecolor\": \"black\", \"alpha\": 0.45, \"pad\": 4},\n        )\n        _ = instruction\n\n        points = []\n        point_scatter = ax.scatter([], [], c=\"yellow\", s=24)\n        circle_patch = Circle((0, 0), radius=1.0, fill=False, edgecolor=\"cyan\", linewidth=2, visible=False)\n        ax.add_patch(circle_patch)\n        roi_contour = None\n        fit_text = ax.text(\n            0.01,\n            0.05,\n            \"\",\n            transform=ax.transAxes,\n            va=\"bottom\",\n            ha=\"left\",\n            fontsize=9,\n            color=\"white\",\n            bbox={\"facecolor\": \"black\", \"alpha\": 0.45, \"pad\": 3},\n        )\n\n        state = {\"accepted\": False, \"fit\": None}\n\n        def _update_overlay():\n            nonlocal roi_contour\n            if len(points) == 0:\n                point_scatter.set_offsets(np.empty((0, 2)))\n            else:\n                point_scatter.set_offsets(np.asarray(points, dtype=float))\n            if len(points) &gt;= 3:\n                try:\n                    cx, cy, radius_px = _fit_circle_from_points(points)\n                    circle_patch.center = (cx, cy)\n                    circle_patch.radius = radius_px\n                    circle_patch.set_visible(True)\n                    geom_candidate = {\n                        \"radius_m\": radius_px / ppm,\n                        \"center_px\": np.array([cx, cy], dtype=float),\n                        \"pixels_per_meter\": ppm,\n                        \"edge_margin_fraction\": float(geometry.get(\"edge_margin_fraction\", 0.9)),\n                        \"contact_exclusion_fraction\": float(geometry.get(\"contact_exclusion_fraction\", 0.12)),\n                    }\n                    roi_pixels = _disk_roi_pixel_count(preview.shape[0], preview.shape[1], geom_candidate)\n                    fit_text.set_text(\n                        f\"n={len(points)}  center=({cx:.1f}, {cy:.1f})  radius={radius_px:.1f}px  roi_pixels={roi_pixels}\"\n                    )\n                    state[\"fit\"] = (cx, cy, radius_px, roi_pixels)\n\n                    if roi_contour is not None:\n                        for coll in roi_contour.collections:\n                            coll.remove()\n                    _, _, _, roi_mask = _build_disk_coordinates(\n                        preview.shape[0], preview.shape[1], geom_candidate\n                    )\n                    roi_contour = ax.contour(\n                        roi_mask.astype(float), levels=[0.5], colors=\"lime\", linewidths=1.0\n                    )\n                except ValueError as exc:\n                    circle_patch.set_visible(False)\n                    fit_text.set_text(str(exc))\n                    state[\"fit\"] = None\n                    if roi_contour is not None:\n                        for coll in roi_contour.collections:\n                            coll.remove()\n                        roi_contour = None\n            else:\n                circle_patch.set_visible(False)\n                fit_text.set_text(\"Need at least 3 points.\")\n                state[\"fit\"] = None\n                if roi_contour is not None:\n                    for coll in roi_contour.collections:\n                        coll.remove()\n                    roi_contour = None\n            fig.canvas.draw_idle()\n\n        def _on_click(event):\n            if event.inaxes != ax or event.xdata is None or event.ydata is None:\n                return\n            if event.button == 1:\n                points.append((float(event.xdata), float(event.ydata)))\n            elif event.button == 3 and len(points) &gt; 0:\n                points.pop()\n            else:\n                return\n            _update_overlay()\n\n        def _on_done(_event):\n            if state[\"fit\"] is None:\n                fit_text.set_text(\"Need a valid circle fit before Done.\")\n                fig.canvas.draw_idle()\n                return\n            if state[\"fit\"][3] &lt;= 0:\n                fit_text.set_text(\"ROI is empty for this circle. Add/adjust circumference points.\")\n                fig.canvas.draw_idle()\n                return\n            state[\"accepted\"] = True\n            plt.close(fig)\n\n        def _on_reset(_event):\n            points.clear()\n            _update_overlay()\n\n        done_ax = fig.add_axes([0.80, 0.03, 0.16, 0.07])\n        done_btn = Button(done_ax, \"Done\")\n        done_btn.on_clicked(_on_done)\n\n        reset_ax = fig.add_axes([0.62, 0.03, 0.16, 0.07])\n        reset_btn = Button(reset_ax, \"Reset\")\n        reset_btn.on_clicked(_on_reset)\n\n        fig.canvas.mpl_connect(\"button_press_event\", _on_click)\n        _update_overlay()\n        plt.show()\n\n        if not state[\"accepted\"] or state[\"fit\"] is None:\n            raise ValueError(\"Interactive selection canceled. Circle was not accepted.\")\n\n        cx, cy, radius_px, _roi_pixels = state[\"fit\"]\n        geometry[\"center_px\"] = [cx, cy]\n        geometry[\"radius_m\"] = radius_px / ppm\n    else:\n        points = plt.ginput(2, timeout=0)\n        plt.close(fig)\n        if len(points) != 2:\n            raise ValueError(\"Interactive selection canceled. Please provide exactly two clicks.\")\n        (x0, y0), (x1, y1) = points\n        xa, xb = sorted([int(round(x0)), int(round(x1))])\n        ya, yb = sorted([int(round(y0)), int(round(y1))])\n        if xa == xb or ya == yb:\n            raise ValueError(\"Selected ROI must have non-zero width and height.\")\n        geometry[\"gauge_roi_px\"] = [xa, xb, ya, yb]\n\n    cfg[\"geometry\"] = geometry\n    return cfg\n</code></pre>"},{"location":"reference/calibrate/#photoelastimetry.calibrate.calibration_residuals","title":"<code>calibration_residuals(params, dataset, fixed_s3=None)</code>","text":"<p>Compute calibration residuals for least-squares fitting.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>ndarray</code> <p>Parameter vector containing C values and S_i_hat components.</p> required <code>dataset</code> <code>dict</code> <p>Dataset dictionary from <code>_build_dataset</code>.</p> required <code>fixed_s3</code> <code>float</code> <p>If provided, S3 is fixed and only S1/S2 are optimised.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>1D residual vector.</p> Source code in <code>photoelastimetry/calibrate.py</code> <pre><code>def calibration_residuals(params, dataset, fixed_s3=None):\n    \"\"\"\n    Compute calibration residuals for least-squares fitting.\n\n    Parameters\n    ----------\n    params : ndarray\n        Parameter vector containing C values and S_i_hat components.\n    dataset : dict\n        Dataset dictionary from `_build_dataset`.\n    fixed_s3 : float, optional\n        If provided, S3 is fixed and only S1/S2 are optimised.\n\n    Returns\n    -------\n    ndarray\n        1D residual vector.\n    \"\"\"\n    wavelengths = dataset[\"wavelengths\"]\n    n_channels = wavelengths.size\n    C, s_i_hat = _decode_params(params, n_channels, fixed_s3=fixed_s3)\n\n    residual_chunks = []\n    for measured, sigma_xx, sigma_yy, sigma_xy in zip(\n        dataset[\"measured_steps\"],\n        dataset[\"sigma_xx_steps\"],\n        dataset[\"sigma_yy_steps\"],\n        dataset[\"sigma_xy_steps\"],\n    ):\n        for c, wl in enumerate(wavelengths):\n            pred = predict_stokes(\n                sigma_xx,\n                sigma_yy,\n                sigma_xy,\n                C[c],\n                dataset[\"nu\"],\n                dataset[\"thickness\"],\n                wl,\n                s_i_hat,\n            )\n            residual_chunks.append((pred - measured[:, c, :]).ravel())\n\n    if len(residual_chunks) == 0:\n        return np.zeros(1, dtype=float)\n\n    return np.concatenate(residual_chunks, axis=0)\n</code></pre>"},{"location":"reference/calibrate/#photoelastimetry.calibrate.fit_calibration_parameters","title":"<code>fit_calibration_parameters(dataset, fit_config)</code>","text":"<p>Fit C and S_i_hat from calibration dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>dict</code> <p>Dataset dictionary from <code>_build_dataset</code>.</p> required <code>fit_config</code> <code>dict</code> <p>Fitting options.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Fit results containing estimated C, S_i_hat, metrics, and optimizer state.</p> Source code in <code>photoelastimetry/calibrate.py</code> <pre><code>def fit_calibration_parameters(dataset, fit_config):\n    \"\"\"\n    Fit C and S_i_hat from calibration dataset.\n\n    Parameters\n    ----------\n    dataset : dict\n        Dataset dictionary from `_build_dataset`.\n    fit_config : dict\n        Fitting options.\n\n    Returns\n    -------\n    dict\n        Fit results containing estimated C, S_i_hat, metrics, and optimizer state.\n    \"\"\"\n    wavelengths = dataset[\"wavelengths\"]\n    n_channels = wavelengths.size\n\n    init_c = _as_float_array(\n        fit_config.get(\"initial_C\", np.full(n_channels, 3e-9)), expected_length=n_channels, name=\"initial_C\"\n    )\n    init_s = np.asarray(fit_config.get(\"initial_S_i_hat\", dataset[\"initial_s_i_hat\"]), dtype=float)\n    if init_s.size == 2:\n        init_s = np.append(init_s, 0.0)\n    if init_s.size != 3:\n        raise ValueError(f\"fit.initial_S_i_hat must have length 2 or 3, got {init_s.size}.\")\n\n    init_s = _normalise_s_i_hat(init_s)\n\n    c_relative_bounds = fit_config.get(\"c_relative_bounds\")\n    if c_relative_bounds is not None:\n        if len(c_relative_bounds) != 2:\n            raise ValueError(\"fit.c_relative_bounds must be [lower_factor, upper_factor].\")\n        lower_factor = float(c_relative_bounds[0])\n        upper_factor = float(c_relative_bounds[1])\n        if lower_factor &lt;= 0 or upper_factor &lt;= 0 or lower_factor &gt;= upper_factor:\n            raise ValueError(\"fit.c_relative_bounds factors must satisfy 0 &lt; lower &lt; upper.\")\n        c_lower = np.maximum(init_c * lower_factor, 1e-15)\n        c_upper = np.maximum(init_c * upper_factor, c_lower + 1e-15)\n    else:\n        c_lower = np.full(n_channels, 1e-15)\n        c_upper = np.full(n_channels, 1e-4)\n\n    x0_full = np.concatenate([init_c, init_s], axis=0)\n    lb_full = np.concatenate([c_lower, np.full(3, -1.0)])\n    ub_full = np.concatenate([c_upper, np.full(3, 1.0)])\n    prior_weight = float(fit_config.get(\"prior_weight\", 0.0))\n\n    def residual_full(params):\n        residual = calibration_residuals(params, dataset, fixed_s3=None)\n        if prior_weight &gt; 0:\n            prior = prior_weight * (params - x0_full)\n            return np.concatenate([residual, prior], axis=0)\n        return residual\n\n    result_full = least_squares(\n        residual_full,\n        x0_full,\n        bounds=(lb_full, ub_full),\n        loss=fit_config[\"loss\"],\n        f_scale=float(fit_config[\"f_scale\"]),\n        max_nfev=int(fit_config[\"max_nfev\"]),\n    )\n\n    col_norms = (\n        np.linalg.norm(result_full.jac, axis=0) if result_full.jac.size &gt; 0 else np.zeros_like(x0_full)\n    )\n    reference_norm = np.median(col_norms[:-1]) if col_norms.size &gt; 1 else 0.0\n    s3_ratio = float(col_norms[-1] / max(reference_norm, 1e-12)) if col_norms.size &gt; 0 else 0.0\n\n    fallback = False\n    fallback_reason = None\n    threshold = float(fit_config.get(\"s3_identifiability_threshold\", 0.02))\n\n    if (not result_full.success) or (s3_ratio &lt; threshold):\n        fallback = True\n        fallback_reason = \"s3_identifiability\" if s3_ratio &lt; threshold else \"full_fit_failed\"\n\n        if fallback_reason == \"s3_identifiability\":\n            # If S3 is unidentifiable, restart fixed-S3 fit from the configured\n            # initial guess to avoid inheriting unstable full-model updates.\n            x0_fix = np.concatenate([init_c, init_s[:2]], axis=0)\n        else:\n            c_guess, s_guess = _decode_params(result_full.x, n_channels, fixed_s3=None)\n            x0_fix = np.concatenate([c_guess, s_guess[:2]], axis=0)\n        lb_fix = np.concatenate([c_lower, np.full(2, -1.0)])\n        ub_fix = np.concatenate([c_upper, np.full(2, 1.0)])\n\n        def residual_fixed(params):\n            residual = calibration_residuals(params, dataset, fixed_s3=0.0)\n            if prior_weight &gt; 0:\n                prior = prior_weight * (params - x0_fix)\n                return np.concatenate([residual, prior], axis=0)\n            return residual\n\n        result = least_squares(\n            residual_fixed,\n            x0_fix,\n            bounds=(lb_fix, ub_fix),\n            loss=fit_config[\"loss\"],\n            f_scale=float(fit_config[\"f_scale\"]),\n            max_nfev=int(fit_config[\"max_nfev\"]),\n        )\n        C_fit, S_fit = _decode_params(result.x, n_channels, fixed_s3=0.0)\n    else:\n        result = result_full\n        C_fit, S_fit = _decode_params(result.x, n_channels, fixed_s3=None)\n\n    residual = result.fun\n    fit_metrics = {\n        \"success\": bool(result.success),\n        \"status\": int(result.status),\n        \"message\": str(result.message),\n        \"cost\": float(result.cost),\n        \"rmse\": float(np.sqrt(np.mean(residual**2))),\n        \"mae\": float(np.mean(np.abs(residual))),\n        \"n_residuals\": int(residual.size),\n        \"n_samples\": int(dataset[\"sample_y\"].size),\n        \"n_load_steps\": int(dataset[\"loads\"].size),\n        \"fallback_used\": bool(fallback),\n        \"fallback_reason\": fallback_reason,\n        \"s3_identifiability_ratio\": float(s3_ratio),\n    }\n\n    return {\n        \"C\": C_fit,\n        \"S_i_hat\": S_fit,\n        \"fit_metrics\": fit_metrics,\n        \"optimizer_result\": result,\n    }\n</code></pre>"},{"location":"reference/calibrate/#photoelastimetry.calibrate.run_calibration","title":"<code>run_calibration(config)</code>","text":"<p>Run full calibration workflow from config.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Calibration input configuration.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Result dictionary containing the calibration profile and metadata.</p> Source code in <code>photoelastimetry/calibrate.py</code> <pre><code>def run_calibration(config):\n    \"\"\"\n    Run full calibration workflow from config.\n\n    Parameters\n    ----------\n    config : dict\n        Calibration input configuration.\n\n    Returns\n    -------\n    dict\n        Result dictionary containing the calibration profile and metadata.\n    \"\"\"\n    cfg = validate_calibration_config(config)\n    dataset = _build_dataset(cfg)\n    fit_result = fit_calibration_parameters(dataset, cfg[\"fit\"])\n\n    output_profile = cfg[\"output_profile\"]\n    output_report = cfg[\"output_report\"]\n    output_diagnostics = cfg[\"output_diagnostics\"]\n    report_root, report_ext = os.path.splitext(output_report)\n    output_diagnostics_plot = f\"{report_root}_fit.png\" if report_ext else f\"{output_report}_fit.png\"\n\n    output_dir = os.path.dirname(output_profile)\n    if output_dir:\n        os.makedirs(output_dir, exist_ok=True)\n\n    for path in (output_report, output_diagnostics, output_diagnostics_plot):\n        folder = os.path.dirname(path)\n        if folder:\n            os.makedirs(folder, exist_ok=True)\n\n    profile_dir = os.path.dirname(output_profile) if os.path.dirname(output_profile) else os.getcwd()\n\n    provenance_steps = [\n        {\n            \"load\": float(step[\"load\"]),\n            \"image_file\": _safe_relative_path(step[\"image_file\"], profile_dir),\n        }\n        for step in cfg[\"load_steps\"]\n    ]\n\n    provenance = {\n        \"generated_utc\": datetime.now(timezone.utc).isoformat(),\n        \"dark_frame_file\": _safe_relative_path(cfg[\"dark_frame_file\"], profile_dir),\n        \"blank_frame_file\": _safe_relative_path(cfg[\"blank_frame_file\"], profile_dir),\n        \"load_steps\": provenance_steps,\n        \"diagnostics_file\": _safe_relative_path(output_diagnostics, profile_dir),\n        \"diagnostics_plot_file\": _safe_relative_path(output_diagnostics_plot, profile_dir),\n    }\n    provenance.update(cfg[\"provenance\"])\n\n    profile = {\n        \"version\": 1,\n        \"method\": cfg[\"method\"],\n        \"wavelengths\": cfg[\"wavelengths\"].tolist(),\n        \"C\": fit_result[\"C\"].tolist(),\n        \"S_i_hat\": fit_result[\"S_i_hat\"].tolist(),\n        \"blank_correction\": dataset[\"blank_correction\"],\n        \"fit_metrics\": fit_result[\"fit_metrics\"],\n        \"provenance\": provenance,\n    }\n\n    with open(output_profile, \"w\") as f:\n        json.dump(profile, f, indent=2)\n\n    _write_visual_diagnostics_plot(output_diagnostics_plot, dataset, fit_result)\n    _write_report(output_report, profile, cfg)\n    visual_maps = _build_visual_diagnostics(dataset, fit_result)\n\n    np.savez(\n        output_diagnostics,\n        roi_mask=dataset[\"roi_mask\"],\n        model_mask=dataset[\"model_mask\"],\n        disk_mask=dataset[\"disk_mask\"],\n        sample_y=dataset[\"sample_y\"],\n        sample_x=dataset[\"sample_x\"],\n        loads=dataset[\"loads\"],\n        C=np.asarray(profile[\"C\"], dtype=float),\n        S_i_hat=np.asarray(profile[\"S_i_hat\"], dtype=float),\n        residual=fit_result[\"optimizer_result\"].fun,\n        diagnostic_channel=np.array([visual_maps[\"channel\"]], dtype=int),\n        measured_i0=visual_maps[\"measured_i0\"],\n        predicted_i0=visual_maps[\"predicted_i0\"],\n        i0_residual_abs=visual_maps[\"i0_residual_abs\"],\n        measured_s1=visual_maps[\"measured_s1\"],\n        predicted_s1=visual_maps[\"predicted_s1\"],\n        stokes_residual_mag=visual_maps[\"stokes_residual_mag\"],\n    )\n\n    return {\n        \"profile\": profile,\n        \"profile_file\": output_profile,\n        \"report_file\": output_report,\n        \"diagnostics_file\": output_diagnostics,\n        \"diagnostics_plot_file\": output_diagnostics_plot,\n    }\n</code></pre>"},{"location":"reference/image/","title":"image","text":"<p>Image processing and Mueller matrix operations.</p> <p>This module provides core image processing functions including Mueller matrix calculations, retardance computation, and principal angle extraction for photoelastic analysis.</p>"},{"location":"reference/image/#photoelastimetry.image","title":"<code>image</code>","text":"<p>Image processing and photoelastic forward model functions.</p> <p>This module contains helper functions for polarimetric image analysis and photoelastic forward modeling, including stress-to-optical transformations.</p>"},{"location":"reference/image/#photoelastimetry.image-functions","title":"Functions","text":""},{"location":"reference/image/#photoelastimetry.image.DoLP","title":"<code>DoLP(image)</code>","text":"<p>Calculate the Degree of Linear Polarisation (DoLP).</p> Source code in <code>photoelastimetry/image.py</code> <pre><code>def DoLP(image):\n    \"\"\"\n    Calculate the Degree of Linear Polarisation (DoLP).\n    \"\"\"\n    I = np.sum(image, axis=3)  # total intensity ovr all polarisation states\n\n    Q = image[:, :, :, 0] - image[:, :, :, 1]  # 0/90 difference\n    U = image[:, :, :, 2] - image[:, :, :, 3]  # 45/135 difference\n\n    return np.sqrt(Q**2 + U**2) / I\n</code></pre>"},{"location":"reference/image/#photoelastimetry.image.AoLP","title":"<code>AoLP(image)</code>","text":"<p>Calculate the Angle of Linear Polarisation (AoLP).</p> Source code in <code>photoelastimetry/image.py</code> <pre><code>def AoLP(image):\n    \"\"\"\n    Calculate the Angle of Linear Polarisation (AoLP).\n    \"\"\"\n\n    Q = image[:, :, :, 0] - image[:, :, :, 1]  # 0/90 difference\n    U = image[:, :, :, 2] - image[:, :, :, 3]  # 45/135 difference\n\n    return 0.5 * np.arctan2(U, Q)\n</code></pre>"},{"location":"reference/image/#photoelastimetry.image.compute_retardance","title":"<code>compute_retardance(sigma_xx, sigma_yy, sigma_xy, C, nu, L, wavelength)</code>","text":"<p>Compute retardance for a given stress tensor and material properties.</p> <p>Parameters:</p> Name Type Description Default <code>sigma_xx</code> <code>float or array - like</code> <p>Normal stress component in x direction (Pa).</p> required <code>sigma_yy</code> <code>float or array - like</code> <p>Normal stress component in y direction (Pa).</p> required <code>sigma_xy</code> <code>float or array - like</code> <p>Shear stress component (Pa).</p> required <code>C</code> <code>float</code> <p>Stress-optic coefficient for the colour channel (1/Pa).</p> required <code>nu</code> <code>float</code> <p>Solid fraction (dimensionless). For solid samples, use nu=1.0. For porous samples, this represents the effective optical path length factor relative to sample thickness.</p> required <code>L</code> <code>float</code> <p>Sample thickness (m).</p> required <code>wavelength</code> <code>float</code> <p>Wavelength of light (m).</p> required <p>Returns:</p> Name Type Description <code>delta</code> <code>float or array - like</code> <p>Retardance (radians).</p> Notes <p>The retardance formula is: \u03b4 = (2\u03c0CnL/\u03bb) * \u221a[(\u03c3_xx - \u03c3_yy)\u00b2 + 4\u03c3_xy\u00b2] where the principal stress difference determines the birefringence magnitude.</p> Source code in <code>photoelastimetry/image.py</code> <pre><code>def compute_retardance(sigma_xx, sigma_yy, sigma_xy, C, nu, L, wavelength):\n    \"\"\"\n    Compute retardance for a given stress tensor and material properties.\n\n    Parameters\n    ----------\n    sigma_xx : float or array-like\n        Normal stress component in x direction (Pa).\n    sigma_yy : float or array-like\n        Normal stress component in y direction (Pa).\n    sigma_xy : float or array-like\n        Shear stress component (Pa).\n    C : float\n        Stress-optic coefficient for the colour channel (1/Pa).\n    nu : float\n        Solid fraction (dimensionless).\n        For solid samples, use nu=1.0. For porous samples, this represents\n        the effective optical path length factor relative to sample thickness.\n    L : float\n        Sample thickness (m).\n    wavelength : float\n        Wavelength of light (m).\n\n    Returns\n    -------\n    delta : float or array-like\n        Retardance (radians).\n\n    Notes\n    -----\n    The retardance formula is: \u03b4 = (2\u03c0CnL/\u03bb) * \u221a[(\u03c3_xx - \u03c3_yy)\u00b2 + 4\u03c3_xy\u00b2]\n    where the principal stress difference determines the birefringence magnitude.\n    \"\"\"\n    principal_stress_diff = np.sqrt((sigma_xx - sigma_yy) ** 2 + 4 * sigma_xy**2)\n    delta = (2 * np.pi * C * nu * L / wavelength) * principal_stress_diff\n    return delta\n</code></pre>"},{"location":"reference/image/#photoelastimetry.image.compute_principal_angle","title":"<code>compute_principal_angle(sigma_xx, sigma_yy, sigma_xy)</code>","text":"<p>Compute the orientation angle of the principal stress direction.</p> <p>Parameters:</p> Name Type Description Default <code>sigma_xx</code> <code>float or array - like</code> <p>Normal stress component in x direction (Pa).</p> required <code>sigma_yy</code> <code>float or array - like</code> <p>Normal stress component in y direction (Pa).</p> required <code>sigma_xy</code> <code>float or array - like</code> <p>Shear stress component (Pa).</p> required <p>Returns:</p> Name Type Description <code>theta</code> <code>float or array - like</code> <p>Principal stress orientation angle (radians).</p> Notes <p>In photoelasticity, the fast axis aligns with the maximum compressive stress direction. This formula gives the angle to the maximum tensile stress (\u03c3_max).</p> Source code in <code>photoelastimetry/image.py</code> <pre><code>def compute_principal_angle(sigma_xx, sigma_yy, sigma_xy):\n    \"\"\"\n    Compute the orientation angle of the principal stress direction.\n\n    Parameters\n    ----------\n    sigma_xx : float or array-like\n        Normal stress component in x direction (Pa).\n    sigma_yy : float or array-like\n        Normal stress component in y direction (Pa).\n    sigma_xy : float or array-like\n        Shear stress component (Pa).\n\n    Returns\n    -------\n    theta : float or array-like\n        Principal stress orientation angle (radians).\n\n    Notes\n    -----\n    In photoelasticity, the fast axis aligns with the maximum compressive\n    stress direction. This formula gives the angle to the maximum tensile\n    stress (\u03c3_max).\n    \"\"\"\n    theta = 0.5 * np.arctan2(2 * sigma_xy, sigma_xx - sigma_yy)\n    return theta\n</code></pre>"},{"location":"reference/image/#photoelastimetry.image.mueller_matrix","title":"<code>mueller_matrix(theta, delta)</code>","text":"<p>Compute the Mueller matrix for a birefringent material.</p> <p>Parameters:</p> Name Type Description Default <code>theta</code> <code>float or array - like</code> <p>Orientation angle of principal stress direction (radians).</p> required <code>delta</code> <code>float or array - like</code> <p>Retardance (radians).</p> required <p>Returns:</p> Name Type Description <code>M</code> <code>ndarray</code> <p>Mueller matrix (4x4) for scalar inputs, or (..., 4, 4) for array inputs.</p> Source code in <code>photoelastimetry/image.py</code> <pre><code>def mueller_matrix(theta, delta):\n    \"\"\"\n    Compute the Mueller matrix for a birefringent material.\n\n    Parameters\n    ----------\n    theta : float or array-like\n        Orientation angle of principal stress direction (radians).\n    delta : float or array-like\n        Retardance (radians).\n\n    Returns\n    -------\n    M : ndarray\n        Mueller matrix (4x4) for scalar inputs, or (..., 4, 4) for array inputs.\n    \"\"\"\n    cos_2theta = np.cos(2 * theta)\n    sin_2theta = np.sin(2 * theta)\n    cos_delta = np.cos(delta)\n    sin_delta = np.sin(delta)\n\n    # Handle scalar vs array inputs\n    if np.isscalar(theta) and np.isscalar(delta):\n        M = np.array(\n            [\n                [1, 0, 0, 0],\n                [\n                    0,\n                    cos_2theta**2 + sin_2theta**2 * cos_delta,\n                    cos_2theta * sin_2theta * (1 - cos_delta),\n                    sin_2theta * sin_delta,\n                ],\n                [\n                    0,\n                    cos_2theta * sin_2theta * (1 - cos_delta),\n                    cos_2theta**2 * cos_delta + sin_2theta**2,\n                    -cos_2theta * sin_delta,\n                ],\n                [0, -sin_2theta * sin_delta, cos_2theta * sin_delta, cos_delta],\n            ]\n        )\n    else:\n        # Array case - build matrix with proper shape (..., 4, 4)\n        shape = np.broadcast(theta, delta).shape\n        M = np.zeros(shape + (4, 4))\n\n        M[..., 0, 0] = 1\n        M[..., 1, 1] = cos_2theta**2 + sin_2theta**2 * cos_delta\n        M[..., 1, 2] = cos_2theta * sin_2theta * (1 - cos_delta)\n        M[..., 1, 3] = sin_2theta * sin_delta\n        M[..., 2, 1] = cos_2theta * sin_2theta * (1 - cos_delta)\n        M[..., 2, 2] = cos_2theta**2 * cos_delta + sin_2theta**2\n        M[..., 2, 3] = -cos_2theta * sin_delta\n        M[..., 3, 1] = -sin_2theta * sin_delta\n        M[..., 3, 2] = cos_2theta * sin_delta\n        M[..., 3, 3] = cos_delta\n\n    return M\n</code></pre>"},{"location":"reference/image/#photoelastimetry.image.mueller_matrix_sensitivity","title":"<code>mueller_matrix_sensitivity(theta, delta)</code>","text":"<p>Compute derivatives of Mueller matrix elements with respect to theta and delta.</p> <p>Returns:</p> Name Type Description <code>dM_dtheta</code> <code>ndarray(..., 4, 4)</code> <code>dM_ddelta</code> <code>ndarray(..., 4, 4)</code> Source code in <code>photoelastimetry/image.py</code> <pre><code>def mueller_matrix_sensitivity(theta, delta):\n    \"\"\"\n    Compute derivatives of Mueller matrix elements with respect to theta and delta.\n\n    Returns\n    -------\n    dM_dtheta : ndarray (..., 4, 4)\n    dM_ddelta : ndarray (..., 4, 4)\n    \"\"\"\n    c2 = np.cos(2 * theta)\n    s2 = np.sin(2 * theta)\n    cd = np.cos(delta)\n    sd = np.sin(delta)\n\n    # Helper for 2*theta derivatives: d(c2)=-2s2, d(s2)=2c2\n    dc2 = -2 * s2\n    ds2 = 2 * c2\n\n    shape = np.broadcast(theta, delta).shape\n    dM_dtheta = np.zeros(shape + (4, 4))\n    dM_ddelta = np.zeros(shape + (4, 4))\n\n    # 0,0 is 1 -&gt; derivs 0\n\n    # 1,1: c2^2 + s2^2*cd\n    dM_dtheta[..., 1, 1] = 2 * c2 * dc2 + 2 * s2 * ds2 * cd\n    dM_ddelta[..., 1, 1] = -(s2**2) * sd\n\n    # 1,2: c2*s2*(1-cd)\n    dM_dtheta[..., 1, 2] = (dc2 * s2 + c2 * ds2) * (1 - cd)\n    dM_ddelta[..., 1, 2] = c2 * s2 * sd\n\n    # 1,3: s2*sd\n    dM_dtheta[..., 1, 3] = ds2 * sd\n    dM_ddelta[..., 1, 3] = s2 * cd\n\n    # 2,1 = 1,2\n    dM_dtheta[..., 2, 1] = dM_dtheta[..., 1, 2]\n    dM_ddelta[..., 2, 1] = dM_ddelta[..., 1, 2]\n\n    # 2,2: c2^2*cd + s2^2\n    dM_dtheta[..., 2, 2] = (2 * c2 * dc2) * cd + 2 * s2 * ds2\n    dM_ddelta[..., 2, 2] = -(c2**2) * sd\n\n    # 2,3: -c2*sd\n    dM_dtheta[..., 2, 3] = -dc2 * sd\n    dM_ddelta[..., 2, 3] = -c2 * cd\n\n    # 3,1: -s2*sd\n    dM_dtheta[..., 3, 1] = -ds2 * sd\n    dM_ddelta[..., 3, 1] = -s2 * cd\n\n    # 3,2: c2*sd\n    dM_dtheta[..., 3, 2] = dc2 * sd\n    dM_ddelta[..., 3, 2] = c2 * cd\n\n    # 3,3: cd\n    dM_dtheta[..., 3, 3] = 0\n    dM_ddelta[..., 3, 3] = -sd\n\n    return dM_dtheta, dM_ddelta\n</code></pre>"},{"location":"reference/image/#photoelastimetry.image.compute_stokes_components","title":"<code>compute_stokes_components(I_0, I_45, I_90, I_135)</code>","text":"<p>Compute the Stokes vector components (S0, S1, S2) from intensity measurements.</p> <p>Parameters:</p> Name Type Description Default <code>I_0</code> <code>array - like</code> <p>Intensity at polariser angle 0 degrees.</p> required <code>I_45</code> <code>array - like</code> <p>Intensity at polariser angle 45 degrees.</p> required <code>I_90</code> <code>array - like</code> <p>Intensity at polariser angle 90 degrees.</p> required <code>I_135</code> <code>array - like</code> <p>Intensity at polariser angle 135 degrees.</p> required <p>Returns:</p> Name Type Description <code>S0</code> <code>array - like</code> <p>Total intensity (sum of orthogonal components).</p> <code>S1</code> <code>array - like</code> <p>Linear polarisation along 0-90 degrees.</p> <code>S2</code> <code>array - like</code> <p>Linear polarisation along 45-135 degrees.</p> Source code in <code>photoelastimetry/image.py</code> <pre><code>def compute_stokes_components(I_0, I_45, I_90, I_135):\n    \"\"\"\n    Compute the Stokes vector components (S0, S1, S2) from intensity measurements.\n\n    Parameters\n    ----------\n    I_0 : array-like\n        Intensity at polariser angle 0 degrees.\n    I_45 : array-like\n        Intensity at polariser angle 45 degrees.\n    I_90 : array-like\n        Intensity at polariser angle 90 degrees.\n    I_135 : array-like\n        Intensity at polariser angle 135 degrees.\n\n    Returns\n    -------\n    S0 : array-like\n        Total intensity (sum of orthogonal components).\n    S1 : array-like\n        Linear polarisation along 0-90 degrees.\n    S2 : array-like\n        Linear polarisation along 45-135 degrees.\n    \"\"\"\n    S0 = I_0 + I_90\n    S1 = I_0 - I_90\n    S2 = I_45 - I_135\n    return S0, S1, S2\n</code></pre>"},{"location":"reference/image/#photoelastimetry.image.compute_normalised_stokes","title":"<code>compute_normalised_stokes(S0, S1, S2)</code>","text":"<p>Compute normalised Stokes vector components.</p> <p>Parameters:</p> Name Type Description Default <code>S0</code> <code>array - like</code> <p>Total intensity Stokes parameter.</p> required <code>S1</code> <code>array - like</code> <p>First linear polarisation Stokes parameter.</p> required <code>S2</code> <code>array - like</code> <p>Second linear polarisation Stokes parameter.</p> required <p>Returns:</p> Name Type Description <code>S1_hat</code> <code>array - like</code> <p>Normalised S1 component (S1/S0).</p> <code>S2_hat</code> <code>array - like</code> <p>Normalised S2 component (S2/S0).</p> Source code in <code>photoelastimetry/image.py</code> <pre><code>def compute_normalised_stokes(S0, S1, S2):\n    \"\"\"\n    Compute normalised Stokes vector components.\n\n    Parameters\n    ----------\n    S0 : array-like\n        Total intensity Stokes parameter.\n    S1 : array-like\n        First linear polarisation Stokes parameter.\n    S2 : array-like\n        Second linear polarisation Stokes parameter.\n\n    Returns\n    -------\n    S1_hat : array-like\n        Normalised S1 component (S1/S0).\n    S2_hat : array-like\n        Normalised S2 component (S2/S0).\n    \"\"\"\n    S0_safe = np.where(S0 == 0, 1e-10, S0)\n    S1_hat = S1 / S0_safe\n    S2_hat = S2 / S0_safe\n    return S1_hat, S2_hat\n</code></pre>"},{"location":"reference/image/#photoelastimetry.image.predict_stokes","title":"<code>predict_stokes(sigma_xx, sigma_yy, sigma_xy, C, nu, L, wavelength, S_i_hat)</code>","text":"<p>Predict measured normalised Stokes components from a stress state.</p> <p>Parameters:</p> Name Type Description Default <code>sigma_xx</code> <code>float or array - like</code> <p>Stress tensor components (Pa).</p> required <code>sigma_yy</code> <code>float or array - like</code> <p>Stress tensor components (Pa).</p> required <code>sigma_xy</code> <code>float or array - like</code> <p>Stress tensor components (Pa).</p> required <code>C</code> <code>float</code> <p>Stress-optic coefficient (1/Pa).</p> required <code>nu</code> <code>float</code> <p>Solid fraction.</p> required <code>L</code> <code>float</code> <p>Sample thickness (m).</p> required <code>wavelength</code> <code>float</code> <p>Illumination wavelength (m).</p> required <code>S_i_hat</code> <code>array - like</code> <p>Incoming normalised Stokes state [S1_hat, S2_hat] or [S1_hat, S2_hat, S3_hat].</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Predicted measured [S1_hat, S2_hat].</p> Source code in <code>photoelastimetry/image.py</code> <pre><code>def predict_stokes(sigma_xx, sigma_yy, sigma_xy, C, nu, L, wavelength, S_i_hat):\n    \"\"\"\n    Predict measured normalised Stokes components from a stress state.\n\n    Parameters\n    ----------\n    sigma_xx, sigma_yy, sigma_xy : float or array-like\n        Stress tensor components (Pa).\n    C : float\n        Stress-optic coefficient (1/Pa).\n    nu : float\n        Solid fraction.\n    L : float\n        Sample thickness (m).\n    wavelength : float\n        Illumination wavelength (m).\n    S_i_hat : array-like\n        Incoming normalised Stokes state [S1_hat, S2_hat] or [S1_hat, S2_hat, S3_hat].\n\n    Returns\n    -------\n    ndarray\n        Predicted measured [S1_hat, S2_hat].\n    \"\"\"\n    theta = compute_principal_angle(sigma_xx, sigma_yy, sigma_xy)\n    delta = compute_retardance(sigma_xx, sigma_yy, sigma_xy, C, nu, L, wavelength)\n    M = mueller_matrix(theta, delta)\n\n    S_i_hat = np.asarray(S_i_hat)\n    if len(S_i_hat) == 2:\n        S_i_full = np.array([1.0, S_i_hat[0], S_i_hat[1], 0.0])\n    elif len(S_i_hat) == 3:\n        S_i_full = np.array([1.0, S_i_hat[0], S_i_hat[1], S_i_hat[2]])\n    else:\n        raise ValueError(f\"S_i_hat must have length 2 or 3, got {len(S_i_hat)}\")\n\n    if M.ndim == 2:\n        S_m = M @ S_i_full\n        return S_m[1:3]\n\n    S_m = np.einsum(\"...ij,j-&gt;...i\", M, S_i_full)\n    return S_m[..., 1:3]\n</code></pre>"},{"location":"reference/image/#photoelastimetry.image.simulate_four_step_polarimetry","title":"<code>simulate_four_step_polarimetry(sigma_xx, sigma_yy, sigma_xy, C, nu, L, wavelength, S_i_hat, I0=1.0)</code>","text":"<p>Simulate four-step polarimetry using Mueller matrix formalism.</p> <p>Parameters:</p> Name Type Description Default <code>sigma_xx</code> <code>float or array - like</code> <p>Normal stress component in x direction (Pa).</p> required <code>sigma_yy</code> <code>float or array - like</code> <p>Normal stress component in y direction (Pa).</p> required <code>sigma_xy</code> <code>float or array - like</code> <p>Shear stress component (Pa).</p> required <code>C</code> <code>float</code> <p>Stress-optic coefficient (1/Pa).</p> required <code>nu</code> <code>float</code> <p>Solid fraction (use 1.0 for solid samples).</p> required <code>L</code> <code>float</code> <p>Sample thickness (m).</p> required <code>wavelength</code> <code>float</code> <p>Wavelength of light (m).</p> required <code>S_i_hat</code> <code>array - like</code> <p>Incoming normalised Stokes vector [S1_hat, S2_hat] or [S1_hat, S2_hat, S3_hat].</p> required <code>I0</code> <code>float</code> <p>Incident light intensity (default: 1.0).</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Four intensity images for analyzer angles 0\u00b0, 45\u00b0, 90\u00b0, 135\u00b0</code> Source code in <code>photoelastimetry/image.py</code> <pre><code>def simulate_four_step_polarimetry(sigma_xx, sigma_yy, sigma_xy, C, nu, L, wavelength, S_i_hat, I0=1.0):\n    \"\"\"\n    Simulate four-step polarimetry using Mueller matrix formalism.\n\n\n    Parameters\n    ----------\n    sigma_xx : float or array-like\n        Normal stress component in x direction (Pa).\n    sigma_yy : float or array-like\n        Normal stress component in y direction (Pa).\n    sigma_xy : float or array-like\n        Shear stress component (Pa).\n    C : float\n        Stress-optic coefficient (1/Pa).\n    nu : float\n        Solid fraction (use 1.0 for solid samples).\n    L : float\n        Sample thickness (m).\n    wavelength : float\n        Wavelength of light (m).\n    S_i_hat : array-like\n        Incoming normalised Stokes vector [S1_hat, S2_hat] or [S1_hat, S2_hat, S3_hat].\n    I0 : float\n        Incident light intensity (default: 1.0).\n\n    Returns\n    -------\n    Four intensity images for analyzer angles 0\u00b0, 45\u00b0, 90\u00b0, 135\u00b0\n    \"\"\"\n    # Compute retardance and principal angle from stress tensor\n    theta = compute_principal_angle(sigma_xx, sigma_yy, sigma_xy)\n    delta = compute_retardance(sigma_xx, sigma_yy, sigma_xy, C, nu, L, wavelength)\n\n    # Get Mueller matrix\n    M = mueller_matrix(theta, delta)\n    # Create full incoming Stokes vector\n    S_i_hat = np.asarray(S_i_hat)\n    if len(S_i_hat) == 2:\n        # Backward compatibility: assume S3 = 0 (no circular polarisation)\n        S_i_full = np.array([1.0, S_i_hat[0], S_i_hat[1], 0.0])\n    elif len(S_i_hat) == 3:\n        # Use provided circular component\n        S_i_full = np.array([1.0, S_i_hat[0], S_i_hat[1], S_i_hat[2]])\n    else:\n        raise ValueError(f\"S_i_hat must have 2 or 3 elements, got {len(S_i_hat)}\")\n\n    # Apply Mueller matrix to get output Stokes vector\n    if M.ndim == 2:\n        # Single pixel case\n        S_out = M @ S_i_full\n    else:\n        # Array case - need to handle broadcasting\n        S_out = np.einsum(\"...ij,j-&gt;...i\", M, S_i_full)\n\n    # Extract S0, S1, S2 from output\n    S0_out = S_out[..., 0] if S_out.ndim &gt; 1 else S_out[0]\n    S1_out = S_out[..., 1] if S_out.ndim &gt; 1 else S_out[1]\n    S2_out = S_out[..., 2] if S_out.ndim &gt; 1 else S_out[2]\n\n    # Compute intensities for four analyzer angles\n    # I(\u03b1) = (S0 + S1*cos(2\u03b1) + S2*sin(2\u03b1)) / 2\n    I0_pol = I0 * (S0_out + S1_out) / 2  # \u03b1 = 0\u00b0\n    I45_pol = I0 * (S0_out + S2_out) / 2  # \u03b1 = 45\u00b0\n    I90_pol = I0 * (S0_out - S1_out) / 2  # \u03b1 = 90\u00b0\n    I135_pol = I0 * (S0_out - S2_out) / 2  # \u03b1 = 135\u00b0\n\n    return I0_pol, I45_pol, I90_pol, I135_pol\n</code></pre>"},{"location":"reference/io/","title":"io","text":"<p>Input/output operations for images and data.</p> <p>This module handles reading and writing of image files, raw camera data, and parameter files for photoelastic analysis workflows.</p>"},{"location":"reference/io/#photoelastimetry.io","title":"<code>io</code>","text":""},{"location":"reference/io/#photoelastimetry.io-functions","title":"Functions","text":""},{"location":"reference/io/#photoelastimetry.io.list_supported_bayer_pixel_formats","title":"<code>list_supported_bayer_pixel_formats()</code>","text":"<p>Return the supported Bayer pixelFormat descriptors keyed by PFNC code.</p> Source code in <code>photoelastimetry/io.py</code> <pre><code>def list_supported_bayer_pixel_formats():\n    \"\"\"\n    Return the supported Bayer pixelFormat descriptors keyed by PFNC code.\n    \"\"\"\n    return {code: dict(spec) for code, spec in SUPPORTED_BAYER_PIXEL_FORMATS.items()}\n</code></pre>"},{"location":"reference/io/#photoelastimetry.io.split_channels","title":"<code>split_channels(data)</code>","text":"<p>Splits the data into its respective polarisation channels. Each superpixel is 4x4 pixels, and the channels are arranged in the following order:</p> <p>R_0 | R_45 | G1_0 | G1_45 R_135 | R_90 | G1_135 | G1_90 G2_0 | G2_45 | B_0 | B_45 G2_135 | G2_90 | B_135 | B_90</p> Source code in <code>photoelastimetry/io.py</code> <pre><code>def split_channels(data):\n    \"\"\"\n    Splits the data into its respective polarisation channels. Each superpixel\n    is 4x4 pixels, and the channels are arranged in the following order:\n\n    R_0 | R_45 | G1_0 | G1_45\n    R_135 | R_90 | G1_135 | G1_90\n    G2_0 | G2_45 | B_0 | B_45\n    G2_135 | G2_90 | B_135 | B_90\n    \"\"\"\n\n    # Reshape the data into a 4D array\n    R_0 = data[0::4, 0::4]\n    R_45 = data[0::4, 1::4]\n    G1_0 = data[0::4, 2::4]\n    G1_45 = data[0::4, 3::4]\n    R_135 = data[1::4, 0::4]\n    R_90 = data[1::4, 1::4]\n    G1_135 = data[1::4, 2::4]\n    G1_90 = data[1::4, 3::4]\n    G2_0 = data[2::4, 0::4]\n    G2_45 = data[2::4, 1::4]\n    B_0 = data[2::4, 2::4]\n    B_45 = data[2::4, 3::4]\n    G2_135 = data[3::4, 0::4]\n    G2_90 = data[3::4, 1::4]\n    B_135 = data[3::4, 2::4]\n    B_90 = data[3::4, 3::4]\n\n    # Stack the channels into a 4D array\n    I0 = np.stack((R_0, G1_0, G2_0, B_0), axis=-1)\n    I90 = np.stack((R_90, G1_90, G2_90, B_90), axis=-1)\n    I45 = np.stack((R_45, G1_45, G2_45, B_45), axis=-1)\n    I135 = np.stack((R_135, G1_135, G2_135, B_135), axis=-1)\n\n    # data is a 4D array with shape (height, width, colour, polarisation)\n    data = np.stack(\n        (\n            I0,\n            I45,\n            I90,\n            I135,\n        ),\n        axis=-1,\n    )\n    return data\n</code></pre>"},{"location":"reference/io/#photoelastimetry.io.save_image","title":"<code>save_image(filename, data, metadata={})</code>","text":"<p>Save image data to a file in various formats.</p> <p>This function saves image data to disk in one of several supported formats, automatically determining the format from the file extension.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the output file. The file extension determines the format. Supported extensions: .npy, .raw, .png, .jpg, .jpeg, .tiff, .tif</p> required <code>data</code> <code>ndarray</code> <p>Image data to save. The data will be cast to the appropriate dtype based on the file format (uint8 for .png/.jpg, uint16 for .tiff, etc.)</p> required <code>metadata</code> <code>dict</code> <p>Dictionary containing metadata about the image. For .raw format, must contain a \"dtype\" key specifying the data type to use when saving. Default is empty.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the file extension is not one of the supported formats.</p> Notes <ul> <li>.npy files preserve the original data type and shape</li> <li>.raw files are saved as binary with dtype specified in metadata</li> <li>.png and .jpg files convert data to uint8</li> <li>.tiff/.tif files convert data to uint16</li> <li>matplotlib is used for .png and .jpg formats</li> <li>tifffile library is used for .tiff/.tif formats</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = np.random.randint(0, 255, (100, 100), dtype=np.uint8)\n&gt;&gt;&gt; metadata = {\"dtype\": \"uint8\"}\n&gt;&gt;&gt; save_image(\"output.png\", data, metadata)\n</code></pre> Source code in <code>photoelastimetry/io.py</code> <pre><code>def save_image(filename, data, metadata={}):\n    \"\"\"\n    Save image data to a file in various formats.\n\n    This function saves image data to disk in one of several supported formats,\n    automatically determining the format from the file extension.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the output file. The file extension determines the format.\n        Supported extensions: .npy, .raw, .png, .jpg, .jpeg, .tiff, .tif\n    data : numpy.ndarray\n        Image data to save. The data will be cast to the appropriate dtype\n        based on the file format (uint8 for .png/.jpg, uint16 for .tiff, etc.)\n    metadata : dict\n        Dictionary containing metadata about the image. For .raw format, must\n        contain a \"dtype\" key specifying the data type to use when saving. Default is empty.\n\n    Raises\n    ------\n    ValueError\n        If the file extension is not one of the supported formats.\n\n    Notes\n    -----\n    - .npy files preserve the original data type and shape\n    - .raw files are saved as binary with dtype specified in metadata\n    - .png and .jpg files convert data to uint8\n    - .tiff/.tif files convert data to uint16\n    - matplotlib is used for .png and .jpg formats\n    - tifffile library is used for .tiff/.tif formats\n\n    Examples\n    --------\n    &gt;&gt;&gt; data = np.random.randint(0, 255, (100, 100), dtype=np.uint8)\n    &gt;&gt;&gt; metadata = {\"dtype\": \"uint8\"}\n    &gt;&gt;&gt; save_image(\"output.png\", data, metadata)\n    \"\"\"\n    output_folder = os.path.dirname(filename)\n    if output_folder != \"\" and not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    if filename.endswith(\".npy\"):\n        np.save(filename, data)\n    elif filename.endswith(\".raw\"):\n        with open(filename, \"wb\") as f:\n            data.astype(metadata[\"dtype\"]).tofile(f)\n    elif filename.endswith(\".png\"):\n        import matplotlib.pyplot as plt\n\n        plt.imsave(filename, data.astype(np.uint8))\n    elif filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n        import matplotlib.pyplot as plt\n\n        plt.imsave(filename, data.astype(np.uint8))\n    elif filename.endswith(\".tiff\") or filename.endswith(\".tif\"):\n        import tifffile\n\n        if data.ndim == 2:\n            tifffile.imwrite(filename, data.astype(\"&lt;f4\"))\n        elif data.ndim == 3:\n            transposed = np.transpose(data, (2, 0, 1))\n            tifffile.imwrite(filename, transposed.astype(\"&lt;f4\"), imagej=True, metadata={\"axes\": \"CYX\"})\n        elif data.ndim == 4:\n            # Permute to [4, 3, H, W] so TIFF is interpreted as 4 timepoints of 3-channel images\n            transposed = np.transpose(data, (3, 2, 0, 1))\n            tifffile.imwrite(filename, transposed.astype(\"&lt;f4\"), imagej=True, metadata={\"axes\": \"TCYX\"})\n    else:\n        raise ValueError(\n            f\"Unsupported file format for {filename}. Supported formats are .npy, .raw, .png, .jpg, .jpeg, .tiff, .tif\"\n        )\n</code></pre>"},{"location":"reference/io/#photoelastimetry.io.load_image","title":"<code>load_image(filename, metadata=None)</code>","text":"<p>Load image data from a file in various formats.</p> <p>This function loads image data from disk in one of several supported formats, automatically determining the format from the file extension.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the input file. The file extension determines the format. Supported extensions: .npy, .raw, .png, .jpg, .jpeg, .tiff, .tif</p> required <code>metadata</code> <code>dict</code> <p>Dictionary containing metadata about the image. For .raw format, must contain \"width\", \"height\", and \"dtype\" keys specifying the image dimensions and data type. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Loaded image data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the file extension is not one of the supported formats.</p> Notes <ul> <li>.npy files preserve the original data type and shape</li> <li>.raw files are read as binary with dtype and shape specified in metadata</li> <li>.png and .jpg files are loaded as uint8 arrays</li> <li>.tiff/.tif files are loaded as uint16 arrays</li> <li>matplotlib is used for .png and .jpg formats</li> <li>tifffile library is used for .tiff/.tif formats</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; metadata = {\"width\": 100, \"height\": 100, \"dtype\": \"uint8\"}\n&gt;&gt;&gt; data = load_image(\"input.raw\", metadata)\n</code></pre> Source code in <code>photoelastimetry/io.py</code> <pre><code>def load_image(filename, metadata=None):\n    \"\"\"\n    Load image data from a file in various formats.\n\n    This function loads image data from disk in one of several supported formats,\n    automatically determining the format from the file extension.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the input file. The file extension determines the format.\n        Supported extensions: .npy, .raw, .png, .jpg, .jpeg, .tiff, .tif\n    metadata : dict, optional\n        Dictionary containing metadata about the image. For .raw format, must\n        contain \"width\", \"height\", and \"dtype\" keys specifying the image dimensions\n        and data type. Default is None.\n\n    Returns\n    -------\n    numpy.ndarray\n        Loaded image data.\n\n    Raises\n    ------\n    ValueError\n        If the file extension is not one of the supported formats.\n\n    Notes\n    -----\n    - .npy files preserve the original data type and shape\n    - .raw files are read as binary with dtype and shape specified in metadata\n    - .png and .jpg files are loaded as uint8 arrays\n    - .tiff/.tif files are loaded as uint16 arrays\n    - matplotlib is used for .png and .jpg formats\n    - tifffile library is used for .tiff/.tif formats\n\n    Examples\n    --------\n    &gt;&gt;&gt; metadata = {\"width\": 100, \"height\": 100, \"dtype\": \"uint8\"}\n    &gt;&gt;&gt; data = load_image(\"input.raw\", metadata)\n    \"\"\"\n    if filename.endswith(\".npy\"):\n        data = np.load(filename)\n    elif filename.endswith(\".raw\"):\n        if metadata is None:\n            raw_path = os.path.abspath(filename)\n            raw_dir = os.path.dirname(raw_path)\n            candidates = [\n                os.path.join(raw_dir, \"recordingMetadata.json\"),\n                os.path.join(os.path.dirname(raw_dir), \"recordingMetadata.json\"),\n                os.path.join(os.path.dirname(os.path.dirname(raw_path)), \"recordingMetadata.json\"),\n            ]\n            for metadata_file in candidates:\n                if os.path.exists(metadata_file):\n                    with open(metadata_file, \"r\") as f:\n                        metadata = json.load(f)\n                    break\n        data = np.array(read_raw(filename, metadata))\n    elif filename.endswith(\".png\") or filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n        import matplotlib.pyplot as plt\n\n        data = plt.imread(filename)\n    elif filename.endswith(\".tiff\") or filename.endswith(\".tif\"):\n        import tifffile\n\n        data = tifffile.imread(filename)\n\n        # transpose data to XYC or XYCP format\n        if data.ndim == 3:\n            data = np.transpose(data, (1, 2, 0))\n        elif data.ndim == 4:\n            data = np.transpose(data, (2, 3, 1, 0))\n\n    else:\n        raise ValueError(\n            f\"Unsupported file format for {filename}. Supported formats are .npy, .raw, .png, .jpg, .jpeg, .tiff, .tif\"\n        )\n\n    if metadata is None:\n        metadata = {}\n        metadata[\"dtype\"] = str(data.dtype)\n        metadata[\"height\"] = data.shape[0]\n        metadata[\"width\"] = data.shape[1]\n\n    return data, metadata\n</code></pre>"},{"location":"reference/io/#photoelastimetry.io.bin_image","title":"<code>bin_image(data, binning)</code>","text":"<p>Bin the image by the specified factor.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input image data to be binned.</p> required <code>binning</code> <code>int</code> <p>Binning factor. The image dimensions will be reduced by this factor.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Binned image data.</p> Source code in <code>photoelastimetry/io.py</code> <pre><code>def bin_image(data, binning):\n    \"\"\"\n    Bin the image by the specified factor.\n\n    Parameters\n    ----------\n    data : numpy.ndarray\n        Input image data to be binned.\n    binning : int\n        Binning factor. The image dimensions will be reduced by this factor.\n\n    Returns\n    -------\n    numpy.ndarray\n        Binned image data.\n    \"\"\"\n    if binning &lt;= 1:\n        return data\n\n    # Calculate new shape\n    new_height = data.shape[0] // binning\n    new_width = data.shape[1] // binning\n\n    # Reshape and bin\n    binned_data = (\n        data[: new_height * binning, : new_width * binning]\n        .reshape(new_height, binning, new_width, binning, *data.shape[2:])\n        .mean(axis=(1, 3))\n    )\n\n    return binned_data\n</code></pre>"},{"location":"reference/main/","title":"main","text":"<p>Command-line interface entry points.</p> <p>This module provides the command-line interfaces for the main tools: - <code>image-to-stress</code> - Convert photoelastic images to stress maps - <code>stress-to-image</code> - Generate photoelastic images from stress fields - <code>demosaic-raw</code> - Process raw polarimetric camera images - <code>calibrate-photoelastimetry</code> - Calibrate optics/material constants from known-load data</p>"},{"location":"reference/main/#photoelastimetry.main","title":"<code>main</code>","text":""},{"location":"reference/main/#photoelastimetry.main-functions","title":"Functions","text":""},{"location":"reference/main/#photoelastimetry.main.image_to_stress","title":"<code>image_to_stress(params, output_filename=None)</code>","text":"<p>Convert photoelastic images to stress maps.</p> <p>This function processes raw photoelastic data to recover stress distribution maps using the stress-optic law and polarisation analysis.</p> <p>Args:     params (dict): Configuration dictionary containing:         - input_filename (str, optional): Path to input image file. If None, raw images are loaded from folderName.         - folderName (str): Path to folder containing raw photoelastic images         - crop (list, optional): Crop region as [x1, x2, y1, y2]         - debug (bool): If True, display all channels for debugging         - C (float): Stress-optic coefficient in 1/Pa         - thickness (float): Sample thickness in meters         - wavelengths (list): List of wavelengths in nanometers         - S_i_hat (list): Incoming normalised Stokes vector [S1_hat, S2_hat, S3_hat]         - seeding (dict, optional): Seeding controls (<code>enabled</code>, <code>n_max</code>, <code>sigma_max</code>)         - top-level optimise options (optional): <code>knot_spacing</code>, <code>spline_degree</code>,           <code>boundary_mask_file</code>, <code>boundary_values_files</code>, <code>boundary_weight</code>,           <code>regularisation_weight</code> (or <code>regularization_weight</code>), <code>regularisation_order</code>,           <code>external_potential_file</code>, <code>external_potential_gradient</code>, <code>max_iterations</code>,           <code>tolerance</code>, <code>verbose</code>, <code>debug</code>     output_filename (str, optional): Path to save the output stress map image.         If None, the stress map is not saved. Defaults to None. Can also be specified in params.</p> <p>Returns:     numpy.ndarray: 3D stress tensor map [H, W, 3] in Pascals.</p> <p>Notes:     - Assumes incoming light is fully S1 polarised     - Uses uniform stress-optic coefficient across all wavelengths     - Assumes solid sample (NU = 1.0)     - Wavelengths are automatically converted from nm to meters</p> Source code in <code>photoelastimetry/main.py</code> <pre><code>def image_to_stress(params, output_filename=None):\n    \"\"\"\n    Convert photoelastic images to stress maps.\n\n    This function processes raw photoelastic data to recover stress distribution maps\n    using the stress-optic law and polarisation analysis.\n\n    Args:\n        params (dict): Configuration dictionary containing:\n            - input_filename (str, optional): Path to input image file. If None, raw images are loaded from folderName.\n            - folderName (str): Path to folder containing raw photoelastic images\n            - crop (list, optional): Crop region as [x1, x2, y1, y2]\n            - debug (bool): If True, display all channels for debugging\n            - C (float): Stress-optic coefficient in 1/Pa\n            - thickness (float): Sample thickness in meters\n            - wavelengths (list): List of wavelengths in nanometers\n            - S_i_hat (list): Incoming normalised Stokes vector [S1_hat, S2_hat, S3_hat]\n            - seeding (dict, optional): Seeding controls (`enabled`, `n_max`, `sigma_max`)\n            - top-level optimise options (optional): `knot_spacing`, `spline_degree`,\n              `boundary_mask_file`, `boundary_values_files`, `boundary_weight`,\n              `regularisation_weight` (or `regularization_weight`), `regularisation_order`,\n              `external_potential_file`, `external_potential_gradient`, `max_iterations`,\n              `tolerance`, `verbose`, `debug`\n        output_filename (str, optional): Path to save the output stress map image.\n            If None, the stress map is not saved. Defaults to None. Can also be specified in params.\n\n    Returns:\n        numpy.ndarray: 3D stress tensor map [H, W, 3] in Pascals.\n\n    Notes:\n        - Assumes incoming light is fully S1 polarised\n        - Uses uniform stress-optic coefficient across all wavelengths\n        - Assumes solid sample (NU = 1.0)\n        - Wavelengths are automatically converted from nm to meters\n    \"\"\"\n\n    params = _merge_params_with_calibration(params)\n\n    if \"folderName\" in params:\n        data, metadata = photoelastimetry.io.load_raw(params[\"folderName\"])\n    elif \"input_filename\" in params:\n        data, metadata = photoelastimetry.io.load_image(params[\"input_filename\"])\n    else:\n        raise ValueError(\"Either 'folderName' or 'input_filename' must be specified in params.\")\n\n    profile = params.get(\"_calibration_profile\")\n    if profile is not None:\n        data = photoelastimetry.calibrate.apply_blank_correction(data, profile[\"blank_correction\"])\n\n    if params.get(\"crop\") is not None:\n        data = data[\n            params[\"crop\"][2] : params[\"crop\"][3],\n            params[\"crop\"][0] : params[\"crop\"][1],\n            :,\n            :,\n        ]\n        if params[\"debug\"]:\n            photoelastimetry.io.save_image(\"debug_cropped_image.tiff\", data, metadata)\n\n    if params[\"debug\"]:\n        # import matplotlib.pyplot as plt\n        import tifffile\n\n        tifffile.imwrite(\"debug_before_binning.tiff\", data[:, :, 0, 0])\n\n    if params.get(\"binning\") is not None:\n        binning = params[\"binning\"]\n        data = photoelastimetry.io.bin_image(data, binning)\n        metadata[\"height\"] //= binning\n        metadata[\"width\"] //= binning\n\n    if params[\"debug\"]:\n        photoelastimetry.plotting.show_all_channels(data, metadata)\n\n    if \"C\" not in params:\n        raise ValueError(\"Missing stress-optic coefficient 'C'. Provide it directly or via calibration_file.\")\n    if \"thickness\" not in params:\n        raise ValueError(\"Missing sample thickness 'thickness'.\")\n    if \"wavelengths\" not in params:\n        raise ValueError(\"Missing wavelengths. Provide them directly or via calibration_file.\")\n    if \"S_i_hat\" not in params:\n        raise ValueError(\"Missing S_i_hat. Provide it directly or via calibration_file.\")\n\n    C = params[\"C\"]  # Stress-optic coefficients in 1/Pa\n    L = params[\"thickness\"]  # Thickness in m\n    WAVELENGTHS = _normalise_wavelengths(params[\"wavelengths\"])\n    NU = 1.0  # Solid sample\n    if isinstance(C, list) or isinstance(C, np.ndarray):\n        C_VALUES = np.asarray(C, dtype=float)\n    else:\n        C_VALUES = np.array(\n            [\n                C,\n                C,\n                C,\n            ],\n            dtype=float,\n        )  # Stress-optic coefficients in 1/Pa\n\n    # Get incoming polarisation state from config\n    S_I_HAT = np.array(params[\"S_i_hat\"])\n    # Ensure it's 3 elements for consistency\n    if len(S_I_HAT) == 2:\n        S_I_HAT = np.append(S_I_HAT, 0.0)  # Add S3_hat = 0 for backward compatibility\n\n    if \"solver\" in params:\n        raise ValueError(\n            \"`solver` is no longer supported. \"\n            \"image_to_stress now always runs the optimise solver. \"\n            \"Remove `solver` from params.\"\n        )\n    if \"global_mean_stress\" in params or \"global_solver\" in params:\n        raise ValueError(\n            \"Nested solver config blocks (`global_mean_stress`, `global_solver`) are no longer supported. \"\n            \"Move solver options to top-level params.\"\n        )\n\n    # Phase Decomposed Seeding\n    seeding_config = params.get(\"seeding\", {})\n    n_max = seeding_config.get(\"n_max\", 6)\n    sigma_max = seeding_config.get(\"sigma_max\", 10e6)\n\n    # Correction parameters\n    correction_params = params.get(\"correction\", {})\n\n    print(\"Running phase decomposed seeding...\")\n    initial_stress_map = photoelastimetry.seeding.phase_decomposed_seeding(\n        data,\n        WAVELENGTHS,\n        C_VALUES,\n        NU,\n        L,\n        S_i_hat=S_I_HAT,\n        sigma_max=sigma_max,\n        n_max=n_max,\n        correction_params=correction_params,\n    )\n\n    H, W = data.shape[:2]\n\n    boundary_mask = None\n    mask_file = params.get(\"boundary_mask_file\")\n    if mask_file is not None:\n        if not os.path.exists(mask_file):\n            raise ValueError(f\"Boundary mask file not found: {mask_file}\")\n        boundary_mask = _load_array(mask_file) &gt; 0\n        if boundary_mask.shape != (H, W):\n            raise ValueError(f\"Boundary mask shape must be {(H, W)}, got {boundary_mask.shape}\")\n\n    boundary_values = None\n    boundary_value_files = params.get(\"boundary_values_files\")\n    if boundary_value_files is not None:\n        boundary_values = {}\n        for key in (\"xx\", \"yy\", \"xy\"):\n            if key not in boundary_value_files:\n                continue\n            value_file = boundary_value_files[key]\n            if value_file is None:\n                continue\n            if not os.path.exists(value_file):\n                raise ValueError(f\"Boundary values file for '{key}' not found: {value_file}\")\n            boundary_values[key] = _load_array(value_file).astype(float)\n            if boundary_values[key].shape != (H, W):\n                raise ValueError(\n                    f\"Boundary values '{key}' shape must be {(H, W)}, got {boundary_values[key].shape}\"\n                )\n        if len(boundary_values) == 0:\n            boundary_values = None\n\n    external_potential = None\n    potential_file = params.get(\"external_potential_file\")\n    potential_gradient = params.get(\"external_potential_gradient\")\n    if potential_file is not None and potential_gradient is not None:\n        raise ValueError(\"Use either external_potential_file or external_potential_gradient, not both.\")\n    if potential_file is not None:\n        if not os.path.exists(potential_file):\n            raise ValueError(f\"External potential file not found: {potential_file}\")\n        external_potential = _load_array(potential_file).astype(float)\n        if external_potential.shape != (H, W):\n            raise ValueError(f\"External potential shape must be {(H, W)}, got {external_potential.shape}\")\n    elif potential_gradient is not None:\n        grad = np.asarray(potential_gradient, dtype=float)\n        if grad.shape != (2,):\n            raise ValueError(f\"external_potential_gradient must be [dVdx, dVdy], got {potential_gradient}\")\n        y_idx, x_idx = np.indices((H, W), dtype=float)\n        external_potential = grad[0] * x_idx + grad[1] * y_idx\n\n    optimise_params = {}\n    for key in (\n        \"knot_spacing\",\n        \"spline_degree\",\n        \"boundary_weight\",\n        \"regularisation_weight\",\n        \"regularisation_order\",\n        \"max_iterations\",\n        \"tolerance\",\n        \"verbose\",\n        \"debug\",\n    ):\n        if key in params:\n            optimise_params[key] = params[key]\n\n    if \"regularization_weight\" in params and \"regularisation_weight\" not in optimise_params:\n        optimise_params[\"regularisation_weight\"] = params[\"regularization_weight\"]\n\n    initial_diff, initial_theta = photoelastimetry.optimise.stress_to_principal_invariants(initial_stress_map)\n\n    bspline_wrapper, coeffs = photoelastimetry.optimise.recover_mean_stress(\n        initial_diff,\n        initial_theta,\n        boundary_mask=boundary_mask,\n        boundary_values=boundary_values,\n        external_potential=external_potential,\n        initial_stress_map=initial_stress_map,\n        **optimise_params,\n    )\n\n    s_xx, s_yy, s_xy = bspline_wrapper.get_stress_fields(coeffs)\n    if external_potential is not None:\n        s_xx = s_xx + external_potential\n        s_yy = s_yy + external_potential\n    stress_map = np.stack([s_xx, s_yy, s_xy], axis=-1)\n\n    if params.get(\"output_filename\") is not None:\n        output_filename = params[\"output_filename\"]\n\n    if output_filename is not None:\n        photoelastimetry.io.save_image(output_filename, stress_map, metadata)\n\n    return stress_map\n</code></pre>"},{"location":"reference/main/#photoelastimetry.main.stress_to_image","title":"<code>stress_to_image(params)</code>","text":"<p>Convert stress field data to photoelastic fringe pattern image.</p> <p>This function loads stress field data, optionally applies Gaussian scattering, computes principal stresses and their orientations, calculates photoelastic retardation and fringe patterns, and saves the resulting visualization.</p> <p>Args:     params (dict): Dictionary containing the following keys:         - p_filename (str): Path to the photoelastimetry parameter file         - stress_filename (str): Path to the stress field data file         - scattering (float, optional): Gaussian filter sigma for scattering simulation.           If falsy, no scattering is applied.         - t (float): Thickness of the photoelastic material         - lambda_light (float): Wavelength of light used in the experiment         - C (float): Stress-optic coefficient of the material         - output_filename (str, optional): Path for the output image.           Defaults to \"output.png\" if not provided.</p> <p>Returns:     None: The function saves the fringe pattern visualization to a file.</p> <p>Notes:     - The stress field is expected to have components in the order [sigma_xy, sigma_yy, sigma_xx]     - Principal stresses are computed using Mohr's circle equations     - Isochromatic fringe intensity is calculated using sin\u00b2(\u03b4/2)     - Isoclinic angle represents the orientation of principal stresses</p> Source code in <code>photoelastimetry/main.py</code> <pre><code>def stress_to_image(params):\n    \"\"\"\n    Convert stress field data to photoelastic fringe pattern image.\n\n    This function loads stress field data, optionally applies Gaussian scattering,\n    computes principal stresses and their orientations, calculates photoelastic\n    retardation and fringe patterns, and saves the resulting visualization.\n\n    Args:\n        params (dict): Dictionary containing the following keys:\n            - p_filename (str): Path to the photoelastimetry parameter file\n            - stress_filename (str): Path to the stress field data file\n            - scattering (float, optional): Gaussian filter sigma for scattering simulation.\n              If falsy, no scattering is applied.\n            - t (float): Thickness of the photoelastic material\n            - lambda_light (float): Wavelength of light used in the experiment\n            - C (float): Stress-optic coefficient of the material\n            - output_filename (str, optional): Path for the output image.\n              Defaults to \"output.png\" if not provided.\n\n    Returns:\n        None: The function saves the fringe pattern visualization to a file.\n\n    Notes:\n        - The stress field is expected to have components in the order [sigma_xy, sigma_yy, sigma_xx]\n        - Principal stresses are computed using Mohr's circle equations\n        - Isochromatic fringe intensity is calculated using sin\u00b2(\u03b4/2)\n        - Isoclinic angle represents the orientation of principal stresses\n    \"\"\"\n\n    fallback_params = {}\n    if \"p_filename\" in params:\n        if not os.path.exists(params[\"p_filename\"]):\n            raise ValueError(f\"Parameter file not found: {params['p_filename']}\")\n        with open(params[\"p_filename\"], \"r\") as f:\n            fallback_params = json5.load(f)\n\n    merged_params = _merge_params_with_calibration(params, fallback_params=fallback_params)\n\n    def get_param(name, default=None, aliases=()):\n        names = (name,) + tuple(aliases)\n        for key in names:\n            if key in merged_params:\n                return merged_params[key]\n        return default\n\n    stress_filename = get_param(\"stress_filename\", aliases=(\"s_filename\",))\n    if stress_filename is None:\n        raise ValueError(\"Missing stress map path. Provide 'stress_filename' (or legacy 's_filename').\")\n\n    stress_map, _ = photoelastimetry.io.load_image(stress_filename)\n    stress_order = get_param(\"stress_order\", default=\"xx_yy_xy\")\n    sigma_xx, sigma_yy, sigma_xy = _get_stress_components(stress_map, stress_order)\n\n    scattering = float(get_param(\"scattering\", default=0.0))\n    if scattering &gt; 0:\n        sigma_xx = gaussian_filter(sigma_xx, sigma=scattering)\n        sigma_xy = gaussian_filter(sigma_xy, sigma=scattering)\n        sigma_yy = gaussian_filter(sigma_yy, sigma=scattering)\n\n    wavelengths_cfg = get_param(\"wavelengths\", aliases=(\"lambda_light\",))\n    if wavelengths_cfg is None:\n        raise ValueError(\"Missing wavelengths. Provide 'wavelengths' or 'lambda_light'.\")\n    wavelengths = _normalise_wavelengths(wavelengths_cfg)\n\n    C_cfg = get_param(\"C\")\n    if C_cfg is None:\n        raise ValueError(\"Missing stress-optic coefficient 'C'.\")\n    C_values = np.asarray(C_cfg, dtype=float)\n    if C_values.ndim == 0:\n        C_values = np.full(wavelengths.shape, float(C_values))\n    elif C_values.size == 1 and wavelengths.size &gt; 1:\n        C_values = np.full(wavelengths.shape, float(C_values.item()))\n    elif C_values.size != wavelengths.size:\n        raise ValueError(f\"C must be scalar or length {wavelengths.size}, got length {C_values.size}.\")\n\n    thickness = get_param(\"thickness\", aliases=(\"t\",))\n    if thickness is None:\n        raise ValueError(\"Missing sample thickness. Provide 'thickness' or legacy key 't'.\")\n    thickness = float(thickness)\n\n    nu = float(get_param(\"nu\", default=1.0))\n    S_i_hat = np.asarray(get_param(\"S_i_hat\", default=[1.0, 0.0, 0.0]), dtype=float)\n    if len(S_i_hat) == 2:\n        S_i_hat = np.append(S_i_hat, 0.0)\n    elif len(S_i_hat) != 3:\n        raise ValueError(f\"S_i_hat must have length 2 or 3, got {len(S_i_hat)}.\")\n\n    H, W = sigma_xx.shape\n    synthetic_images = np.zeros((H, W, len(wavelengths), 4), dtype=np.float32)\n    for i, (wl, C_val) in enumerate(zip(wavelengths, C_values)):\n        I0, I45, I90, I135 = simulate_four_step_polarimetry(\n            sigma_xx, sigma_yy, sigma_xy, C_val, nu, thickness, wl, S_i_hat\n        )\n        synthetic_images[:, :, i, 0] = I0\n        synthetic_images[:, :, i, 1] = I45\n        synthetic_images[:, :, i, 2] = I90\n        synthetic_images[:, :, i, 3] = I135\n\n    output_filename = get_param(\"output_filename\", default=\"output.png\")\n    ext = os.path.splitext(output_filename)[1].lower()\n\n    if ext in {\".tiff\", \".tif\", \".npy\", \".raw\"}:\n        photoelastimetry.io.save_image(output_filename, synthetic_images)\n    elif ext in {\".png\", \".jpg\", \".jpeg\"}:\n        delta = compute_retardance(sigma_xx, sigma_yy, sigma_xy, C_values[0], nu, thickness, wavelengths[0])\n        fringe_intensity = np.sin(delta / 2) ** 2\n        phi = 0.5 * np.arctan2(2 * sigma_xy, sigma_xx - sigma_yy)\n        photoelastimetry.plotting.plot_fringe_pattern(fringe_intensity, phi, filename=output_filename)\n    else:\n        raise ValueError(\n            f\"Unsupported output extension '{ext}' for stress_to_image. \"\n            \"Use .tiff/.tif/.npy/.raw for stacks or .png/.jpg/.jpeg for a plot.\"\n        )\n\n    return synthetic_images\n</code></pre>"},{"location":"reference/main/#photoelastimetry.main.cli_image_to_stress","title":"<code>cli_image_to_stress()</code>","text":"<p>Command line interface for image_to_stress function.</p> Source code in <code>photoelastimetry/main.py</code> <pre><code>def cli_image_to_stress():\n    \"\"\"Command line interface for image_to_stress function.\"\"\"\n    parser = argparse.ArgumentParser(description=\"Convert photoelastic images to stress maps.\")\n    parser.add_argument(\n        \"json_filename\",\n        type=str,\n        help=\"Path to the JSON5 parameter file.\",\n    )\n    parser.add_argument(\n        \"--output\",\n        type=str,\n        default=None,\n        help=\"Path to save the output stress map image (optional).\",\n    )\n    args = parser.parse_args()\n\n    params = json5.load(open(args.json_filename, \"r\"))\n    image_to_stress(params, output_filename=args.output)\n</code></pre>"},{"location":"reference/main/#photoelastimetry.main.cli_stress_to_image","title":"<code>cli_stress_to_image()</code>","text":"<p>Command line interface for stress_to_image function.</p> Source code in <code>photoelastimetry/main.py</code> <pre><code>def cli_stress_to_image():\n    \"\"\"Command line interface for stress_to_image function.\"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Convert stress field data to photoelastic fringe pattern image.\"\n    )\n    parser.add_argument(\n        \"json_filename\",\n        type=str,\n        help=\"Path to the JSON5 parameter file.\",\n    )\n    args = parser.parse_args()\n\n    params = json5.load(open(args.json_filename, \"r\"))\n    stress_to_image(params)\n</code></pre>"},{"location":"reference/main/#photoelastimetry.main.cli_calibrate","title":"<code>cli_calibrate()</code>","text":"<p>Command line interface for calibration workflow.</p> Source code in <code>photoelastimetry/main.py</code> <pre><code>def cli_calibrate():\n    \"\"\"Command line interface for calibration workflow.\"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Calibrate photoelastimetry parameters from known-load data.\"\n    )\n    parser.add_argument(\n        \"json_filename\",\n        type=str,\n        help=\"Path to the calibration JSON5 parameter file.\",\n    )\n    parser.add_argument(\n        \"--interactive\",\n        action=\"store_true\",\n        help=\"Launch interactive geometry wizard before calibration.\",\n    )\n    parser.add_argument(\n        \"--save-config\",\n        type=str,\n        default=None,\n        help=\"Optional path to write the post-wizard calibration config JSON.\",\n    )\n    args = parser.parse_args()\n\n    with open(args.json_filename, \"r\") as f:\n        params = json5.load(f)\n\n    if args.interactive:\n        params = photoelastimetry.calibrate.interactive_geometry_wizard(params)\n        print(\"Applied interactive geometry selection.\")\n        if args.save_config is not None:\n            out_dir = os.path.dirname(args.save_config)\n            if out_dir:\n                os.makedirs(out_dir, exist_ok=True)\n            with open(args.save_config, \"w\") as f:\n                json.dump(params, f, indent=2)\n            print(f\"Wrote updated calibration config: {args.save_config}\")\n\n    result = photoelastimetry.calibrate.run_calibration(params)\n    print(f\"Wrote calibration profile: {result['profile_file']}\")\n    print(f\"Wrote calibration report: {result['report_file']}\")\n    print(f\"Wrote calibration diagnostics: {result['diagnostics_file']}\")\n    if \"diagnostics_plot_file\" in result:\n        print(f\"Wrote calibration diagnostics plot: {result['diagnostics_plot_file']}\")\n</code></pre>"},{"location":"reference/main/#photoelastimetry.main.demosaic_raw_image","title":"<code>demosaic_raw_image(input_file, metadata, output_prefix=None, output_format='tiff')</code>","text":"<p>De-mosaic a raw polarimetric image and save to TIFF stack or individual PNGs.</p> <p>This function takes a raw image from a polarimetric camera with a 4x4 superpixel pattern and splits it into separate channels for each color and polarisation angle.</p> <p>Args:     input_file (str): Path to the raw image file.     metadata (dict): Dictionary containing image metadata with keys:         - width (int): Image width in pixels         - height (int): Image height in pixels         - dtype (str, optional): Data type ('uint8' or 'uint16')     output_prefix (str, optional): Prefix for output files. If None, uses input         filename without extension. Defaults to None.     output_format (str, optional): Output format, either 'tiff' for a single         TIFF stack or 'png' for individual PNG files. Defaults to 'tiff'.</p> <p>Returns:     numpy.ndarray: De-mosaiced image stack of shape [H, W, 4, 4] where:         - H, W are the de-mosaiced dimensions (1/4 of original)         - First dimension 4: color channels (R, G1, G2, B)         - Second dimension 4: polarisation angles (0\u00b0, 45\u00b0, 90\u00b0, 135\u00b0)</p> <p>Notes:     - The raw image uses a 4x4 superpixel pattern with interleaved polarisation       and color filters     - Output TIFF stack has shape [H, W, 4, 4] with all channels     - Output PNGs create 4 files (one per polarisation angle) with shape [H, W, 4]       showing all color channels</p> Source code in <code>photoelastimetry/main.py</code> <pre><code>def demosaic_raw_image(input_file, metadata, output_prefix=None, output_format=\"tiff\"):\n    \"\"\"\n    De-mosaic a raw polarimetric image and save to TIFF stack or individual PNGs.\n\n    This function takes a raw image from a polarimetric camera with a 4x4 superpixel\n    pattern and splits it into separate channels for each color and polarisation angle.\n\n    Args:\n        input_file (str): Path to the raw image file.\n        metadata (dict): Dictionary containing image metadata with keys:\n            - width (int): Image width in pixels\n            - height (int): Image height in pixels\n            - dtype (str, optional): Data type ('uint8' or 'uint16')\n        output_prefix (str, optional): Prefix for output files. If None, uses input\n            filename without extension. Defaults to None.\n        output_format (str, optional): Output format, either 'tiff' for a single\n            TIFF stack or 'png' for individual PNG files. Defaults to 'tiff'.\n\n    Returns:\n        numpy.ndarray: De-mosaiced image stack of shape [H, W, 4, 4] where:\n            - H, W are the de-mosaiced dimensions (1/4 of original)\n            - First dimension 4: color channels (R, G1, G2, B)\n            - Second dimension 4: polarisation angles (0\u00b0, 45\u00b0, 90\u00b0, 135\u00b0)\n\n    Notes:\n        - The raw image uses a 4x4 superpixel pattern with interleaved polarisation\n          and color filters\n        - Output TIFF stack has shape [H, W, 4, 4] with all channels\n        - Output PNGs create 4 files (one per polarisation angle) with shape [H, W, 4]\n          showing all color channels\n    \"\"\"\n    # Read raw image\n    data = photoelastimetry.io.read_raw(input_file, metadata)\n\n    return demosaic_raw_data(\n        data, output_prefix=output_prefix or os.path.splitext(input_file)[0], output_format=output_format\n    )\n</code></pre>"},{"location":"reference/main/#photoelastimetry.main.demosaic_raw_data","title":"<code>demosaic_raw_data(data, output_prefix, output_format='tiff')</code>","text":"<p>De-mosaic raw sensor data array and save outputs.</p> Source code in <code>photoelastimetry/main.py</code> <pre><code>def demosaic_raw_data(data, output_prefix, output_format=\"tiff\"):\n    \"\"\"De-mosaic raw sensor data array and save outputs.\"\"\"\n    # De-mosaic into channels\n    demosaiced = photoelastimetry.io.split_channels(data)\n\n    # Keep only R, G1, B channels by removing G2\n    demosaiced = demosaiced[:, :, [0, 1, 3], :]  # Keep R, G1, B\n\n    # Save based on format\n    if output_format.lower() == \"tiff\":\n        import tifffile\n\n        output_file = f\"{output_prefix}_demosaiced.tiff\"\n        # Permute to [4, 3, H, W] so TIFF is interpreted as 4 timepoints of 3-channel images\n        demosaiced_transposed = np.transpose(demosaiced, (3, 2, 0, 1))\n        tifffile.imwrite(\n            output_file, demosaiced_transposed.astype(np.uint16), imagej=True, metadata={\"axes\": \"TCYX\"}\n        )\n        # print(f\"Saved TIFF stack to {output_file} (4 polarisation angles \u00d7 3 color channels)\")\n    elif output_format.lower() == \"png\":\n        import matplotlib.pyplot as plt\n\n        angle_names = [\"0deg\", \"45deg\", \"90deg\", \"135deg\"]\n        for i, angle in enumerate(angle_names):\n            output_file = f\"{output_prefix}_{angle}.png\"\n\n            # Normalise to 0-1 for PNG\n            # HARDCODED: 4096 for 12-bit images\n            img = demosaiced[:, :, :, i] / 4096\n\n            plt.imsave(output_file, img)\n            # print(f\"Saved {angle} polarisation to {output_file}\")\n    else:\n        raise ValueError(f\"Unsupported output format: {output_format}. Use 'tiff' or 'png'.\")\n\n    return demosaiced\n</code></pre>"},{"location":"reference/main/#photoelastimetry.main.demosaic_raw_average","title":"<code>demosaic_raw_average(raw_files, metadata, output_prefix, output_format='tiff', average_method='median')</code>","text":"<p>Average multiple raw frames, then de-mosaic once.</p> Source code in <code>photoelastimetry/main.py</code> <pre><code>def demosaic_raw_average(raw_files, metadata, output_prefix, output_format=\"tiff\", average_method=\"median\"):\n    \"\"\"Average multiple raw frames, then de-mosaic once.\"\"\"\n    if len(raw_files) == 0:\n        raise ValueError(\"No raw files provided for averaging.\")\n\n    frames = [\n        np.asarray(photoelastimetry.io.read_raw(raw_file, metadata), dtype=np.float32)\n        for raw_file in raw_files\n    ]\n    stacked = np.stack(frames, axis=0)\n    if average_method == \"mean\":\n        averaged = np.mean(stacked, axis=0)\n    elif average_method == \"median\":\n        averaged = np.median(stacked, axis=0)\n    else:\n        raise ValueError(f\"Unsupported average method: {average_method}. Use 'mean' or 'median'.\")\n\n    return demosaic_raw_data(averaged, output_prefix=output_prefix, output_format=output_format)\n</code></pre>"},{"location":"reference/main/#photoelastimetry.main.cli_demosaic","title":"<code>cli_demosaic()</code>","text":"<p>Command line interface for de-mosaicing raw polarimetric images.</p> Source code in <code>photoelastimetry/main.py</code> <pre><code>def cli_demosaic():\n    \"\"\"Command line interface for de-mosaicing raw polarimetric images.\"\"\"\n    parser = argparse.ArgumentParser(description=\"De-mosaic raw polarimetric images into separate channels.\")\n    parser.add_argument(\n        \"input_file\",\n        type=str,\n        help=\"Path to the raw image file or directory (with --all flag).\",\n    )\n    parser.add_argument(\n        \"--width\",\n        type=int,\n        default=4096,\n        help=\"Image width in pixels (default: 4096).\",\n    )\n    parser.add_argument(\n        \"--height\",\n        type=int,\n        default=3000,\n        help=\"Image height in pixels (default: 3000).\",\n    )\n    parser.add_argument(\n        \"--dtype\",\n        type=str,\n        default=None,\n        choices=[\"uint8\", \"uint16\"],\n        help=\"Data type (uint8 or uint16). Auto-detected if not specified.\",\n    )\n    parser.add_argument(\n        \"--output-prefix\",\n        type=str,\n        default=None,\n        help=\"Prefix for output files (default: input filename without extension).\",\n    )\n    parser.add_argument(\n        \"--format\",\n        type=str,\n        default=\"tiff\",\n        choices=[\"tiff\", \"png\"],\n        help=\"Output format: 'tiff' for single stack, 'png' for 4 separate images (default: tiff).\",\n    )\n    parser.add_argument(\n        \"--all\",\n        action=\"store_true\",\n        help=\"Recursively process all .raw files in the input directory and subdirectories.\",\n    )\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        choices=[\"auto\", \"single\", \"average\", \"series\"],\n        help=\"Processing mode. 'auto' chooses single for a file, average for a recording directory.\",\n    )\n    parser.add_argument(\n        \"--average-method\",\n        type=str,\n        default=\"median\",\n        choices=[\"mean\", \"median\"],\n        help=\"Method used when --mode average (default: median).\",\n    )\n    parser.add_argument(\n        \"--start\",\n        type=int,\n        default=None,\n        help=\"Start frame index (inclusive).\",\n    )\n    parser.add_argument(\n        \"--stop\",\n        type=int,\n        default=None,\n        help=\"Stop frame index (exclusive).\",\n    )\n    parser.add_argument(\n        \"--step\",\n        type=int,\n        default=1,\n        help=\"Frame step for selection (default: 1).\",\n    )\n    args = parser.parse_args()\n\n    metadata = {\n        \"width\": args.width,\n        \"height\": args.height,\n    }\n    if args.dtype:\n        metadata[\"dtype\"] = args.dtype\n\n    def ensure_parent_dir(path):\n        parent = os.path.dirname(path)\n        if parent:\n            os.makedirs(parent, exist_ok=True)\n\n    if args.all:\n        if args.mode == \"average\":\n            raise ValueError(\"--mode average is not supported with --all.\")\n        # Process all raw files recursively\n        if not os.path.isdir(args.input_file):\n            raise ValueError(f\"When using --all flag, input_file must be a directory. Got: {args.input_file}\")\n\n        # Find all .raw files recursively\n        from glob import glob\n\n        raw_files = sorted(glob(os.path.join(args.input_file, \"**\", \"*.raw\"), recursive=True))\n\n        if len(raw_files) == 0:\n            print(f\"No .raw files found in {args.input_file}\")\n            return\n        raw_files = _apply_frame_range(raw_files, start=args.start, stop=args.stop, step=args.step)\n\n        print(f\"Found {len(raw_files)} .raw files to process\")\n\n        # Process each file\n        from tqdm import tqdm\n\n        for raw_file in tqdm(raw_files, desc=\"Processing raw files\"):\n            try:\n                file_metadata = _load_cli_or_recording_metadata(raw_file, metadata)\n                demosaic_raw_image(raw_file, file_metadata, args.output_prefix, args.format)\n            except Exception as e:\n                print(f\"Error processing {raw_file}: {e}\")\n                continue\n    else:\n        # Process either a single raw file or one recording directory.\n        if os.path.isdir(args.input_file):\n            recording_dir = os.path.abspath(args.input_file)\n            raw_files = _resolve_recording_raw_files(recording_dir)\n            raw_files = _apply_frame_range(raw_files, start=args.start, stop=args.stop, step=args.step)\n            mode = args.mode if args.mode != \"auto\" else \"average\"\n\n            if mode == \"single\":\n                raise ValueError(\"Mode 'single' requires a .raw file input, not a directory.\")\n            if mode == \"average\":\n                file_metadata = _load_cli_or_recording_metadata(raw_files[0], metadata)\n                output_prefix = args.output_prefix or os.path.join(recording_dir, \"average\", \"demosaiced\")\n                ensure_parent_dir(output_prefix)\n                demosaic_raw_average(\n                    raw_files,\n                    metadata=file_metadata,\n                    output_prefix=output_prefix,\n                    output_format=args.format,\n                    average_method=args.average_method,\n                )\n            elif mode == \"series\":\n                from tqdm import tqdm\n\n                output_dir = os.path.join(recording_dir, \"series\")\n                os.makedirs(output_dir, exist_ok=True)\n                for raw_file in tqdm(raw_files, desc=\"Processing raw files\"):\n                    file_metadata = _load_cli_or_recording_metadata(raw_file, metadata)\n                    stem = os.path.splitext(os.path.basename(raw_file))[0]\n                    output_prefix = (\n                        f\"{args.output_prefix}_{stem}\"\n                        if args.output_prefix\n                        else os.path.join(output_dir, stem)\n                    )\n                    ensure_parent_dir(output_prefix)\n                    demosaic_raw_image(raw_file, file_metadata, output_prefix, args.format)\n            else:\n                raise ValueError(f\"Unsupported mode for directory input: {mode}\")\n        else:\n            mode = args.mode if args.mode != \"auto\" else \"single\"\n            if mode == \"average\":\n                raise ValueError(\"Mode 'average' requires a directory input.\")\n            if args.start is not None or args.stop is not None or args.step != 1:\n                raise ValueError(\"Frame range options (--start/--stop/--step) require a directory input.\")\n            file_metadata = _load_cli_or_recording_metadata(args.input_file, metadata)\n            demosaic_raw_image(args.input_file, file_metadata, args.output_prefix, args.format)\n</code></pre>"},{"location":"reference/optimise/","title":"optimise","text":"<p>Mean-stress equilibrium solver used by <code>image-to-stress</code>.</p>"},{"location":"reference/optimise/#photoelastimetry.optimise","title":"<code>optimise</code>","text":"<p>Global Mean Stress Recovery Solver.</p> <p>This module provides a solver that reconstructs the hydrostatic (mean) stress component given the known deviatoric stress components (derived from photoelastic measurements), while enforcing global equilibrium in a least-squares sense using a scalar B-spline pressure field.</p> <p>Unlike the full equilibrium solver, this approach assumes the principal stress difference and orientation are \"trusted\" inputs (e.g. from high-quality seeding), and only optimizes the stress field to be consistent with these inputs while satisfying equilibrium.</p>"},{"location":"reference/optimise/#photoelastimetry.optimise-classes","title":"Classes","text":""},{"location":"reference/optimise/#photoelastimetry.optimise.PressureFieldResult","title":"<code>PressureFieldResult</code>","text":"<p>Wrapper to present Pressure Field results as full stress fields.</p> Source code in <code>photoelastimetry/optimise.py</code> <pre><code>class PressureFieldResult:\n    \"\"\"Wrapper to present Pressure Field results as full stress fields.\"\"\"\n\n    def __init__(self, bspline_p, s_xx_dev, s_yy_dev, s_xy_dev):\n        self.bspline_p = bspline_p\n        self.s_xx_dev = s_xx_dev\n        self.s_yy_dev = s_yy_dev\n        self.s_xy_dev = s_xy_dev\n        # Forward basic properties\n        self.n_coeffs = bspline_p.n_coeffs\n        self.n_coeffs_x = bspline_p.n_coeffs_x\n        self.n_coeffs_y = bspline_p.n_coeffs_y\n\n    def get_stress_fields(self, coeffs):\n        \"\"\"\n        Reconstruct total stress fields from pressure coefficients and stored deviatoric parts.\n\n        Sigma_tot = P + S_dev\n        Note: If external potential V is used, it should be added externally to XX and YY.\n        \"\"\"\n        # Calculate P\n        P, _, _ = self.bspline_p.get_scalar_fields(coeffs)\n\n        # Combine\n        # s_xx_dev, s_yy_dev, s_xy_dev MUST be broadcastable or same shape\n        # They are stored as full maps.\n\n        sigma_xx = P + self.s_xx_dev\n        sigma_yy = P + self.s_yy_dev\n        sigma_xy = self.s_xy_dev\n\n        return sigma_xx, sigma_yy, sigma_xy\n\n    def project_stress_gradients(self, grad_s_xx, grad_s_yy, grad_s_xy):\n        \"\"\"Projections for regularization (if needed externally).\"\"\"\n        # Gradient of Loss w.r.t Stresses -&gt; Coefficients\n        # Stress = P + S_dev\n        # dStress/dP = 1\n        # dLoss/dP = dLoss/dStress * 1\n\n        grad_P = grad_s_xx + grad_s_yy  # + 0 * grad_s_xy\n\n        # P = B * C\n        return self.bspline_p.project_scalar_gradients(grad_P, None, None)\n</code></pre>"},{"location":"reference/optimise/#photoelastimetry.optimise.PressureFieldResult-functions","title":"Functions","text":""},{"location":"reference/optimise/#photoelastimetry.optimise.PressureFieldResult.get_stress_fields","title":"<code>get_stress_fields(coeffs)</code>","text":"<p>Reconstruct total stress fields from pressure coefficients and stored deviatoric parts.</p> <p>Sigma_tot = P + S_dev Note: If external potential V is used, it should be added externally to XX and YY.</p> Source code in <code>photoelastimetry/optimise.py</code> <pre><code>def get_stress_fields(self, coeffs):\n    \"\"\"\n    Reconstruct total stress fields from pressure coefficients and stored deviatoric parts.\n\n    Sigma_tot = P + S_dev\n    Note: If external potential V is used, it should be added externally to XX and YY.\n    \"\"\"\n    # Calculate P\n    P, _, _ = self.bspline_p.get_scalar_fields(coeffs)\n\n    # Combine\n    # s_xx_dev, s_yy_dev, s_xy_dev MUST be broadcastable or same shape\n    # They are stored as full maps.\n\n    sigma_xx = P + self.s_xx_dev\n    sigma_yy = P + self.s_yy_dev\n    sigma_xy = self.s_xy_dev\n\n    return sigma_xx, sigma_yy, sigma_xy\n</code></pre>"},{"location":"reference/optimise/#photoelastimetry.optimise.PressureFieldResult.project_stress_gradients","title":"<code>project_stress_gradients(grad_s_xx, grad_s_yy, grad_s_xy)</code>","text":"<p>Projections for regularization (if needed externally).</p> Source code in <code>photoelastimetry/optimise.py</code> <pre><code>def project_stress_gradients(self, grad_s_xx, grad_s_yy, grad_s_xy):\n    \"\"\"Projections for regularization (if needed externally).\"\"\"\n    # Gradient of Loss w.r.t Stresses -&gt; Coefficients\n    # Stress = P + S_dev\n    # dStress/dP = 1\n    # dLoss/dP = dLoss/dStress * 1\n\n    grad_P = grad_s_xx + grad_s_yy  # + 0 * grad_s_xy\n\n    # P = B * C\n    return self.bspline_p.project_scalar_gradients(grad_P, None, None)\n</code></pre>"},{"location":"reference/optimise/#photoelastimetry.optimise-functions","title":"Functions","text":""},{"location":"reference/optimise/#photoelastimetry.optimise.stress_to_principal_invariants","title":"<code>stress_to_principal_invariants(stress_map)</code>","text":"<p>Convert a stress map [sigma_xx, sigma_yy, sigma_xy] to (delta_sigma, theta).</p> <p>Parameters:</p> Name Type Description Default <code>stress_map</code> <code>ndarray</code> <p>Stress tensor map with shape (..., 3) ordered as [xx, yy, xy].</p> required <p>Returns:</p> Name Type Description <code>delta_sigma_map</code> <code>ndarray</code> <p>Principal stress difference sqrt((xx-yy)^2 + 4*xy^2).</p> <code>theta_map</code> <code>ndarray</code> <p>Principal stress angle 0.5atan2(2xy, xx-yy).</p> Source code in <code>photoelastimetry/optimise.py</code> <pre><code>def stress_to_principal_invariants(stress_map):\n    \"\"\"\n    Convert a stress map [sigma_xx, sigma_yy, sigma_xy] to (delta_sigma, theta).\n\n    Parameters\n    ----------\n    stress_map : ndarray\n        Stress tensor map with shape (..., 3) ordered as [xx, yy, xy].\n\n    Returns\n    -------\n    delta_sigma_map : ndarray\n        Principal stress difference sqrt((xx-yy)^2 + 4*xy^2).\n    theta_map : ndarray\n        Principal stress angle 0.5*atan2(2*xy, xx-yy).\n    \"\"\"\n    s_xx = stress_map[..., 0]\n    s_yy = stress_map[..., 1]\n    s_xy = stress_map[..., 2]\n\n    delta_sigma_map = np.sqrt((s_xx - s_yy) ** 2 + 4 * s_xy**2)\n    theta_map = 0.5 * np.arctan2(2 * s_xy, s_xx - s_yy)\n    return delta_sigma_map, theta_map\n</code></pre>"},{"location":"reference/optimise/#photoelastimetry.optimise.recover_mean_stress","title":"<code>recover_mean_stress(delta_sigma_map, theta_map, knot_spacing=20, spline_degree=3, boundary_mask=None, boundary_values=None, boundary_weight=1.0, regularisation_weight=0.0, regularisation_order=2, external_potential=None, max_iterations=100, tolerance=1e-05, initial_stress_map=None, verbose=True, debug=False, **kwargs)</code>","text":"<p>Recover the hydrostatic (mean) stress component P(x,y) given fixed deviatoric components.</p> <p>This solver assumes the deviatoric stress field (difference and orientation) provided as input is trusted and fixed. It solves for the scalar pressure field P(x,y) that best satisfies the stress equilibrium equations in a least-squares sense using a B-Spline representation.</p> <p>Stresses are constructed as:     sigma_xx = P(x,y) + s_xx_meas     sigma_yy = P(x,y) + s_yy_meas     sigma_xy = s_xy_meas</p> <p>Equilibrium requires:     d(sigma_xx)/dx + d(sigma_xy)/dy = 0  =&gt;  dP/dx = -d(s_xx_meas)/dx - d(s_xy_meas)/dy     d(sigma_xy)/dx + d(sigma_yy)/dy = 0  =&gt;  dP/dy = -d(s_xy_meas)/dx - d(s_yy_meas)/dy</p> <p>Parameters:</p> Name Type Description Default <code>delta_sigma_map</code> <code>ndarray</code> <p>Map of principal stress difference [H, W] (Pa).</p> required <code>theta_map</code> <code>ndarray</code> <p>Map of principal stress orientation [H, W] (radians).</p> required <code>knot_spacing</code> <code>int</code> <p>Spacing of B-spline knots in pixels.</p> <code>20</code> <code>boundary_mask</code> <code>ndarray(bool)</code> <p>Mask where specific stress component values should be enforced.</p> <code>None</code> <code>boundary_values</code> <code>dict</code> <p>Dictionary containing 'xx', 'yy', 'xy' keys with target boundary values maps (Pa). Only pixels where boundary_mask is True are used.</p> <code>None</code> <code>boundary_weight</code> <code>float</code> <p>Weight for boundary condition penalty.</p> <code>1.0</code> <code>regularisation_weight</code> <code>float</code> <p>Weight for smoothness regularisation on B-spline coefficients.</p> <code>0.0</code> <code>external_potential</code> <code>ndarray</code> <p>Scalar field V(x,y) [H, W] representing body force potential (e.g. -rhogy). This term is added to the equilibrium equations:     d(sigma_xx)/dx + ... + F_x = 0  (where F_x = -dV/dx) If external_potential represents V where F = -grad(V), then:     dP/dx = ... + dV/dx     dP/dy = ... + dV/dy Effectively, P_total = P_solved - V. However, the current implementation treats input V as adding to normal stresses directly? Let's assume standard gravity potential: sigma_ij_total = sigma_ij_effective + delta_ij * V? Or simply Body Forces F_i. If external_potential is provided as V (potential) such that F = -grad(V).</p> <code>None</code> <code>initial_stress_map</code> <code>ndarray</code> <p>Initial guess for stress field to seed P.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bspline</code> <code>BSplineScalar</code> <p>Fitted B-spline object for Pressure field.</p> <code>coeffs</code> <code>ndarray</code> <p>Coefficients for P.</p> Source code in <code>photoelastimetry/optimise.py</code> <pre><code>def recover_mean_stress(\n    delta_sigma_map,\n    theta_map,\n    knot_spacing=20,\n    spline_degree=3,\n    boundary_mask=None,\n    boundary_values=None,\n    boundary_weight=1.0,\n    regularisation_weight=0.0,\n    regularisation_order=2,\n    external_potential=None,\n    max_iterations=100,\n    tolerance=1e-5,\n    initial_stress_map=None,\n    verbose=True,\n    debug=False,\n    **kwargs,\n):\n    \"\"\"\n    Recover the hydrostatic (mean) stress component P(x,y) given fixed deviatoric components.\n\n    This solver assumes the deviatoric stress field (difference and orientation) provided\n    as input is trusted and fixed. It solves for the scalar pressure field P(x,y) that\n    best satisfies the stress equilibrium equations in a least-squares sense using a B-Spline\n    representation.\n\n    Stresses are constructed as:\n        sigma_xx = P(x,y) + s_xx_meas\n        sigma_yy = P(x,y) + s_yy_meas\n        sigma_xy = s_xy_meas\n\n    Equilibrium requires:\n        d(sigma_xx)/dx + d(sigma_xy)/dy = 0  =&gt;  dP/dx = -d(s_xx_meas)/dx - d(s_xy_meas)/dy\n        d(sigma_xy)/dx + d(sigma_yy)/dy = 0  =&gt;  dP/dy = -d(s_xy_meas)/dx - d(s_yy_meas)/dy\n\n    Parameters\n    ----------\n    delta_sigma_map : ndarray\n        Map of principal stress difference [H, W] (Pa).\n    theta_map : ndarray\n        Map of principal stress orientation [H, W] (radians).\n    knot_spacing : int\n        Spacing of B-spline knots in pixels.\n    boundary_mask : ndarray (bool), optional\n        Mask where specific stress component values should be enforced.\n    boundary_values : dict, optional\n        Dictionary containing 'xx', 'yy', 'xy' keys with target boundary values maps (Pa).\n        Only pixels where boundary_mask is True are used.\n    boundary_weight : float\n        Weight for boundary condition penalty.\n    regularisation_weight : float\n        Weight for smoothness regularisation on B-spline coefficients.\n    external_potential : ndarray, optional\n        Scalar field V(x,y) [H, W] representing body force potential (e.g. -rho*g*y).\n        This term is added to the equilibrium equations:\n            d(sigma_xx)/dx + ... + F_x = 0  (where F_x = -dV/dx)\n        If external_potential represents V where F = -grad(V), then:\n            dP/dx = ... + dV/dx\n            dP/dy = ... + dV/dy\n        Effectively, P_total = P_solved - V.\n        However, the current implementation treats input V as adding to normal stresses directly?\n        Let's assume standard gravity potential: sigma_ij_total = sigma_ij_effective + delta_ij * V?\n        Or simply Body Forces F_i.\n        If external_potential is provided as V (potential) such that F = -grad(V).\n    initial_stress_map : ndarray, optional\n        Initial guess for stress field to seed P.\n\n    Returns\n    -------\n    bspline : BSplineScalar\n        Fitted B-spline object for Pressure field.\n    coeffs : ndarray\n        Coefficients for P.\n    \"\"\"\n\n    H, W = delta_sigma_map.shape\n\n    if external_potential is not None:\n        external_potential = np.asarray(external_potential)\n\n    if external_potential is not None and external_potential.shape != (H, W):\n        raise ValueError(f\"external_potential must have shape {(H, W)}, got {external_potential.shape}\")\n\n    # 1. Compute trusted deviatoric components\n    # s_xx_dev = 0.5 * delta * cos(2theta)\n    # s_yy_dev = -0.5 * delta * cos(2theta)\n    # s_xy_dev = 0.5 * delta * sin(2theta)\n\n    cos_2t = np.cos(2 * theta_map)\n    sin_2t = np.sin(2 * theta_map)\n\n    s_xx_meas = 0.5 * delta_sigma_map * cos_2t\n    s_yy_meas = -0.5 * delta_sigma_map * cos_2t\n    s_xy_meas = 0.5 * delta_sigma_map * sin_2t\n\n    # Handle NaNs in input\n    valid_mask = ~(np.isnan(delta_sigma_map) | np.isnan(theta_map))\n    if external_potential is not None:\n        valid_mask &amp;= ~np.isnan(external_potential)\n\n    if verbose and not np.all(valid_mask):\n        print(f\"Mean Stress Solver: Ignoring {np.sum(~valid_mask)} pixels with NaN inputs.\")\n        # Fill NaNs with 0 (gradients will be messy at edges of NaNs, but masking handles loss)\n        s_xx_meas[~valid_mask] = 0\n        s_yy_meas[~valid_mask] = 0\n        s_xy_meas[~valid_mask] = 0\n\n    # 2. Compute target gradients for P\n    # Gradients of measured fields using central difference\n    # gradient returns list [d/dy, d/dx]\n    diff_s_xx = np.gradient(s_xx_meas)\n    ds_xx_dy, ds_xx_dx = diff_s_xx\n\n    diff_s_yy = np.gradient(s_yy_meas)\n    ds_yy_dy, ds_yy_dx = diff_s_yy\n\n    diff_s_xy = np.gradient(s_xy_meas)\n    ds_xy_dy, ds_xy_dx = diff_s_xy\n\n    # Equilibrium Targets:\n    # dP/dx = - (ds_xx/dx + ds_xy/dy) - F_x\n    # dP/dy = - (ds_xy/dx + ds_yy/dy) - F_y\n\n    # Body forces from external potential V\n    # F = -grad(V). So term -F becomes +grad(V)\n    # dP/dx_target = - (ds_xx/dx + ds_xy/dy) + dV/dx\n\n    # dP/dx_target = - (ds_xx/dx + ds_xy/dy)\n    # dP/dy_target = - (ds_xy/dx + ds_yy/dy)\n    # (Body forces handled by implicit cancellation or external addition)\n\n    target_grad_P_x = -(ds_xx_dx + ds_xy_dy)\n    target_grad_P_y = -(ds_xy_dx + ds_yy_dy)\n\n    if external_potential is not None:\n        safe_V = np.nan_to_num(external_potential, nan=0.0)\n        dV_dy, dV_dx = np.gradient(safe_V)\n        target_grad_P_x += dV_dx\n        target_grad_P_y += dV_dy\n\n    if verbose:\n        max_grad = np.max(np.sqrt(target_grad_P_x**2 + target_grad_P_y**2))\n        print(f\"Mean Stress Solver: Max target gradient {max_grad:.2e} Pa/px.\")\n\n    # Initialize B-Spline Scalara\n    bspline_backing = BSplineScalar((H, W), knot_spacing=knot_spacing, degree=spline_degree)\n\n    # Create Wrapper\n    bspline_wrapper = PressureFieldResult(bspline_backing, s_xx_meas, s_yy_meas, s_xy_meas)\n\n    has_pressure_bc_global = False\n    if boundary_mask is not None and boundary_values is not None:\n        if \"xx\" in boundary_values:\n            has_pressure_bc_global |= np.any(boundary_mask &amp; ~np.isnan(boundary_values[\"xx\"]))\n        if \"yy\" in boundary_values:\n            has_pressure_bc_global |= np.any(boundary_mask &amp; ~np.isnan(boundary_values[\"yy\"]))\n\n    if verbose:\n        print(\n            f\"Mean Stress Solver: Grid {H}x{W}, Knots {knot_spacing}px, \"\n            f\"Coeffs {bspline_backing.n_coeffs_y}x{bspline_backing.n_coeffs_x} ({bspline_backing.n_coeffs})\"\n        )\n\n    # Optimization counter\n    iteration_count = [0]\n\n    def loss_and_gradient(coeffs_flat):\n        iteration_count[0] += 1\n\n        # Calculate P and gradients from current spline\n        P, dP_dx, dP_dy = bspline_backing.get_scalar_fields(coeffs_flat)\n\n        # Residuals in gradients (Equilibrium violation)\n        res_grad_x = dP_dx - target_grad_P_x\n        res_grad_y = dP_dy - target_grad_P_y\n\n        # Mask invalid pixels (where input or gradients are bad)\n        # Note: np.gradient at edges is less accurate.\n        # We assume valid_mask covers the trust region.\n        res_grad_x[~valid_mask] = 0\n        res_grad_y[~valid_mask] = 0\n\n        # Loss function\n        loss = np.sum(res_grad_x**2 + res_grad_y**2)\n\n        # Gradients w.r.t P fields\n        # dL/d(dP/dx) = 2 * res_grad_x\n        # dL/d(dP/dy) = 2 * res_grad_y\n        # dL/dP = 0 (from equilibrium term)\n\n        grad_dP_dx = 2 * res_grad_x\n        grad_dP_dy = 2 * res_grad_y\n        grad_P = np.zeros_like(P)\n\n        # Boundary penalty on P values (Dirichlet conditions)\n        # If we have known stresses at boundaries:\n        # sigma_xx_bound = P + s_xx_meas (+ V if V used) =&gt; P_target = sigma_xx_bound - s_xx_meas (- V)\n\n        if boundary_mask is not None and boundary_values is not None:\n            # We enforce P to match implied pressure from boundary conditions\n            # Prioritize Normal stresses which give P directly\n\n            # Count how many conditions set P at each pixel\n            count_P = np.zeros_like(P, dtype=float)\n            sum_P_target = np.zeros_like(P)\n\n            V_term = external_potential if external_potential is not None else 0\n\n            if \"xx\" in boundary_values:\n                b_xx = boundary_values[\"xx\"]\n                if not np.all(np.isnan(b_xx)):  # If useful\n                    valid_b = ~np.isnan(b_xx) &amp; boundary_mask\n                    # P = sigma_xx - s_xx_dev - V\n                    p_from_xx = b_xx - s_xx_meas - V_term\n                    sum_P_target[valid_b] += p_from_xx[valid_b]\n                    count_P[valid_b] += 1\n\n            if \"yy\" in boundary_values:\n                b_yy = boundary_values[\"yy\"]\n                if not np.all(np.isnan(b_yy)):\n                    valid_b = ~np.isnan(b_yy) &amp; boundary_mask\n                    # P = sigma_yy - s_yy_dev - V\n                    p_from_yy = b_yy - s_yy_meas - V_term\n                    sum_P_target[valid_b] += p_from_yy[valid_b]\n                    count_P[valid_b] += 1\n\n            if \"xy\" in boundary_values:\n                # XY boundary condition does not constrain P directly!\n                # It constrains s_xy_meas, which is fixed input.\n                pass\n\n            # Average targets where consistent\n            has_target = count_P &gt; 0\n\n            if np.any(has_target):\n                P_target = np.zeros_like(P)\n                P_target[has_target] = sum_P_target[has_target] / count_P[has_target]\n\n                res_P = P - P_target\n\n                loss += boundary_weight * np.sum(res_P[has_target] ** 2)\n                grad_P[has_target] += 2 * boundary_weight * res_P[has_target]\n\n        elif boundary_mask is not None:\n            # Fallback\n            pass\n\n        # Gauge condition for under-constrained pressure: center mean pressure at zero.\n        if not has_pressure_bc_global:\n            n_valid = int(np.sum(valid_mask))\n            if n_valid &gt; 0:\n                mean_P = np.mean(P[valid_mask])\n                gauge_weight = 1.0\n                loss += gauge_weight * mean_P**2\n                grad_P[valid_mask] += (2 * gauge_weight * mean_P) / n_valid\n\n        # Backproject gradients to coefficients\n        grad_coeffs = bspline_backing.project_scalar_gradients(grad_P, grad_dP_dx, grad_dP_dy)\n\n        # Smoothness regularization\n        if regularisation_weight &gt; 0:\n            grad_coeffs += regularisation_weight * coeffs_flat  # Simple L2 Ridge\n            loss += 0.5 * regularisation_weight * np.sum(coeffs_flat**2)\n\n        if verbose and iteration_count[0] % 10 == 0:\n            print(f\"Mean Stress Solver Iteration {iteration_count[0]}, Loss: {loss:.6e}\", end=\"\\r\")\n\n        return loss, grad_coeffs\n\n    # Initialize coefficients\n    if initial_stress_map is not None:\n        # Estimate P form initial map\n        # initial_stress_map contains full [xx, yy, xy]\n        s_xx_init = initial_stress_map[:, :, 0]\n        s_yy_init = initial_stress_map[:, :, 1]\n\n        # P_init = (s_xx + s_yy)/2 - V? No, P is just (s_xx + s_yy)/2 - s_dev...\n        # s_xx = P + s_xx_dev =&gt; P = s_xx - s_xx_dev\n        # s_yy = P + s_yy_dev =&gt; P = s_yy - s_yy_dev\n        # Average: P = Mean_Stress - (s_xx_dev + s_yy_dev)/2\n        # But s_xx_dev = -s_yy_dev, so (s_xx_dev + s_yy_dev)/2 = 0\n        # So P_init = Mean_Stress = (s_xx + s_yy)/2\n\n        # We must subtract V if initial map includes V\n        V_init = external_potential if external_potential is not None else 0\n\n        P_init_field = (s_xx_init + s_yy_init) / 2.0 - V_init\n\n        # Fit B-spline coefficients to the initial pressure estimate for faster convergence.\n        initial_coeffs = bspline_backing.fit_scalar_field(P_init_field, mask=valid_mask, maxiter=100)\n    else:\n        rng = np.random.default_rng(42)\n        initial_coeffs = rng.normal(0, 1e-10, bspline_backing.n_coeffs)\n\n    # Optimization\n    res = scipy.optimize.minimize(\n        loss_and_gradient,\n        initial_coeffs,\n        method=\"L-BFGS-B\",\n        jac=True,\n        options={\"maxiter\": max_iterations, \"ftol\": tolerance, \"disp\": verbose},\n    )\n\n    if verbose:\n        print(f\"\\nOptimization finished: {res.message}\")\n\n    # If pressure BCs do not pin the gauge, shift coefficients to exactly zero-mean pressure.\n    if not has_pressure_bc_global and np.any(valid_mask):\n        P_opt, _, _ = bspline_backing.get_scalar_fields(res.x)\n        mean_P = np.mean(P_opt[valid_mask])\n        res.x = res.x - mean_P\n\n    return bspline_wrapper, res.x\n</code></pre>"},{"location":"reference/plotting/","title":"plotting","text":"<p>Visualization utilities and colormaps.</p> <p>This module provides specialized plotting functions and colormaps for visualizing stress fields and photoelastic data.</p>"},{"location":"reference/plotting/#photoelastimetry.plotting","title":"<code>plotting</code>","text":""},{"location":"reference/plotting/#photoelastimetry.plotting-functions","title":"Functions","text":""},{"location":"reference/plotting/#photoelastimetry.plotting.virino","title":"<code>virino()</code>","text":"<p>Defines the virino colormap, useful for plotting angular data.</p> <p>Returns:     The virino colormap</p> Source code in <code>photoelastimetry/plotting.py</code> <pre><code>def virino():\n    \"\"\"\n    Defines the virino colormap, useful for plotting angular data.\n\n    Returns:\n        The virino colormap\n    \"\"\"\n\n    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"virino\", _virino_list)\n    return cmap\n</code></pre>"},{"location":"reference/plotting/#photoelastimetry.plotting.plot_optimization_history","title":"<code>plot_optimization_history(history, S_m_hat, filename=None)</code>","text":"<p>Plot the evolution of stress components and Stokes parameters during optimization.</p> <p>Parameters:</p> Name Type Description Default <code>history</code> <code>dict</code> <p>Dictionary containing optimization history with keys: - 'all_paths': list of dicts, each containing optimization path data - 'best_path_index': index of the path that led to the best solution</p> required <code>S_m_hat</code> <code>ndarray</code> <p>Measured normalised Stokes components, shape (3, 2) for RGB channels. Used to show target values.</p> required <code>filename</code> <code>str</code> <p>If provided, save figure to this filename instead of displaying.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>The figure object.</p> Source code in <code>photoelastimetry/plotting.py</code> <pre><code>def plot_optimization_history(history, S_m_hat, filename=None):\n    \"\"\"\n    Plot the evolution of stress components and Stokes parameters during optimization.\n\n    Parameters\n    ----------\n    history : dict\n        Dictionary containing optimization history with keys:\n        - 'all_paths': list of dicts, each containing optimization path data\n        - 'best_path_index': index of the path that led to the best solution\n    S_m_hat : ndarray\n        Measured normalised Stokes components, shape (3, 2) for RGB channels.\n        Used to show target values.\n    filename : str, optional\n        If provided, save figure to this filename instead of displaying.\n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure\n        The figure object.\n    \"\"\"\n    all_paths = history[\"all_paths\"]\n    best_path_index = history[\"best_path_index\"]\n\n    colors_rgb = [\"red\", \"green\", \"blue\"]\n\n    fig = plt.figure(figsize=(16, 10))\n    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n\n    # Plot 1: Stress components evolution (all paths)\n    ax1 = fig.add_subplot(gs[0, :])\n    for i, path in enumerate(all_paths):\n        stress_params = path[\"stress_params\"]\n        n_iter = len(stress_params)\n        iterations = np.arange(n_iter)\n        is_best = path[\"is_best\"]\n        alpha = 0.8 if is_best else 0.1\n        linewidth = 2 if is_best else 0.1\n        linestyle = \"-\" if is_best else \"-\"\n        markersize = 2 if is_best else 0.1\n\n        ax1.plot(\n            iterations,\n            stress_params[:, 0],\n            \"o-\",\n            alpha=alpha,\n            markersize=markersize,\n            linewidth=linewidth,\n            color=\"C0\",\n        )\n        ax1.plot(\n            iterations,\n            stress_params[:, 1],\n            \"s-\",\n            alpha=alpha,\n            markersize=markersize,\n            linewidth=linewidth,\n            color=\"C1\",\n        )\n        ax1.plot(\n            iterations,\n            stress_params[:, 2],\n            \"^-\",\n            alpha=alpha,\n            markersize=markersize,\n            linewidth=linewidth,\n            color=\"C2\",\n        )\n\n    # Add legend (using best path)\n    best_path = all_paths[best_path_index]\n    ax1.plot([], [], \"o-\", color=\"C0\", label=\"\u03c3_xx\", linewidth=2)\n    ax1.plot([], [], \"s-\", color=\"C1\", label=\"\u03c3_yy\", linewidth=2)\n    ax1.plot([], [], \"^-\", color=\"C2\", label=\"\u03c3_xy\", linewidth=2)\n    ax1.set_xlabel(\"Iteration (within each path)\")\n    ax1.set_ylabel(\"Stress (Pa)\")\n    ax1.set_title(\n        f\"Evolution of Stress Components ({len(all_paths)} optimization paths, best path highlighted)\"\n    )\n    ax1.legend()\n    # ax1.grid(True, alpha=0.3)\n\n    # Plot 2: Residual evolution (all paths)\n    ax2 = fig.add_subplot(gs[1, 0])\n    for i, path in enumerate(all_paths):\n        residuals = path[\"residuals\"]\n        n_iter = len(residuals)\n        iterations = np.arange(n_iter)\n        is_best = path[\"is_best\"]\n        alpha = 0.8 if is_best else 0.2\n        linewidth = 2 if is_best else 0.5\n\n        ax2.semilogy(\n            iterations, residuals, \"o-\", alpha=alpha, markersize=2 if is_best else 1, linewidth=linewidth\n        )\n    ax2.set_xlabel(\"Iteration (within each path)\")\n    ax2.set_ylabel(\"Residual (log scale)\")\n    ax2.set_title(\"Residual Evolution (All Paths)\")\n    ax2.grid(True, alpha=0.3)\n\n    # Plot 3: S1_hat evolution for RGB channels (best path only)\n    ax3 = fig.add_subplot(gs[1, 1])\n    S_predicted = best_path[\"S_predicted\"]\n    n_iter = len(S_predicted)\n    iterations = np.arange(n_iter)\n    for c, color in enumerate(colors_rgb):\n        ax3.plot(\n            iterations,\n            S_predicted[:, c, 0],\n            \"o-\",\n            color=color,\n            alpha=0.7,\n            markersize=2,\n            label=f\"{color.upper()} predicted\",\n        )\n        ax3.axhline(\n            S_m_hat[c, 0],\n            color=color,\n            linestyle=\"--\",\n            linewidth=2,\n            alpha=0.8,\n            label=f\"{color.upper()} measured\",\n        )\n    ax3.set_xlabel(\"Iteration\")\n    ax3.set_ylabel(\"S1_hat (normalised)\")\n    ax3.set_title(\"S1_hat Evolution - Best Path (RGB Channels)\")\n    ax3.legend(fontsize=8, ncol=2)\n    ax3.grid(True, alpha=0.3)\n\n    # Plot 4: S2_hat evolution for RGB channels (best path only)\n    ax4 = fig.add_subplot(gs[1, 2])\n    for c, color in enumerate(colors_rgb):\n        ax4.plot(\n            iterations,\n            S_predicted[:, c, 1],\n            \"s-\",\n            color=color,\n            alpha=0.7,\n            markersize=2,\n            label=f\"{color.upper()} predicted\",\n        )\n        ax4.axhline(\n            S_m_hat[c, 1],\n            color=color,\n            linestyle=\"--\",\n            linewidth=2,\n            alpha=0.8,\n            label=f\"{color.upper()} measured\",\n        )\n    ax4.set_xlabel(\"Iteration\")\n    ax4.set_ylabel(\"S2_hat (normalised)\")\n    ax4.set_title(\"S2_hat Evolution - Best Path (RGB Channels)\")\n    ax4.legend(fontsize=8, ncol=2)\n    ax4.grid(True, alpha=0.3)\n\n    # Plot 5: 3D trajectory in stress space (all paths)\n    ax5 = fig.add_subplot(gs[2, 0], projection=\"3d\")\n    for i, path in enumerate(all_paths):\n        stress_params = path[\"stress_params\"]\n        n_iter = len(stress_params)\n        iterations_path = np.arange(n_iter)\n        is_best = path[\"is_best\"]\n        alpha = 0.7 if is_best else 0.15\n        linewidth = 2 if is_best else 0.5\n        s = 20 if is_best else 5\n\n        scatter = ax5.scatter(\n            stress_params[:, 0],\n            stress_params[:, 1],\n            stress_params[:, 2],\n            c=iterations_path,\n            cmap=\"viridis\",\n            s=s,\n            alpha=alpha,\n        )\n        ax5.plot(\n            stress_params[:, 0],\n            stress_params[:, 1],\n            stress_params[:, 2],\n            \"k-\",\n            alpha=alpha,\n            linewidth=linewidth,\n        )\n\n        # Mark start and end points for best path only\n        if is_best:\n            ax5.scatter(\n                stress_params[0, 0],\n                stress_params[0, 1],\n                stress_params[0, 2],\n                color=\"green\",\n                s=100,\n                marker=\"o\",\n                label=\"Start (best)\",\n                edgecolors=\"black\",\n            )\n            ax5.scatter(\n                stress_params[-1, 0],\n                stress_params[-1, 1],\n                stress_params[-1, 2],\n                color=\"red\",\n                s=100,\n                marker=\"*\",\n                label=\"End (best)\",\n                edgecolors=\"black\",\n            )\n\n    ax5.set_xlabel(\"\u03c3_xx (Pa)\")\n    ax5.set_ylabel(\"\u03c3_yy (Pa)\")\n    ax5.set_zlabel(\"\u03c3_xy (Pa)\")\n    ax5.set_title(f\"Optimization Trajectories in Stress Space ({len(all_paths)} paths)\")\n    # ax5.legend()\n    plt.colorbar(scatter, ax=ax5, label=\"Iteration\", shrink=0.6)\n\n    # Plot 6: Final comparison of measured vs predicted (best path)\n    ax6 = fig.add_subplot(gs[2, 1:])\n    x_pos = np.arange(6)\n    measured = np.concatenate([S_m_hat[:, 0], S_m_hat[:, 1]])\n    S_predicted_best = best_path[\"S_predicted\"]\n    predicted = np.concatenate([S_predicted_best[-1, :, 0], S_predicted_best[-1, :, 1]])\n\n    width = 0.35\n    ax6.bar(x_pos - width / 2, measured, width, label=\"Measured\", alpha=0.7, color=\"steelblue\")\n    ax6.bar(x_pos + width / 2, predicted, width, label=\"Predicted (final)\", alpha=0.7, color=\"coral\")\n    ax6.set_xlabel(\"Stokes Component\")\n    ax6.set_ylabel(\"Normalised Value\")\n    ax6.set_title(\"Final Comparison: Measured vs Predicted Stokes Components (Best Path)\")\n    ax6.set_xticks(x_pos)\n    ax6.set_xticklabels([\"R S1\", \"G S1\", \"B S1\", \"R S2\", \"G S2\", \"B S2\"])\n    ax6.legend()\n    ax6.grid(True, alpha=0.3, axis=\"y\")\n\n    # Add summary text\n    final_residual = best_path[\"residuals\"][-1]\n    final_stress = best_path[\"stress_params\"][-1]\n    fig.text(\n        0.02,\n        0.98,\n        f\"Final residual: {final_residual:.2e}\\n\"\n        f\"Final \u03c3_xx: {final_stress[0]:.2e} Pa\\n\"\n        f\"Final \u03c3_yy: {final_stress[1]:.2e} Pa\\n\"\n        f\"Final \u03c3_xy: {final_stress[2]:.2e} Pa\\n\"\n        f\"Iterations: {n_iter}\",\n        verticalalignment=\"top\",\n        fontsize=10,\n        bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5),\n    )\n\n    if filename:\n        plt.savefig(filename, dpi=150, bbox_inches=\"tight\")\n        plt.close()\n    else:\n        plt.tight_layout()\n\n    return fig\n</code></pre>"},{"location":"reference/plotting/#photoelastimetry.plotting.plot_optimization_history_live","title":"<code>plot_optimization_history_live(history, S_m_hat, fig=None, axes=None)</code>","text":"<p>Create or update a live plot of optimization history (for interactive use).</p> <p>Parameters:</p> Name Type Description Default <code>history</code> <code>dict</code> <p>Dictionary containing optimization history (same format as plot_optimization_history).</p> required <code>S_m_hat</code> <code>ndarray</code> <p>Measured normalised Stokes components, shape (3, 2).</p> required <code>fig</code> <code>Figure</code> <p>Existing figure to update. If None, creates new figure.</p> <code>None</code> <code>axes</code> <code>list</code> <p>List of existing axes to update. If None, creates new axes.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>The figure object.</p> <code>axes</code> <code>list</code> <p>List of axes objects.</p> Source code in <code>photoelastimetry/plotting.py</code> <pre><code>def plot_optimization_history_live(history, S_m_hat, fig=None, axes=None):\n    \"\"\"\n    Create or update a live plot of optimization history (for interactive use).\n\n    Parameters\n    ----------\n    history : dict\n        Dictionary containing optimization history (same format as plot_optimization_history).\n    S_m_hat : ndarray\n        Measured normalised Stokes components, shape (3, 2).\n    fig : matplotlib.figure.Figure, optional\n        Existing figure to update. If None, creates new figure.\n    axes : list, optional\n        List of existing axes to update. If None, creates new axes.\n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure\n        The figure object.\n    axes : list\n        List of axes objects.\n    \"\"\"\n    stress_params = history[\"stress_params\"]\n    S_predicted = history[\"S_predicted\"]\n    residuals = history[\"residuals\"]\n    n_iter = len(residuals)\n    iterations = np.arange(n_iter)\n\n    colors_rgb = [\"red\", \"green\", \"blue\"]\n\n    # Create figure if needed\n    if fig is None:\n        fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n        fig.suptitle(\"Live Optimization Progress\", fontsize=14, fontweight=\"bold\")\n        plt.ion()  # Enable interactive mode\n    else:\n        # Clear existing axes\n        for ax in axes.flat:\n            ax.clear()\n\n    axes = axes.flatten()\n\n    # Plot 1: Stress components\n    axes[0].plot(iterations, stress_params[:, 0], \"o-\", label=\"\u03c3_xx\", alpha=0.7, markersize=3)\n    axes[0].plot(iterations, stress_params[:, 1], \"s-\", label=\"\u03c3_yy\", alpha=0.7, markersize=3)\n    axes[0].plot(iterations, stress_params[:, 2], \"^-\", label=\"\u03c3_xy\", alpha=0.7, markersize=3)\n    axes[0].set_xlabel(\"Iteration\")\n    axes[0].set_ylabel(\"Stress (Pa)\")\n    axes[0].set_title(\"Stress Components\")\n    axes[0].legend(fontsize=8)\n    axes[0].grid(True, alpha=0.3)\n\n    # Plot 2: Residual\n    axes[1].semilogy(iterations, residuals, \"ko-\", markersize=3)\n    axes[1].set_xlabel(\"Iteration\")\n    axes[1].set_ylabel(\"Residual (log)\")\n    axes[1].set_title(\"Residual Evolution\")\n    axes[1].grid(True, alpha=0.3)\n\n    # Plot 3: S1_hat for RGB\n    for c, color in enumerate(colors_rgb):\n        axes[2].plot(\n            iterations,\n            S_predicted[:, c, 0],\n            \"o-\",\n            color=color,\n            alpha=0.7,\n            markersize=2,\n            label=f\"{color[0].upper()} pred\",\n        )\n        axes[2].axhline(S_m_hat[c, 0], color=color, linestyle=\"--\", linewidth=2, alpha=0.5)\n    axes[2].set_xlabel(\"Iteration\")\n    axes[2].set_ylabel(\"S1_hat\")\n    axes[2].set_title(\"S1_hat (RGB)\")\n    axes[2].legend(fontsize=7)\n    axes[2].grid(True, alpha=0.3)\n\n    # Plot 4: S2_hat for RGB\n    for c, color in enumerate(colors_rgb):\n        axes[3].plot(\n            iterations,\n            S_predicted[:, c, 1],\n            \"s-\",\n            color=color,\n            alpha=0.7,\n            markersize=2,\n            label=f\"{color[0].upper()} pred\",\n        )\n        axes[3].axhline(S_m_hat[c, 1], color=color, linestyle=\"--\", linewidth=2, alpha=0.5)\n    axes[3].set_xlabel(\"Iteration\")\n    axes[3].set_ylabel(\"S2_hat\")\n    axes[3].set_title(\"S2_hat (RGB)\")\n    axes[3].legend(fontsize=7)\n    axes[3].grid(True, alpha=0.3)\n\n    # Plot 5: Trajectory projection (sigma_xx vs sigma_yy)\n    axes[4].plot(stress_params[:, 0], stress_params[:, 1], \"o-\", markersize=3, alpha=0.7, color=\"navy\")\n    axes[4].scatter(\n        stress_params[0, 0],\n        stress_params[0, 1],\n        color=\"green\",\n        s=100,\n        marker=\"o\",\n        label=\"Start\",\n        edgecolors=\"black\",\n        zorder=5,\n    )\n    axes[4].scatter(\n        stress_params[-1, 0],\n        stress_params[-1, 1],\n        color=\"red\",\n        s=100,\n        marker=\"*\",\n        label=\"End\",\n        edgecolors=\"black\",\n        zorder=5,\n    )\n    axes[4].set_xlabel(\"\u03c3_xx (Pa)\")\n    axes[4].set_ylabel(\"\u03c3_yy (Pa)\")\n    axes[4].set_title(\"Stress Trajectory (xy plane)\")\n    axes[4].legend(fontsize=8)\n    axes[4].grid(True, alpha=0.3)\n\n    # Plot 6: Final comparison\n    x_pos = np.arange(6)\n    measured = np.concatenate([S_m_hat[:, 0], S_m_hat[:, 1]])\n    predicted = np.concatenate([S_predicted[-1, :, 0], S_predicted[-1, :, 1]])\n\n    width = 0.35\n    axes[5].bar(x_pos - width / 2, measured, width, label=\"Measured\", alpha=0.7, color=\"steelblue\")\n    axes[5].bar(x_pos + width / 2, predicted, width, label=\"Predicted\", alpha=0.7, color=\"coral\")\n    axes[5].set_xlabel(\"Component\")\n    axes[5].set_ylabel(\"Value\")\n    axes[5].set_title(\"Measured vs Predicted\")\n    axes[5].set_xticks(x_pos)\n    axes[5].set_xticklabels([\"RS1\", \"GS1\", \"BS1\", \"RS2\", \"GS2\", \"BS2\"], fontsize=8)\n    axes[5].legend(fontsize=8)\n    axes[5].grid(True, alpha=0.3, axis=\"y\")\n\n    fig.tight_layout()\n    fig.canvas.draw()\n    fig.canvas.flush_events()\n\n    return fig, axes.reshape(2, 3)\n</code></pre>"},{"location":"reference/seeding/","title":"seeding","text":"<p>Phase-decomposed seeding utilities used to initialize stress inversion.</p>"},{"location":"reference/seeding/#photoelastimetry.seeding","title":"<code>seeding</code>","text":"<p>Phase decomposed seeding for stress initialisation.</p> <p>This module implements the phase decomposed seeding method described in the paper to provide accurate initial estimates for stress optimization algorithms.</p>"},{"location":"reference/seeding/#photoelastimetry.seeding-functions","title":"Functions","text":""},{"location":"reference/seeding/#photoelastimetry.seeding.invert_wrapped_retardance","title":"<code>invert_wrapped_retardance(S_m_hat, S_i_hat)</code>","text":"<p>Invert measured Stokes parameters to get wrapped retardance and orientation.</p> <p>Parameters:</p> Name Type Description Default <code>S_m_hat</code> <code>ndarray</code> <p>Measured normalised Stokes parameters [S1, S2] for each channel. Shape: (..., n_wavelengths, 2)</p> required <code>S_i_hat</code> <code>ndarray</code> <p>Input normalised Stokes parameter [S1, S2, S3].</p> required <p>Returns:</p> Name Type Description <code>theta</code> <code>float</code> <p>Principal stress orientation in radians [0, pi/2].</p> <code>delta_wrap</code> <code>ndarray</code> <p>Wrapped retardance [0, pi] for each channel. Shape: (..., n_wavelengths)</p> Source code in <code>photoelastimetry/seeding.py</code> <pre><code>def invert_wrapped_retardance(S_m_hat, S_i_hat):\n    \"\"\"\n    Invert measured Stokes parameters to get wrapped retardance and orientation.\n\n    Parameters\n    ----------\n    S_m_hat : ndarray\n        Measured normalised Stokes parameters [S1, S2] for each channel.\n        Shape: (..., n_wavelengths, 2)\n    S_i_hat : ndarray\n        Input normalised Stokes parameter [S1, S2, S3].\n\n    Returns\n    -------\n    theta : float\n        Principal stress orientation in radians [0, pi/2].\n    delta_wrap : ndarray\n        Wrapped retardance [0, pi] for each channel. Shape: (..., n_wavelengths)\n    \"\"\"\n\n    s1 = S_m_hat[..., 0]\n    s2 = S_m_hat[..., 1]\n\n    # Check for circular polarization input (large S3 component)\n    is_circular = abs(S_i_hat[2]) &gt; 0.9\n\n    if is_circular:\n        # Circular polarisation implementation\n        # Reference: \"Advancing instantaneous photoelastic method with color polarization camera\", Zhang et al.\n\n        S3_in = S_i_hat[2]\n\n        # Calculate theta\n        # General case for S3_in (can be +1 or -1)\n        # S1 = S3_in * sin(2theta) * sin(delta)\n        # S2 = -S3_in * cos(2theta) * sin(delta)\n        #\n        # We want to recover 2theta.\n        # S1 = -S3_in * sin(2theta) * sin(delta)\n        # S2 = S3_in * cos(2theta) * sin(delta)\n        #\n        # sin(2theta) ~ -S1 / S3_in\n        # cos(2theta) ~ S2 / S3_in\n        # 2theta = atan2(-S1/S3_in, S2/S3_in) = atan2(-S1*S3_in, S2*S3_in)\n\n        # Sum vectors over wavelengths for robustness\n        # Note: arctan2(y, x). y ~ sin(2theta), x ~ cos(2theta)\n        # S1 ~ sin(2theta), S2 ~ -cos(2theta)\n        # =&gt; x (cos) ~ -S2, y (sin) ~ S1\n\n        x_sum = np.sum(-s2 * S3_in, axis=-1)\n        y_sum = np.sum(s1 * S3_in, axis=-1)\n        theta = 0.5 * np.arctan2(y_sum, x_sum)\n\n        # Calculate delta (wrapped)\n        # Magnitude = |sin(delta)| =&gt; delta_wrap in [0, pi/2]\n        magnitude = np.sqrt(s1**2 + s2**2)\n        magnitude = np.clip(magnitude, 0, 1)\n        delta_wrap = np.arcsin(magnitude)\n\n        return theta, delta_wrap\n\n    S1_in = S_i_hat[0]\n    S2_in = S_i_hat[1]\n\n    # Calculate alpha (input polarisation angle) from Stokes parameters\n    alpha = 0.5 * np.arctan2(S2_in, S1_in)\n\n    # Calculate difference vector components\n    dx = s2 - S2_in\n    dy = S1_in - s1\n\n    # Sum vectors over wavelengths to handle wrap-around and weight by signal strength\n    x_sum = np.sum(dx, axis=-1)\n    y_sum = np.sum(dy, axis=-1)\n\n    # 2*theta = atan2(Y, X)\n    theta_mean = 0.5 * np.arctan2(y_sum, x_sum)\n    sin_weight = np.abs(np.sin(2 * (theta_mean - alpha)))\n    R = np.sqrt(dx**2 + dy**2)\n    raw_magnitude = R / 2.0\n\n    # Avoid division by zero at isoclinics (where W -&gt; 0)\n    sin_weight_expanded = sin_weight[..., np.newaxis]\n\n    # Use where to handle safe division\n    sin_sq_delta_2 = np.divide(raw_magnitude, sin_weight_expanded, where=(sin_weight_expanded &gt; 1e-3))\n\n    # If too close to isoclinic, fallback or set to 0\n    sin_sq_delta_2 = np.where(sin_weight_expanded &lt;= 1e-3, 0.0, sin_sq_delta_2)\n\n    # Clamp to [0, 1] for numerical stability\n    sin_sq_delta_2 = np.clip(sin_sq_delta_2, 0, 1)\n\n    delta_wrap = 2 * np.arcsin(np.sqrt(sin_sq_delta_2))\n\n    # theta = 0.5 * np.arctan2(\n    #     y_sum * np.mean(np.sin(delta_wrap), axis=-1), x_sum * np.mean(np.sin(delta_wrap), axis=-1)\n    # )\n    theta = theta_mean  # Using mean theta directly\n\n    return theta, delta_wrap\n</code></pre>"},{"location":"reference/seeding/#photoelastimetry.seeding.resolve_fringe_orders","title":"<code>resolve_fringe_orders(delta_wrap, wavelengths, C_values, nu, L, sigma_max=None, n_max=6, is_circular=False)</code>","text":"<p>Resolve fringe orders using multi-wavelength consistency.</p> <p>Parameters:</p> Name Type Description Default <code>delta_wrap</code> <code>ndarray</code> <p>Wrapped retardance for each wavelength. Shape (..., n_wavelengths)</p> required <code>wavelengths</code> <code>ndarray</code> <p>Wavelengths in meters.</p> required <code>C_values</code> <code>ndarray</code> <p>Stress-optic coefficients.</p> required <code>nu</code> <code>float</code> <p>Solid fraction.</p> required <code>L</code> <code>float</code> <p>Thickness.</p> required <code>sigma_max</code> <code>float</code> <p>Maximum expected stress difference (Pa).</p> <code>None</code> <code>n_max</code> <code>int</code> <p>Maximum fringe order to search.</p> <code>6</code> <code>is_circular</code> <code>bool</code> <p>Whether the input data is from a circular polariscope (affects wrapping strategies).</p> <code>False</code> <p>Returns:</p> Name Type Description <code>delta_sigma</code> <code>float or ndarray</code> <p>Estimated stress difference.</p> Source code in <code>photoelastimetry/seeding.py</code> <pre><code>def resolve_fringe_orders(\n    delta_wrap, wavelengths, C_values, nu, L, sigma_max=None, n_max=6, is_circular=False\n):\n    \"\"\"\n    Resolve fringe orders using multi-wavelength consistency.\n\n    Parameters\n    ----------\n    delta_wrap : ndarray\n        Wrapped retardance for each wavelength. Shape (..., n_wavelengths)\n    wavelengths : ndarray\n        Wavelengths in meters.\n    C_values : ndarray\n        Stress-optic coefficients.\n    nu : float\n        Solid fraction.\n    L : float\n        Thickness.\n    sigma_max : float, optional\n        Maximum expected stress difference (Pa).\n    n_max : int\n        Maximum fringe order to search.\n    is_circular : bool, optional\n        Whether the input data is from a circular polariscope (affects wrapping strategies).\n\n    Returns\n    -------\n    delta_sigma : float or ndarray\n        Estimated stress difference.\n    \"\"\"\n    # Ensure inputs are arrays\n    delta_wrap = np.asarray(delta_wrap)\n    wavelengths = np.asarray(wavelengths)\n    C_values = np.asarray(C_values)\n\n    n_channels = wavelengths.shape[0]\n    base_shape = delta_wrap.shape[:-1]\n\n    # Flatten pixel dimensions for vectorized processing\n    if len(base_shape) &gt; 0:\n        n_pixels = np.prod(base_shape)\n        d_wrap_flat = delta_wrap.reshape(n_pixels, n_channels)\n    else:\n        n_pixels = 1\n        d_wrap_flat = delta_wrap.reshape(1, n_channels)\n\n    # Calculate factor for delta -&gt; sigma conversion\n    factor = wavelengths / (2 * np.pi * C_values * nu * L)\n\n    # Pre-generate search strategies for one channel\n    channel_strategies_indices = []\n    candidate_stresses = []\n\n    # Pre-calculate all possible stress candidates for each channel\n    # This avoids recomputing them N^2 times in the inner loop\n    for c in range(n_channels):\n        strategies = []\n        if is_circular:\n            # Circular: k*pi +/- delta\n            for k in range(2 * n_max + 2):\n                strategies.append((np.pi * k, 1.0))\n                if k &gt; 0:\n                    strategies.append((np.pi * k, -1.0))\n        else:\n            # Linear: 2*pi*n +/- delta\n            n_vals = np.arange(n_max + 1)\n            for n in n_vals:\n                strategies.append((2 * np.pi * n, 1.0))\n                for n in n_vals:\n                    strategies.append((2 * np.pi * (n + 1), -1.0))\n\n        # Remove duplicates if any (though construction avoids them mostly)\n        # Calculate candidates for this channel\n        # Shape: (n_strategies, n_pixels)\n        c_candidates = []\n        effective_strategies = []\n\n        for idx, (shift, sign) in enumerate(strategies):\n            s = factor[c] * (shift + sign * d_wrap_flat[:, c])\n            c_candidates.append(s)\n            effective_strategies.append(idx)\n\n        candidate_stresses.append(np.array(c_candidates))\n        channel_strategies_indices.append(range(len(effective_strategies)))\n\n    import itertools\n\n    best_metric = np.full(n_pixels, np.inf)\n    best_indices = np.zeros((n_pixels, n_channels), dtype=int)\n\n    # Convert to list of arrays for faster indexing\n    candidates_arrays = candidate_stresses  # List of (N_strat, N_pixels)\n\n    # Iterate over all combinations of strategy INDICES\n    for combo_indices in itertools.product(*channel_strategies_indices):\n        # combo_indices is tuple (i, j, k)\n\n        # Retrieve precomputed stresses (no compute here, just lookup)\n        # s0, s1, s2...\n        current_stresses_list = [candidates_arrays[c][idx] for c, idx in enumerate(combo_indices)]\n\n        # Stack to (n_channels, n_pixels) -&gt; Transpose to (n_pixels, n_channels)\n        # Actually keeping as list of arrays is fine for math\n\n        # Check sigma_max constraint\n        if sigma_max is not None:\n            # Efficient check: all must be &lt; limit\n            # AND all must be &gt; 0 (stress difference is positive)\n            limit = sigma_max * 1.5\n            is_valid = True\n            for s in current_stresses_list:\n                # We can check validity per pixel\n                # But to save doing math on invalid pixels, we compute a mask\n                pass\n\n            # Perform validity check vectorized\n            # Stack for vectorized operations: shape (n_channels, n_pixels)\n            # This stack is fast enough?\n            stresses_stack = np.stack(current_stresses_list, axis=0)  # (Channels, Pixels)\n\n            valid_mask = np.all((stresses_stack &lt; limit) &amp; (stresses_stack &gt; -1e-10), axis=0)\n\n            if not np.any(valid_mask):\n                continue\n\n            # Only compute metric for valid pixels\n            # Metric: Sum of Squared Differences (proportional to variance)\n            # SSD = sum((x - mean)^2)\n            # For 3 values: (a-b)^2 + (b-c)^2 + (c-a)^2 is proportional to variance\n\n            # Using vectorized variance is fine if masked\n            # var(axis=0) on stack\n\n            stresses_valid = stresses_stack[:, valid_mask]\n            metric = np.var(stresses_valid, axis=0)\n\n            # Compare with best\n            current_best_valid = best_metric[valid_mask]\n            improvement_mask = metric &lt; current_best_valid\n\n            # Where we have valid pixels that improve on the metric:\n            # We need to map back to original indices\n            # valid_mask is size n_pixels (boolean)\n            # improvement_mask is size count_nonzero(valid_mask)\n\n            # Indices in the compressed array\n            # We want indices in the full array where (valid &amp; improvement)\n\n            # Full boolean mask\n            update_mask = np.zeros(n_pixels, dtype=bool)\n            update_mask[valid_mask] = improvement_mask\n\n            if np.any(update_mask):\n                best_metric[update_mask] = metric[improvement_mask]\n                best_indices[update_mask] = combo_indices\n\n        else:\n            # Similar logic without bounds check\n            stresses_stack = np.stack(current_stresses_list, axis=0)\n            metric = np.var(stresses_stack, axis=0)\n            update_mask = metric &lt; best_metric\n            best_metric[update_mask] = metric[update_mask]\n            best_indices[update_mask] = combo_indices\n\n    # Reconstruct best comparison\n    # best_indices shape (n_pixels, n_channels)\n    final_stresses = np.zeros((n_pixels, n_channels))\n    for c in range(n_channels):\n        # Advanced indexing: valid strategy index per pixel\n        strat_indices = best_indices[:, c]\n        # candidate_stresses[c] has shape (N_strat, n_pixels)\n        # We need to pick element [strat_indices[p], p] for each pixel p\n        # Row indices: strat_indices\n        # Col indices: arange(n_pixels)\n        final_stresses[:, c] = candidates_arrays[c][strat_indices, np.arange(n_pixels)]\n\n    # Final median\n    best_delta_sigma = np.median(final_stresses, axis=1)\n\n    # Reshape back to original shape\n    if len(base_shape) &gt; 0:\n        return best_delta_sigma.reshape(base_shape)\n    else:\n        return best_delta_sigma.item()\n</code></pre>"},{"location":"reference/seeding/#photoelastimetry.seeding.initialise_stress_tensor","title":"<code>initialise_stress_tensor(delta_sigma, theta, K=1)</code>","text":"<p>Initialise stress tensor components assuming a principal stress ratio K. Under these conditions, the stresses are:  - sigma_1 = delta_sigma / (1 - K)  - sigma_2 = K * sigma_1  - p = (sigma_1 + sigma_2) / 2  - sigma_xx = p + (delta_sigma / 2) * cos(2theta)  - sigma_yy = p - (delta_sigma / 2) * cos(2theta)  - sigma_xy = (delta_sigma / 2) * sin(2*theta)</p> <p>Parameters:</p> Name Type Description Default <code>delta_sigma</code> <code>float</code> <p>Stress difference.</p> required <code>theta</code> <code>float</code> <p>Orientation.</p> required <p>Returns:</p> Name Type Description <code>stress</code> <code>ndarray</code> <p>Stress components [sigma_xx, sigma_yy, sigma_xy].</p> Source code in <code>photoelastimetry/seeding.py</code> <pre><code>def initialise_stress_tensor(delta_sigma, theta, K=1):\n    \"\"\"\n    Initialise stress tensor components assuming a principal stress ratio K. Under these conditions, the stresses are:\n     - sigma_1 = delta_sigma / (1 - K)\n     - sigma_2 = K * sigma_1\n     - p = (sigma_1 + sigma_2) / 2\n     - sigma_xx = p + (delta_sigma / 2) * cos(2*theta)\n     - sigma_yy = p - (delta_sigma / 2) * cos(2*theta)\n     - sigma_xy = (delta_sigma / 2) * sin(2*theta)\n\n    Parameters\n    ----------\n    delta_sigma : float\n        Stress difference.\n    theta : float\n        Orientation.\n\n    Returns\n    -------\n    stress : ndarray\n        Stress components [sigma_xx, sigma_yy, sigma_xy].\n    \"\"\"\n\n    sigma_1 = delta_sigma / (1 - K)\n    sigma_2 = K * sigma_1\n    p = (sigma_1 + sigma_2) / 2\n    cos_2theta = np.cos(2 * theta)\n    sin_2theta = np.sin(2 * theta)\n    sigma_xx = p + (delta_sigma / 2) * cos_2theta\n    sigma_yy = p - (delta_sigma / 2) * cos_2theta\n    sigma_xy = (delta_sigma / 2) * sin_2theta\n\n    return np.array([sigma_xx, sigma_yy, sigma_xy])\n</code></pre>"},{"location":"reference/seeding/#photoelastimetry.seeding.phase_decomposed_seeding","title":"<code>phase_decomposed_seeding(data, wavelengths, C_values, nu, L, S_i_hat=None, sigma_max=None, n_max=6, K=0.5, correction_params=None)</code>","text":"<p>Compute initial stress guess using phase decomposed seeding method.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input image data.</p> required <code>wavelengths</code> <code>ndarray</code> <p>Wavelengths in meters.</p> required <code>C_values</code> <code>ndarray</code> <p>Stress-optic coefficients.</p> required <code>nu</code> <code>float</code> <p>Solid fraction.</p> required <code>L</code> <code>float</code> <p>Sample thickness in meters.</p> required <code>S_i_hat</code> <code>ndarray</code> <p>Incoming normalised Stokes vector.</p> <code>None</code> <code>sigma_max</code> <code>float</code> <p>Maximum allowed stress difference (Pa).</p> <code>None</code> <code>n_max</code> <code>int</code> <p>Maximum fringe order to search.</p> <code>6</code> <code>K</code> <code>float, optional. Default=0.5</code> <p>Principal stress ratio for initialisation.</p> <code>0.5</code> <code>correction_params</code> <code>dict</code> <p>Parameters for disorder correction: - enabled (bool): whether to apply correction - order_param (float): order parameter |m| [0, 1] - N (float, optional): number of encounters - d (float, optional): particle diameter (to calculate N)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>stress_map</code> <code>ndarray</code> <p>Initial stress map [H, W, 3].</p> Source code in <code>photoelastimetry/seeding.py</code> <pre><code>def phase_decomposed_seeding(\n    data,\n    wavelengths,\n    C_values,\n    nu,\n    L,\n    S_i_hat=None,\n    sigma_max=None,\n    n_max=6,\n    K=0.5,\n    correction_params=None,\n):\n    \"\"\"\n    Compute initial stress guess using phase decomposed seeding method.\n\n    Parameters\n    ----------\n    data : ndarray\n        Input image data.\n    wavelengths : ndarray\n        Wavelengths in meters.\n    C_values : ndarray\n        Stress-optic coefficients.\n    nu : float\n        Solid fraction.\n    L : float\n        Sample thickness in meters.\n    S_i_hat : ndarray, optional\n        Incoming normalised Stokes vector.\n    sigma_max : float, optional\n        Maximum allowed stress difference (Pa).\n    n_max : int\n        Maximum fringe order to search.\n    K : float, optional. Default=0.5\n        Principal stress ratio for initialisation.\n    correction_params : dict, optional\n        Parameters for disorder correction:\n        - enabled (bool): whether to apply correction\n        - order_param (float): order parameter |m| [0, 1]\n        - N (float, optional): number of encounters\n        - d (float, optional): particle diameter (to calculate N)\n\n    Returns\n    -------\n    stress_map : ndarray\n        Initial stress map [H, W, 3].\n    \"\"\"\n    # Flatten data for processing\n    H, W = data.shape[:2]\n\n    # Compute normalised Stokes for all pixels\n    # Function signature: compute_normalised_stokes(data, S_i_hat) -&gt; S_m_hat (H, W, n_wl, 2)\n    # Note: image.compute_normalised_stokes expects specific data format.\n    # Assuming standard format (H, W, n_wl, n_angles)\n\n    I_0 = data[..., 0]\n    I_45 = data[..., 1]\n    I_90 = data[..., 2]\n    I_135 = data[..., 3]\n\n    S0, S1, S2 = compute_stokes_components(I_0, I_45, I_90, I_135)\n    S1_hat, S2_hat = compute_normalised_stokes(S0, S1, S2)\n    S_m_hat = np.stack([S1_hat, S2_hat], axis=-1)\n\n    # Reshape for vectorized processing\n    S_flat = S_m_hat.reshape(-1, S_m_hat.shape[-2], S_m_hat.shape[-1])\n\n    if S_i_hat is None:\n        # Default: linear horizontal polarization\n        S_i_hat = np.array([1.0, 0.0, 0.0])\n\n    # Vectorized inversion\n    theta, delta_wrap = invert_wrapped_retardance(S_flat, S_i_hat)\n\n    is_circular = abs(S_i_hat[2]) &gt; 0.9\n\n    # Vectorized fringe resolution\n    delta_sigma = resolve_fringe_orders(\n        delta_wrap, wavelengths, C_values, nu, L, sigma_max, n_max, is_circular=is_circular\n    )\n\n    # Unflatten theta and delta_sigma\n    theta = theta.reshape(H, W)\n    delta_sigma = delta_sigma.reshape(H, W)\n\n    if is_circular:\n        # Re-calculate theta robustly using the resolved stress difference\n        # This handles the sign ambiguity of sin(delta) for each wavelength\n\n        # Compute theoretical delta for all pixels and wavelengths\n        # delta_sigma: (H, W) -&gt; (H, W, 1) to broadcast vs (3,)\n        delta_expected = (2 * np.pi * C_values * nu * L * delta_sigma[..., np.newaxis]) / wavelengths\n\n        # Determine sign of sin(delta)\n        sign_sin_delta = np.sign(np.sin(delta_expected))\n\n        # Retrieve Stokes components (H, W, n_wl)\n        s1 = S_m_hat[..., 0]\n        s2 = S_m_hat[..., 1]\n        S3_in = S_i_hat[2]\n\n        # Weighted vector sum for 2*theta\n        # Based on Mueller matrix in image.py:\n        # S1 = S3 * sin(2theta) * sin(delta)\n        # S2 = -S3 * cos(2theta) * sin(delta)\n        #\n        # sin(2theta) = S1 / (S3 * sin(delta)) ~ S1 * S3 * sgn(sin(delta))\n        # cos(2theta) = -S2 / (S3 * sin(delta)) ~ -S2 * S3 * sgn(sin(delta))\n\n        X = -s2 * S3_in * sign_sin_delta\n        Y = s1 * S3_in * sign_sin_delta\n\n        X_sum = np.sum(X, axis=-1)\n        Y_sum = np.sum(Y, axis=-1)\n\n        # 2*theta = atan2(Y, X)\n        theta = 0.5 * np.arctan2(Y_sum, X_sum)\n\n        # For stress tensor initialization (uses 2*theta), unwrapping is not strictly needed.\n        unwrapped_theta = theta\n    else:\n        unwrapped_theta = unwrap_angles_graph_cut(theta, quality=delta_sigma)\n\n    if correction_params and correction_params.get(\"unwrap_angles\", False):\n        unwrapped_theta = unwrap_angles_graph_cut(theta, quality=delta_sigma)\n\n    # Apply disorder correction if enabled\n    if correction_params and correction_params.get(\"enabled\", False):\n        order_param = correction_params.get(\"order_param\")\n\n        N = correction_params.get(\"N\")\n\n        if N is None and \"d\" in correction_params:\n            d = correction_params[\"d\"]\n            N = estimate_grain_encounters(nu, L, d)\n\n        if N is not None:\n            correction_factor = compute_disorder_correction(N, order_param)\n            delta_sigma *= correction_factor\n\n    # Vectorized stress tensor construction\n    # initialise_stress_tensor returns (3, N)\n    stress_components = initialise_stress_tensor(delta_sigma.flatten(), unwrapped_theta.flatten(), K)\n    # Reshape to (H, W, 3)\n    stress_map = np.moveaxis(stress_components, 0, -1).reshape(H, W, 3)\n\n    return stress_map\n</code></pre>"},{"location":"reference/unwrapping/","title":"unwrapping","text":"<p>Angle unwrapping helpers for orientation recovery.</p>"},{"location":"reference/unwrapping/#photoelastimetry.unwrapping","title":"<code>unwrapping</code>","text":""},{"location":"reference/unwrapping/#photoelastimetry.unwrapping-functions","title":"Functions","text":""},{"location":"reference/unwrapping/#photoelastimetry.unwrapping.unwrap_angles_graph_cut","title":"<code>unwrap_angles_graph_cut(angles, quality=None)</code>","text":"<p>Unwrap angles from the range [0, pi/2] to [0, pi] using a graph-cut method.</p> <p>This function formulates the unwrapping problem as a binary labeling problem (Markov Random Field), where for each pixel we decide whether to add 0 or pi/2 to the measured angle. The objective is to minimize the squared difference of the resulting angles between neighboring pixels.</p> <p>The energy function minimized is:     E(x) = sum_{neighbors i,j} Q_ij * (theta_new_i - theta_new_j)^2 where theta_new = theta_measured + x * pi/2, with x in {0, 1}.</p> <p>Parameters:</p> Name Type Description Default <code>angles</code> <code>array_like</code> <p>Input angles in radians, assumed to be in the range [0, pi/2]. Shape (H, W).</p> required <code>quality</code> <code>array_like</code> <p>Quality map of the same shape as angles. Higher values indicate higher confidence. If None, a uniform quality of 1.0 is used. The smoothness terms are weighted by the minimum quality of the two neighbors.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>unwrapped_angles</code> <code>ndarray</code> <p>The unwrapped angles in the range [0, pi]. Shape (H, W).</p> Source code in <code>photoelastimetry/unwrapping.py</code> <pre><code>def unwrap_angles_graph_cut(angles, quality=None):\n    \"\"\"\n    Unwrap angles from the range [0, pi/2] to [0, pi] using a graph-cut method.\n\n    This function formulates the unwrapping problem as a binary labeling problem (Markov Random Field),\n    where for each pixel we decide whether to add 0 or pi/2 to the measured angle.\n    The objective is to minimize the squared difference of the resulting angles between neighboring pixels.\n\n    The energy function minimized is:\n        E(x) = sum_{neighbors i,j} Q_ij * (theta_new_i - theta_new_j)^2\n    where theta_new = theta_measured + x * pi/2, with x in {0, 1}.\n\n    Parameters\n    ----------\n    angles : array_like\n        Input angles in radians, assumed to be in the range [0, pi/2].\n        Shape (H, W).\n    quality : array_like, optional\n        Quality map of the same shape as angles. Higher values indicate higher confidence.\n        If None, a uniform quality of 1.0 is used.\n        The smoothness terms are weighted by the minimum quality of the two neighbors.\n\n    Returns\n    -------\n    unwrapped_angles : ndarray\n        The unwrapped angles in the range [0, pi].\n        Shape (H, W).\n    \"\"\"\n    angles = np.array(angles, dtype=np.float64)\n    H, W = angles.shape\n\n    if quality is None:\n        quality = np.ones((H, W), dtype=np.float64)\n    else:\n        quality = np.array(quality, dtype=np.float64)\n\n    # The energy function decomposes into:\n    # E(x) = Constant + sum_i U_i(x_i) + sum_{i,j} W_ij * (x_i != x_j)\n    # Actually, for the squared difference metric:\n    # Pairwise term W_ij is constant Q_ij * pi^2/4 (symmetric).\n    # Unary term for node i comes from data differences with neighbors.\n    # U_i is the \"cost penalty\" for setting x_i = 1 relative to x_i = 0.\n\n    # Initialize capacities\n    # We will accumulate the 'terminal' capacities diffs here.\n    # Positive value means we add capacity to t-link to Sink (penalize 1).\n    # Negative value means we add capacity to t-link to Source (penalize 0).\n    unary_diff = np.zeros((H, W), dtype=np.float64)\n\n    # Parameters\n    PI = np.pi\n    W_coeff = PI**2 / 4.0\n\n    # --- Vertical Edges ---\n    # Neighbors (y, x) and (y+1, x)\n    # delta = theta(y) - theta(y+1)\n    delta_v = angles[:-1, :] - angles[1:, :]\n\n    # Weight Q_v = min(Q(y), Q(y+1))\n    # Using geometric mean or min? Min is standard for \"weakest link\".\n    q_v = np.minimum(quality[:-1, :], quality[1:, :])\n\n    # Term added to Energy:\n    # For pixel i=(y,x):   + Q * pi * delta * x_i\n    # For pixel j=(y+1,x): - Q * pi * delta * x_j\n    term_v = q_v * PI * delta_v\n\n    unary_diff[:-1, :] += term_v\n    unary_diff[1:, :] -= term_v\n\n    # Pairwise weights\n    weights_v = q_v * W_coeff\n\n    # --- Horizontal Edges ---\n    # Neighbors (y, x) and (y, x+1)\n    delta_h = angles[:, :-1] - angles[:, 1:]\n    q_h = np.minimum(quality[:, :-1], quality[:, 1:])\n\n    term_h = q_h * PI * delta_h\n\n    unary_diff[:, :-1] += term_h\n    unary_diff[:, 1:] -= term_h\n\n    weights_h = q_h * W_coeff\n\n    # --- Graph Construction ---\n    g = maxflow.Graph[float](H * W, H * W * 2)\n    nodeids = g.add_grid_nodes((H, W))\n\n    # Add n-links (edges between pixels)\n    # Structure for add_grid_edges:\n    # weights: array.\n    # For structure=structure, usually defining neighborhood.\n    # To add specific weights for vertical/horizontal, we might need separate calls or a constructed structure.\n    # The default structure is von Neumann (4-connected).\n    # add_grid_edges takes a single 'weights' array or one per direction.\n    # If using 'weights' as array, it usually assumes isotropic or requires complex setup.\n    # Easier way in PyMaxflow:\n    # add_grid_edges(nodeids, weights, structure, symmetric)\n    # If we pass a list of weight arrays?\n    # Documentation says: \"weights\" can be a scalar or a numpy array with the same shape as nodeids.\n    # If structure has multiple edges per node, how do we specify different weights?\n    # We can call add_grid_edges multiple times with different structures!\n\n    # Vertical edges: link (y,x) to (y+1,x). Structure: [0,0,0], [0,0,0], [0,1,0] ??\n    # PyMaxflow structure is array shape (3,3). Center is (1,1).\n    # Structure for down:\n    # [[0,0,0],\n    #  [0,0,0],\n    #  [0,1,0]]\n    # This connects (y,x) to (y+1, x).\n\n    s_vert = np.zeros((3, 3))\n    s_vert[2, 1] = 1  # Down\n\n    # Note: weights array must match nodeids shape, but for edges at boundary, they are ignored/handled.\n    # When using `add_grid_edges`, if we provide `weights` array of shape (H,W),\n    # it uses `weights[y,x]` as capacity for the edge starting at (y,x) defined by structure.\n    # So for structure \"Down\", weights[y,x] is cap for edge (y,x)-&gt;(y+1,x).\n    # We computed `weights_v` of shape (H-1, W). We need to pad it to (H,W).\n    # The last row won't have a down neighbor so value doesn't matter (or handled automatically).\n\n    w_v_padded = np.zeros((H, W), dtype=np.float64)\n    w_v_padded[:-1, :] = weights_v\n\n    g.add_grid_edges(nodeids, w_v_padded, structure=s_vert, symmetric=True)\n\n    # Horizontal edges: (y,x) to (y, x+1).\n    s_horiz = np.zeros((3, 3))\n    s_horiz[1, 2] = 1  # Right\n\n    w_h_padded = np.zeros((H, W), dtype=np.float64)\n    w_h_padded[:, :-1] = weights_h\n\n    g.add_grid_edges(nodeids, w_h_padded, structure=s_horiz, symmetric=True)\n\n    # --- Add t-links (Unary) ---\n    # unary_diff[i]: Cost difference (Cost1 - Cost0).\n    # If &gt; 0: prefer 0. Add cap to Link to Sink (1).\n    # If &lt; 0: prefer 1. Add cap to Link to Source (0).\n\n    # g.add_grid_tedges(nodeids, source_cap, sink_cap)\n    # source_cap: cost if node is 1 (cut source link? No, cut source link means node is disconnected from Source -&gt; node is Sink (1).\n    # Wait, terminology:\n    # Cap(S-&gt;i): If cut, $i$ becomes Sink.\n    # Cap(i-&gt;T): If cut, $i$ becomes Source.\n    # We want to minimize cost.\n    # If we want x=0 (Source), we want high Cap(i-&gt;T) or low Cap(S-&gt;i)?\n    # If we pick Source, we cut i-&gt;T. So we pay Cap(i-&gt;T).\n    # If we pick Sink, we cut S-&gt;i. We pay Cap(S-&gt;i).\n    # Cost(0) = Cap(i-&gt;T).\n    # Cost(1) = Cap(S-&gt;i).\n    # We have diff D = Cost(1) - Cost(0).\n    # If D &gt; 0 (Cost(1) &gt; Cost(0)), we prefer 0.\n    # We can set Cost(0)=0, Cost(1)=D.\n    # So Cap(i-&gt;T) = 0, Cap(S-&gt;i) = D.\n\n    # If D &lt; 0 (Cost(0) &gt; Cost(1)), we prefer 1.\n    # Cost(0) = -D, Cost(1) = 0.\n    # Cap(i-&gt;T) = -D, Cap(S-&gt;i) = 0.\n\n    # Source Capacity array (cost of being 1).\n    source_caps = np.maximum(unary_diff, 0)\n    # Sink Capacity array (cost of being 0).\n    sink_caps = np.maximum(-unary_diff, 0)\n\n    g.add_grid_tedges(nodeids, source_caps, sink_caps)\n\n    # Compute maxflow\n    g.maxflow()\n\n    # Get results\n    # get_grid_segments returns boolean array where True means Source (0)??\n    # Check PyMaxflow docs:\n    # \"False means the node is in the source segment, True means the node is in the sink segment.\" -&gt; Standard confusion.\n    # Actually usually 0/1.\n    # segment: \"returns the segment... 0 for source, 1 for sink\".\n\n    sgm = g.get_grid_segments(nodeids)\n    # sgm is boolean. True if Sink (1). False if Source (0).\n\n    # x_i corresponds to sgm.\n    # 0 -&gt; keep angle.\n    # 1 -&gt; add pi/2.\n\n    unwrapped = angles.copy()\n    unwrapped[sgm] += PI / 2.0\n\n    return unwrapped\n</code></pre>"},{"location":"reference/visualisation/","title":"visualisation","text":"<p>ASCII visualisation helpers for debugging boundary-condition setups.</p>"},{"location":"reference/visualisation/#photoelastimetry.visualisation","title":"<code>visualisation</code>","text":""},{"location":"reference/visualisation/#photoelastimetry.visualisation-functions","title":"Functions","text":""},{"location":"reference/visualisation/#photoelastimetry.visualisation.ascii_boundary_conditions","title":"<code>ascii_boundary_conditions(boundary_mask, boundary_values, title='Boundary Conditions', downsample_factor=None)</code>","text":"<p>Generate an ASCII representation of the boundary conditions.</p> <p>Parameters:</p> Name Type Description Default <code>boundary_mask</code> <code>ndarray(bool)</code> <p>[H, W] boolean mask of active boundary pixels.</p> required <code>boundary_values</code> <code>dict</code> <p>Dictionary with keys 'xx', 'yy', 'xy', containing [H, W] arrays or scalars. NaN values indicate 'unconstrained' at that pixel for that component.</p> required <code>title</code> <code>str</code> <p>Title for the plot.</p> <code>'Boundary Conditions'</code> <code>downsample_factor</code> <code>int</code> <p>Factor to downsample grid for printing. If None, auto-calculated to fit ~80 chars width.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>ASCII string representation.</p> Source code in <code>photoelastimetry/visualisation.py</code> <pre><code>def ascii_boundary_conditions(\n    boundary_mask, boundary_values, title=\"Boundary Conditions\", downsample_factor=None\n):\n    \"\"\"\n    Generate an ASCII representation of the boundary conditions.\n\n    Parameters\n    ----------\n    boundary_mask : ndarray (bool)\n        [H, W] boolean mask of active boundary pixels.\n    boundary_values : dict\n        Dictionary with keys 'xx', 'yy', 'xy', containing [H, W] arrays or scalars.\n        NaN values indicate 'unconstrained' at that pixel for that component.\n    title : str\n        Title for the plot.\n    downsample_factor : int, optional\n        Factor to downsample grid for printing. If None, auto-calculated to fit ~80 chars width.\n\n    Returns\n    -------\n    str\n        ASCII string representation.\n    \"\"\"\n    H, W = boundary_mask.shape\n\n    # 1. Determine downsampling\n    if downsample_factor is None:\n        downsample_factor = max(1, W // 60, H // 40)\n\n    h_small = (H + downsample_factor - 1) // downsample_factor\n    w_small = (W + downsample_factor - 1) // downsample_factor\n\n    # Create grid for simplified view\n    # We will prioritize 'True' in the mask during downsampling (max pool)\n    # Actually, standard striding is safer for visualization structure\n    # mask_small = boundary_mask[::downsample_factor, ::downsample_factor]\n\n    # Better: Downsample carefully. If any pixel in block is boundary, show it.\n    grid_chars = np.full((h_small, w_small), \" \", dtype=object)\n\n    # Standardize values inputs\n    components = [\"xx\", \"yy\", \"xy\"]\n    val_maps = {}\n    for c in components:\n        if c in boundary_values:\n            v = boundary_values[c]\n            if np.isscalar(v):\n                v = np.full((H, W), v)\n            val_maps[c] = v\n        else:\n            val_maps[c] = np.full((H, W), np.nan)\n\n    # Icons\n    # Pinned/Clamped (All fixed): #\n    # Roller Vert (X fixed, Y free?): |\n    # Roller Horz (Y fixed, X free?): =\n    # Shear only: S\n    # Free surface (Zero traction): 0\n    # Custom Load: L\n\n    # Let's think in terms of local constraints\n    # C = {xx, yy, xy}\n    # For each block\n    for r in range(h_small):\n        for c in range(w_small):\n            # Extract block\n            r0, r1 = r * downsample_factor, min((r + 1) * downsample_factor, H)\n            c0, c1 = c * downsample_factor, min((c + 1) * downsample_factor, W)\n\n            block_mask = boundary_mask[r0:r1, c0:c1]\n            if not np.any(block_mask):\n                # Check if it's inside or outside?\n                # Usually we just want to see boundaries.\n                grid_chars[r, c] = \".\"  # internal/empty\n                continue\n\n            # Find the most constrained pixel in the block to represent it\n            # Or just take center/first\n            # Let's take the first masked pixel found\n            y_local, x_local = np.where(block_mask)\n            py, px = r0 + y_local[0], c0 + x_local[0]\n\n            constraints = []\n            values = []\n\n            for comp in components:\n                val = val_maps[comp][py, px]\n                if not np.isnan(val):\n                    constraints.append(comp)\n                    values.append(val)\n\n            # Symbol Logic\n            is_xx = \"xx\" in constraints\n            is_yy = \"yy\" in constraints\n            is_xy = \"xy\" in constraints\n\n            sym = \"?\"\n\n            if is_xx and is_yy and is_xy:\n                sym = \"\u25a0\"  # Clamped / Fully Known\n            elif is_xx and is_yy:\n                sym = \"+\"  # Bi-axial normal\n            elif is_xx and is_xy:\n                sym = \"\u29b6\"  # Vertical constraint?\n            elif is_yy and is_xy:\n                sym = \"\u29b7\"  # Horizontal constraint?\n            elif is_xx:\n                sym = \"|\"  # XX fixed (Normal X)\n            elif is_yy:\n                sym = \"-\"  # YY fixed (Normal Y)\n            elif is_xy:\n                sym = \"x\"  # Shear fixed\n            else:\n                sym = \"o\"  # Masked but no constraints? (Free?)\n\n            # Special check for Zero (Free Surface) vs Non-Zero (Load)\n            # If all constrained values are approx zero -&gt; Free Surface\n            # We differentiate 'Fixed to 0' from 'Fixed to Value'\n            all_zero = True\n            for v in values:\n                if abs(v) &gt; 1e-6:  # Tolerance\n                    all_zero = False\n                    break\n\n            # If it's a \"Free Surface\" (Traction = 0), key components are usually Normal+Shear=0\n            # But here we visualize components.\n            # Let's denote Non-Zero loads with bold or different char?\n            # Terminal bold: \\033[1m ... \\033[0m\n            if not all_zero:\n                # Load\n                sym = f\"\\033[91m{sym}\\033[0m\"  # Red for Load\n            else:\n                # Zero constraint (Support/FreeSurface)\n                sym = f\"\\033[92m{sym}\\033[0m\"  # Green for Zero\n\n            grid_chars[r, c] = sym\n\n    # Convert grid to string\n    lines = []\n    lines.append(f\"=== {title} ===\")\n    lines.append(f\"Grid: {W}x{H} -&gt; {w_small}x{h_small} (DS: {downsample_factor})\")\n\n    # Improved Legend\n    lines.append(\"Legend (Colors):\")\n    lines.append(\"  \\033[92mGREEN\\033[0m : Zero Value (Support / Free Surface)\")\n    lines.append(\"  \\033[91mRED  \\033[0m : Non-Zero Value (Load / Displacement)\")\n\n    lines.append(\"Legend (Symbols):\")\n    lines.append(f\"  \u25a0 : Clamped (xx, yy, xy fixed)\")\n    lines.append(f\"  + : Bi-axial Normal (xx, yy fixed)\")\n    lines.append(f\"  \u29b6 : Vertical Roller / Side (xx, xy fixed)\")\n    lines.append(f\"  \u29b7 : Horizontal Roller / Top/Bot (yy, xy fixed)\")\n    lines.append(f\"  | : Normal X fixed (xx)\")\n    lines.append(f\"  - : Normal Y fixed (yy)\")\n    lines.append(f\"  x : Shear fixed (xy)\")\n    lines.append(f\"  o : Unconstrained (Masked but Free)\")\n\n    lines.append(\"-\" * (w_small + 2))\n\n    for r in range(h_small):\n        row_str = \"\".join(grid_chars[r, :])\n        lines.append(f\" {row_str} \")\n\n    lines.append(\"-\" * (w_small + 2))\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/generate/disk/","title":"generate.disk","text":"<p>Elastic disk solution and photoelastic simulation.</p> <p>This module provides functions for simulating the photoelastic response of an elastic disk under compression, including analytical stress solutions and Mueller matrix-based polarimetry simulation.</p>"},{"location":"reference/generate/disk/#photoelastimetry.generate.disk","title":"<code>disk</code>","text":""},{"location":"reference/generate/disk/#photoelastimetry.generate.disk-functions","title":"Functions","text":""},{"location":"reference/generate/disk/#photoelastimetry.generate.disk.diametrical_stress_cartesian","title":"<code>diametrical_stress_cartesian(X, Y, P, R)</code>","text":"<p>Exact Brazil test solution from ISRM standards and Jaeger &amp; Cook P: total load (force per unit thickness) R: disk radius</p> <p>Key validation: At center (0,0): - sigma_x = 2P/(piR) (tensile) - sigma_y = -6P/(piR) (compressive) - tau_xy = 0</p> Source code in <code>photoelastimetry/generate/disk.py</code> <pre><code>def diametrical_stress_cartesian(X, Y, P, R):\n    \"\"\"\n    Exact Brazil test solution from ISRM standards and Jaeger &amp; Cook\n    P: total load (force per unit thickness)\n    R: disk radius\n\n    Key validation: At center (0,0):\n    - sigma_x = 2P/(pi*R) (tensile)\n    - sigma_y = -6P/(pi*R) (compressive)\n    - tau_xy = 0\n    \"\"\"\n\n    X_safe = X.copy()\n    Y_safe = Y.copy()\n\n    # Small offset to avoid singularities at origin\n    origin_mask = (X**2 + Y**2) &lt; (0.001 * R) ** 2\n    X_safe = np.where(origin_mask, 0.001 * R, X_safe)\n    Y_safe = np.where(origin_mask, 0.001 * R, Y_safe)\n\n    # Distance from load points\n    r1 = np.sqrt(X_safe**2 + (Y_safe - R) ** 2)  # from (0, R)\n    r2 = np.sqrt(X_safe**2 + (Y_safe + R) ** 2)  # from (0, -R)\n\n    # Angles from load points\n    theta1 = np.arctan2(X_safe, Y_safe - R)\n    theta2 = np.arctan2(X_safe, Y_safe + R)\n\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        sigma_xx = (\n            -(2 * P / np.pi)\n            * (np.cos(theta1) ** 2 * (Y_safe - R) / (r1**2) - np.cos(theta2) ** 2 * (Y_safe + R) / (r2**2))\n            / R\n        )\n\n        sigma_yy = (\n            -(2 * P / np.pi)\n            * (np.sin(theta1) ** 2 * (Y_safe - R) / (r1**2) - np.sin(theta2) ** 2 * (Y_safe + R) / (r2**2))\n            / R\n        )\n\n        tau_xy = (\n            -(2 * P / np.pi)\n            * (\n                np.sin(theta1) * np.cos(theta1) * (Y_safe - R) / (r1**2)\n                - np.sin(theta2) * np.cos(theta2) * (Y_safe + R) / (r2**2)\n            )\n            / R\n        )\n\n    return sigma_xx, sigma_yy, tau_xy\n</code></pre>"},{"location":"reference/generate/disk/#photoelastimetry.generate.disk.generate_synthetic_brazil_test","title":"<code>generate_synthetic_brazil_test(X, Y, P, R, S_i_hat, mask, wavelengths=None, thickness=None, C=None, polarisation_efficiency=1.0, **kwargs)</code>","text":"<p>Generate synthetic Brazil test data for validation This function creates a synthetic dataset based on the analytical solution and saves it in a format suitable for testing.</p> Source code in <code>photoelastimetry/generate/disk.py</code> <pre><code>def generate_synthetic_brazil_test(\n    X,\n    Y,\n    P,\n    R,\n    S_i_hat,\n    mask,\n    wavelengths=None,\n    thickness=None,\n    C=None,\n    polarisation_efficiency=1.0,\n    **kwargs,\n):\n    \"\"\"\n    Generate synthetic Brazil test data for validation\n    This function creates a synthetic dataset based on the analytical solution\n    and saves it in a format suitable for testing.\n    \"\"\"\n\n    # Backward compatibility: older callers used keyword `wavelengths_nm`\n    if wavelengths is None:\n        wavelengths = kwargs.pop(\"wavelengths_nm\", None)\n    elif \"wavelengths_nm\" in kwargs:\n        raise TypeError(\"Pass only one of `wavelengths` or `wavelengths_nm`, not both.\")\n\n    if kwargs:\n        unexpected = \", \".join(sorted(kwargs.keys()))\n        raise TypeError(f\"Unexpected keyword argument(s): {unexpected}\")\n\n    if wavelengths is None:\n        raise TypeError(\"Missing required wavelength input: pass `wavelengths` (meters).\")\n\n    # Get stress components directly\n    sigma_xx, sigma_yy, tau_xy = diametrical_stress_cartesian(X, Y, P, R)\n\n    # Mask outside the disk\n    sigma_xx[~mask] = np.nan\n    sigma_yy[~mask] = np.nan\n    tau_xy[~mask] = np.nan\n\n    # Principal stress difference and angle\n    sigma_avg = 0.5 * (sigma_xx + sigma_yy)\n    R_mohr = np.sqrt(((sigma_xx - sigma_yy) / 2) ** 2 + tau_xy**2)\n    sigma1 = sigma_avg + R_mohr\n    sigma2 = sigma_avg - R_mohr\n    principal_diff = sigma1 - sigma2\n    theta_p = 0.5 * np.arctan2(2 * tau_xy, sigma_xx - sigma_yy)\n\n    # Mask again\n    principal_diff[~mask] = np.nan\n    theta_p[~mask] = np.nan\n\n    height, width = sigma_xx.shape\n\n    synthetic_images = np.empty((height, width, 3, 4))  # RGB, 4 polarizer angles\n\n    # Use incoming light fully S1 polarized (standard setup)\n    # S_i_hat = np.array([0.0, 0.0, 1.0])\n    nu = 1.0  # Solid sample\n\n    for i, lambda_light in tqdm(enumerate(wavelengths)):\n        # Generate four-step polarimetry images using Mueller matrix approach\n        I0_pol, I45_pol, I90_pol, I135_pol = simulate_four_step_polarimetry(\n            sigma_xx, sigma_yy, tau_xy, C[i], nu, thickness, lambda_light, S_i_hat\n        )\n\n        synthetic_images[:, :, i, 0] = I0_pol\n        synthetic_images[:, :, i, 1] = I45_pol\n        synthetic_images[:, :, i, 2] = I90_pol\n        synthetic_images[:, :, i, 3] = I135_pol\n\n    return (\n        synthetic_images,\n        principal_diff,\n        theta_p,\n        sigma_xx,\n        sigma_yy,\n        tau_xy,\n    )\n</code></pre>"},{"location":"reference/generate/inclined_plane/","title":"generate.inclined_plane","text":"<p>Inclined plane stress field simulation.</p> <p>This module provides functions for simulating the photoelastic response of a material under inclined plane stress conditions (rectangular mass with gravity acting at an angle).</p>"},{"location":"reference/generate/inclined_plane/#photoelastimetry.generate.inclined_plane","title":"<code>inclined_plane</code>","text":""},{"location":"reference/generate/inclined_plane/#photoelastimetry.generate.inclined_plane-functions","title":"Functions","text":""},{"location":"reference/generate/inclined_plane/#photoelastimetry.generate.inclined_plane.inclined_stress_cartesian","title":"<code>inclined_stress_cartesian(X, Y, rho, g=9.81, theta_deg=0.0, K0=0.5)</code>","text":"<p>Stress field for an inclined plane (rectangular mass with inclined gravity).</p> <p>This computes the stress field in a rectangular domain with gravity acting at an angle theta from vertical. The resulting stress field includes both normal stresses that vary with depth and shear stresses due to the inclined gravity.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array - like</code> <p>X coordinates (horizontal position).</p> required <code>Y</code> <code>array - like</code> <p>Y coordinates (depth, positive downward from surface).</p> required <code>rho</code> <code>float</code> <p>Density (kg/m^3).</p> required <code>g</code> <code>float</code> <p>Gravitational acceleration (m/s^2).</p> <code>9.81</code> <code>theta_deg</code> <code>float</code> <p>Inclination angle of gravity from vertical (degrees). 0 degrees = vertical (standard lithostatic) Positive angles tilt gravity towards +x direction</p> <code>0.0</code> <code>K0</code> <code>float</code> <p>Coefficient of lateral earth pressure at rest. Used to relate stresses perpendicular to the inclined direction.</p> <code>0.5</code> <p>Returns:</p> Name Type Description <code>sigma_xx</code> <code>array - like</code> <p>Normal stress in x direction (Pa).</p> <code>sigma_yy</code> <code>array - like</code> <p>Normal stress in y direction (Pa).</p> <code>tau_xy</code> <code>array - like</code> <p>Shear stress (Pa).</p> Notes <p>For an inclined gravity field, the body forces are: - f_x = rho * g * sin(theta)  (horizontal component) - f_y = rho * g * cos(theta)  (vertical component)</p> <p>The stress field must satisfy equilibrium: - d\u03c3_xx/dx + d\u03c4_xy/dy + f_x = 0 - d\u03c4_xy/dx + d\u03c3_yy/dy + f_y = 0</p> <p>For a uniform rectangular mass with no boundaries except at the top, we assume a solution where stresses increase linearly with depth in the direction of gravity, and include shear stress from the inclined component.</p> Source code in <code>photoelastimetry/generate/inclined_plane.py</code> <pre><code>def inclined_stress_cartesian(X, Y, rho, g=9.81, theta_deg=0.0, K0=0.5):\n    \"\"\"\n    Stress field for an inclined plane (rectangular mass with inclined gravity).\n\n    This computes the stress field in a rectangular domain with gravity\n    acting at an angle theta from vertical. The resulting stress field\n    includes both normal stresses that vary with depth and shear stresses\n    due to the inclined gravity.\n\n    Parameters\n    ----------\n    X : array-like\n        X coordinates (horizontal position).\n    Y : array-like\n        Y coordinates (depth, positive downward from surface).\n    rho : float\n        Density (kg/m^3).\n    g : float\n        Gravitational acceleration (m/s^2).\n    theta_deg : float\n        Inclination angle of gravity from vertical (degrees).\n        0 degrees = vertical (standard lithostatic)\n        Positive angles tilt gravity towards +x direction\n    K0 : float\n        Coefficient of lateral earth pressure at rest.\n        Used to relate stresses perpendicular to the inclined direction.\n\n    Returns\n    -------\n    sigma_xx : array-like\n        Normal stress in x direction (Pa).\n    sigma_yy : array-like\n        Normal stress in y direction (Pa).\n    tau_xy : array-like\n        Shear stress (Pa).\n\n    Notes\n    -----\n    For an inclined gravity field, the body forces are:\n    - f_x = rho * g * sin(theta)  (horizontal component)\n    - f_y = rho * g * cos(theta)  (vertical component)\n\n    The stress field must satisfy equilibrium:\n    - d\u03c3_xx/dx + d\u03c4_xy/dy + f_x = 0\n    - d\u03c4_xy/dx + d\u03c3_yy/dy + f_y = 0\n\n    For a uniform rectangular mass with no boundaries except at the top,\n    we assume a solution where stresses increase linearly with depth\n    in the direction of gravity, and include shear stress from the\n    inclined component.\n    \"\"\"\n    theta_rad = np.deg2rad(theta_deg)\n\n    # Components of gravity\n    g_x = g * np.sin(theta_rad)  # Horizontal component\n    g_y = g * np.cos(theta_rad)  # Vertical component\n\n    # For a simple inclined plane solution, we assume:\n    # 1. Vertical stress component increases with depth due to g_y\n    # 2. Horizontal stress is related by K0\n    # 3. Shear stress arises from the horizontal gravity component\n\n    # Stress in the direction of gravity (normal to inclined layers)\n    # For simplicity, we compute stress as if in a rotated coordinate system\n    # then transform back to x-y coordinates\n\n    # Normal stress perpendicular to gravity direction\n    sigma_normal = rho * g * Y  # Total weight effect with depth\n\n    # In the inclined case, we decompose this into x-y components\n    # The vertical stress component\n    sigma_yy = rho * g_y * Y\n\n    # The horizontal stress has contributions from both K0 effect and inclination\n    sigma_xx = K0 * sigma_yy\n\n    # Shear stress arises from the inclined gravity\n    # In equilibrium, tau_xy must balance the horizontal body force\n    # For a linear variation: dtau_xy/dy = -rho * g_x\n    # Integrating: tau_xy = -rho * g_x * Y + C\n    # With free surface at Y=0: tau_xy(Y=0) = 0, so C = 0\n    tau_xy = rho * g_x * Y\n\n    # Ensure non-negative normal stresses (no tension)\n    sigma_yy = np.maximum(0, sigma_yy)\n    sigma_xx = np.maximum(0, sigma_xx)\n\n    return sigma_xx, sigma_yy, tau_xy\n</code></pre>"},{"location":"reference/generate/inclined_plane/#photoelastimetry.generate.inclined_plane.generate_synthetic_inclined_plane","title":"<code>generate_synthetic_inclined_plane(X, Y, rho, g, theta_deg, K0, S_i_hat, wavelengths_nm, thickness, C)</code>","text":"<p>Generate synthetic inclined plane stress data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array - like</code> <p>Coordinate grids</p> required <code>Y</code> <code>array - like</code> <p>Coordinate grids</p> required <code>rho</code> <code>float</code> <p>Density (kg/m^3)</p> required <code>g</code> <code>float</code> <p>Gravitational acceleration (m/s^2)</p> required <code>theta_deg</code> <code>float</code> <p>Inclination angle from vertical (degrees)</p> required <code>K0</code> <code>float</code> <p>Coefficient of lateral earth pressure</p> required <code>S_i_hat</code> <code>array - like</code> <p>Incoming normalised Stokes vector</p> required <code>wavelengths_nm</code> <code>array - like</code> <p>Wavelengths in meters</p> required <code>thickness</code> <code>float</code> <p>Sample thickness (m)</p> required <code>C</code> <code>array - like</code> <p>Stress-optic coefficients for each wavelength</p> required <p>Returns:</p> Name Type Description <code>synthetic_images</code> <code>array - like</code> <p>Generated synthetic images [height, width, n_wavelengths, 4]</p> <code>principal_diff</code> <code>array - like</code> <p>Principal stress difference</p> <code>theta_p</code> <code>array - like</code> <p>Principal stress angle</p> <code>sigma_xx, sigma_yy, tau_xy : array-like</code> <p>Stress components</p> Source code in <code>photoelastimetry/generate/inclined_plane.py</code> <pre><code>def generate_synthetic_inclined_plane(X, Y, rho, g, theta_deg, K0, S_i_hat, wavelengths_nm, thickness, C):\n    \"\"\"\n    Generate synthetic inclined plane stress data.\n\n    Parameters\n    ----------\n    X, Y : array-like\n        Coordinate grids\n    rho : float\n        Density (kg/m^3)\n    g : float\n        Gravitational acceleration (m/s^2)\n    theta_deg : float\n        Inclination angle from vertical (degrees)\n    K0 : float\n        Coefficient of lateral earth pressure\n    S_i_hat : array-like\n        Incoming normalised Stokes vector\n    wavelengths_nm : array-like\n        Wavelengths in meters\n    thickness : float\n        Sample thickness (m)\n    C : array-like\n        Stress-optic coefficients for each wavelength\n\n    Returns\n    -------\n    synthetic_images : array-like\n        Generated synthetic images [height, width, n_wavelengths, 4]\n    principal_diff : array-like\n        Principal stress difference\n    theta_p : array-like\n        Principal stress angle\n    sigma_xx, sigma_yy, tau_xy : array-like\n        Stress components\n    \"\"\"\n    # Get stress components\n    sigma_xx, sigma_yy, tau_xy = inclined_stress_cartesian(X, Y, rho, g, theta_deg, K0)\n\n    # Principal stress difference and angle\n    sigma_avg = 0.5 * (sigma_xx + sigma_yy)\n    R_mohr = np.sqrt(((sigma_xx - sigma_yy) / 2) ** 2 + tau_xy**2)\n    sigma1 = sigma_avg + R_mohr\n    sigma2 = sigma_avg - R_mohr\n    principal_diff = sigma1 - sigma2\n    theta_p = 0.5 * np.arctan2(2 * tau_xy, sigma_xx - sigma_yy)\n\n    height, width = sigma_xx.shape\n    n_colors = len(wavelengths_nm)\n\n    synthetic_images = np.zeros((height, width, n_colors, 4))\n\n    for i, lambda_light in enumerate(wavelengths_nm):\n        # Stress-optic coefficient for this wavelength\n        c_lambda = C[i]\n\n        # Simulate polarimetry\n        I0, I45, I90, I135 = simulate_four_step_polarimetry(\n            sigma_xx, sigma_yy, tau_xy, c_lambda, 1.0, thickness, lambda_light, S_i_hat  # nu (solid fraction)\n        )\n\n        # Stack into our array\n        synthetic_images[:, :, i, 0] = I0\n        synthetic_images[:, :, i, 1] = I45\n        synthetic_images[:, :, i, 2] = I90\n        synthetic_images[:, :, i, 3] = I135\n\n    return synthetic_images, principal_diff, theta_p, sigma_xx, sigma_yy, tau_xy\n</code></pre>"},{"location":"reference/generate/lithostatic/","title":"generate.lithostatic","text":"<p>Lithostatic stress field simulation.</p> <p>This module provides functions for simulating the photoelastic response of a material under lithostatic stress conditions (stress increasing linearly with depth).</p>"},{"location":"reference/generate/lithostatic/#photoelastimetry.generate.lithostatic","title":"<code>lithostatic</code>","text":""},{"location":"reference/generate/lithostatic/#photoelastimetry.generate.lithostatic-functions","title":"Functions","text":""},{"location":"reference/generate/lithostatic/#photoelastimetry.generate.lithostatic.lithostatic_stress_cartesian","title":"<code>lithostatic_stress_cartesian(X, Y, rho, g=9.81, K0=0.5)</code>","text":"<p>Lithostatic stress field (increasing with depth).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array - like</code> <p>X coordinates (horizontal position).</p> required <code>Y</code> <code>array - like</code> <p>Y coordinates (depth, positive downward from surface).</p> required <code>rho</code> <code>float</code> <p>Density (kg/m^3).</p> required <code>g</code> <code>float</code> <p>Gravity (m/s^2).</p> <code>9.81</code> <code>K0</code> <code>float</code> <p>Coefficient of lateral earth pressure (sigma_xx / sigma_yy).</p> <code>0.5</code> <p>Returns:</p> Name Type Description <code>sigma_xx</code> <code>array - like</code> <p>Normal stress in x direction (Pa).</p> <code>sigma_yy</code> <code>array - like</code> <p>Normal stress in y direction (Pa).</p> <code>tau_xy</code> <code>array - like</code> <p>Shear stress (Pa).</p> Source code in <code>photoelastimetry/generate/lithostatic.py</code> <pre><code>def lithostatic_stress_cartesian(X, Y, rho, g=9.81, K0=0.5):\n    \"\"\"\n    Lithostatic stress field (increasing with depth).\n\n    Parameters\n    ----------\n    X : array-like\n        X coordinates (horizontal position).\n    Y : array-like\n        Y coordinates (depth, positive downward from surface).\n    rho : float\n        Density (kg/m^3).\n    g : float\n        Gravity (m/s^2).\n    K0 : float\n        Coefficient of lateral earth pressure (sigma_xx / sigma_yy).\n\n    Returns\n    -------\n    sigma_xx : array-like\n        Normal stress in x direction (Pa).\n    sigma_yy : array-like\n        Normal stress in y direction (Pa).\n    tau_xy : array-like\n        Shear stress (Pa).\n    \"\"\"\n    # Vertical stress increases linearly with depth\n    sigma_yy = rho * g * Y\n\n    # Ensure no negative depth (if Y coordinate system differs) produces negative stress\n    # Assuming soil/rock/granular material doesn't support tension this way usually\n    sigma_yy = np.maximum(0, sigma_yy)\n\n    # Horizontal stress is a fraction of vertical stress\n    sigma_xx = K0 * sigma_yy\n\n    # No shear stress in simple lithostatic case\n    tau_xy = np.zeros_like(X)\n\n    return sigma_xx, sigma_yy, tau_xy\n</code></pre>"},{"location":"reference/generate/lithostatic/#photoelastimetry.generate.lithostatic.generate_synthetic_lithostatic","title":"<code>generate_synthetic_lithostatic(X, Y, rho, g, K0, S_i_hat, wavelengths_nm, thickness, C)</code>","text":"<p>Generate synthetic lithostatic stress data.</p> Source code in <code>photoelastimetry/generate/lithostatic.py</code> <pre><code>def generate_synthetic_lithostatic(X, Y, rho, g, K0, S_i_hat, wavelengths_nm, thickness, C):\n    \"\"\"\n    Generate synthetic lithostatic stress data.\n    \"\"\"\n\n    # Get stress components\n    sigma_xx, sigma_yy, tau_xy = lithostatic_stress_cartesian(X, Y, rho, g, K0)\n\n    # Principal stress difference and angle\n    principal_diff = np.abs(sigma_xx - sigma_yy)\n    theta_p = 0.5 * np.arctan2(2 * tau_xy, sigma_xx - sigma_yy)\n\n    height, width = sigma_xx.shape\n    n_colors = len(wavelengths_nm)\n\n    synthetic_images = np.zeros((height, width, n_colors, 4))\n\n    for i, lambda_light in enumerate(wavelengths_nm):\n        # Stress-optic coefficient for this wavelength\n        c_lambda = C[i]\n\n        # Simulate polarimetry\n        I0, I45, I90, I135 = simulate_four_step_polarimetry(\n            sigma_xx, sigma_yy, tau_xy, c_lambda, 1.0, thickness, lambda_light, S_i_hat  # nu (solid fraction)\n        )\n\n        # Stack into our array\n        synthetic_images[:, :, i, 0] = I0\n        synthetic_images[:, :, i, 1] = I45\n        synthetic_images[:, :, i, 2] = I90\n        synthetic_images[:, :, i, 3] = I135\n\n    return synthetic_images, principal_diff, theta_p, sigma_xx, sigma_yy, tau_xy\n</code></pre>"},{"location":"reference/generate/point_load/","title":"generate.point_load","text":"<p>Boussinesq point-load stress field and synthetic polarimetry generation.</p>"},{"location":"reference/generate/point_load/#photoelastimetry.generate.point_load","title":"<code>point_load</code>","text":""},{"location":"reference/generate/point_load/#photoelastimetry.generate.point_load-functions","title":"Functions","text":""},{"location":"reference/generate/point_load/#photoelastimetry.generate.point_load.boussinesq_stress_cartesian","title":"<code>boussinesq_stress_cartesian(X, Y, P, nu_poisson=0.3)</code>","text":"<p>Boussinesq solution for point load on elastic half-space.</p> <p>This computes the stress field in a semi-infinite elastic solid subjected to a concentrated vertical point load P at the surface.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array - like</code> <p>X coordinates (horizontal position)</p> required <code>Y</code> <code>array - like</code> <p>Y coordinates (depth, positive downward from surface)</p> required <code>P</code> <code>float</code> <p>Point load magnitude (force, in N)</p> required <code>nu_poisson</code> <code>float</code> <p>Poisson's ratio (default: 0.3)</p> <code>0.3</code> <p>Returns:</p> Name Type Description <code>sigma_xx</code> <code>array - like</code> <p>Normal stress in x direction (Pa)</p> <code>sigma_yy</code> <code>array - like</code> <p>Normal stress in y direction (Pa)</p> <code>tau_xy</code> <code>array - like</code> <p>Shear stress (Pa)</p> Notes <p>The Boussinesq solution assumes: - Semi-infinite elastic half-space (y &gt;= 0) - Point load P applied at origin on the surface - Y axis points downward (into the material) - Linear elastic material with Poisson's ratio nu</p> References <p>Boussinesq, J. (1885). Application des potentiels \u00e0 l'\u00e9tude de l'\u00e9quilibre et du mouvement des solides \u00e9lastiques.</p> Source code in <code>photoelastimetry/generate/point_load.py</code> <pre><code>def boussinesq_stress_cartesian(X, Y, P, nu_poisson=0.3):\n    \"\"\"\n    Boussinesq solution for point load on elastic half-space.\n\n    This computes the stress field in a semi-infinite elastic solid\n    subjected to a concentrated vertical point load P at the surface.\n\n    Parameters\n    ----------\n    X : array-like\n        X coordinates (horizontal position)\n    Y : array-like\n        Y coordinates (depth, positive downward from surface)\n    P : float\n        Point load magnitude (force, in N)\n    nu_poisson : float\n        Poisson's ratio (default: 0.3)\n\n    Returns\n    -------\n    sigma_xx : array-like\n        Normal stress in x direction (Pa)\n    sigma_yy : array-like\n        Normal stress in y direction (Pa)\n    tau_xy : array-like\n        Shear stress (Pa)\n\n    Notes\n    -----\n    The Boussinesq solution assumes:\n    - Semi-infinite elastic half-space (y &gt;= 0)\n    - Point load P applied at origin on the surface\n    - Y axis points downward (into the material)\n    - Linear elastic material with Poisson's ratio nu\n\n    References\n    ----------\n    Boussinesq, J. (1885). Application des potentiels \u00e0 l'\u00e9tude de\n    l'\u00e9quilibre et du mouvement des solides \u00e9lastiques.\n    \"\"\"\n    X_safe = X.copy()\n    Y_safe = Y.copy()\n\n    # Small offset to avoid singularity at load point\n    epsilon = 1e-6\n    origin_mask = (X**2 + Y**2) &lt; epsilon**2\n    X_safe = np.where(origin_mask, epsilon, X_safe)\n    Y_safe = np.where(origin_mask, epsilon, Y_safe)\n\n    # Distance from load point\n    r = np.sqrt(X_safe**2 + Y_safe**2)\n\n    # Boussinesq stress components for point load\n    # These are the classical solutions from elasticity theory\n    r3 = r**3\n    r5 = r**5\n\n    # Stress components\n    sigma_xx = (P / (2 * np.pi)) * (\n        (1 - 2 * nu_poisson) * (Y_safe / r3 - X_safe**2 * Y_safe / r5) - 3 * X_safe**2 * Y_safe / r5\n    )\n\n    sigma_yy = (P / (2 * np.pi)) * (\n        (1 - 2 * nu_poisson) * (Y_safe / r3 - Y_safe**3 / r5) - 3 * Y_safe**3 / r5\n    )\n\n    tau_xy = (P / (2 * np.pi)) * (\n        (1 - 2 * nu_poisson) * (-X_safe / r3 + X_safe * Y_safe**2 / r5) - 3 * X_safe * Y_safe**2 / r5\n    )\n\n    # Set stress to zero above the surface (y &lt; 0)\n    above_surface = Y &lt; 0\n    sigma_xx[above_surface] = 0\n    sigma_yy[above_surface] = 0\n    tau_xy[above_surface] = 0\n\n    return sigma_xx, sigma_yy, tau_xy\n</code></pre>"},{"location":"reference/generate/point_load/#photoelastimetry.generate.point_load.generate_synthetic_boussinesq","title":"<code>generate_synthetic_boussinesq(X, Y, P, nu_poisson, S_i_hat, mask, wavelengths_nm, thickness, C, polarisation_efficiency)</code>","text":"<p>Generate synthetic Boussinesq point load data for validation.</p> <p>This function creates a synthetic dataset based on the analytical solution and saves it in a format suitable for testing.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array - like</code> <p>Coordinate grids</p> required <code>Y</code> <code>array - like</code> <p>Coordinate grids</p> required <code>P</code> <code>float</code> <p>Point load magnitude (N)</p> required <code>nu_poisson</code> <code>float</code> <p>Poisson's ratio</p> required <code>S_i_hat</code> <code>array - like</code> <p>Incoming normalised Stokes vector</p> required <code>mask</code> <code>array - like</code> <p>Boolean mask for valid region</p> required <code>wavelengths_nm</code> <code>array - like</code> <p>Wavelengths in meters</p> required <code>thickness</code> <code>float</code> <p>Sample thickness (m)</p> required <code>C</code> <code>array - like</code> <p>Stress-optic coefficients for each wavelength</p> required <code>polarisation_efficiency</code> <code>float</code> <p>Polarisation efficiency (0-1)</p> required <p>Returns:</p> Name Type Description <code>synthetic_images</code> <code>array - like</code> <p>Generated synthetic images [height, width, n_wavelengths, 4]</p> <code>principal_diff</code> <code>array - like</code> <p>Principal stress difference</p> <code>theta_p</code> <code>array - like</code> <p>Principal stress angle</p> <code>sigma_xx, sigma_yy, tau_xy : array-like</code> <p>Stress components</p> Source code in <code>photoelastimetry/generate/point_load.py</code> <pre><code>def generate_synthetic_boussinesq(\n    X, Y, P, nu_poisson, S_i_hat, mask, wavelengths_nm, thickness, C, polarisation_efficiency\n):\n    \"\"\"\n    Generate synthetic Boussinesq point load data for validation.\n\n    This function creates a synthetic dataset based on the analytical solution\n    and saves it in a format suitable for testing.\n\n    Parameters\n    ----------\n    X, Y : array-like\n        Coordinate grids\n    P : float\n        Point load magnitude (N)\n    nu_poisson : float\n        Poisson's ratio\n    S_i_hat : array-like\n        Incoming normalised Stokes vector\n    mask : array-like\n        Boolean mask for valid region\n    wavelengths_nm : array-like\n        Wavelengths in meters\n    thickness : float\n        Sample thickness (m)\n    C : array-like\n        Stress-optic coefficients for each wavelength\n    polarisation_efficiency : float\n        Polarisation efficiency (0-1)\n\n    Returns\n    -------\n    synthetic_images : array-like\n        Generated synthetic images [height, width, n_wavelengths, 4]\n    principal_diff : array-like\n        Principal stress difference\n    theta_p : array-like\n        Principal stress angle\n    sigma_xx, sigma_yy, tau_xy : array-like\n        Stress components\n    \"\"\"\n    # Get stress components directly\n    sigma_xx, sigma_yy, tau_xy = boussinesq_stress_cartesian(X, Y, P, nu_poisson)\n\n    # Mask outside the valid region\n    sigma_xx[~mask] = np.nan\n    sigma_yy[~mask] = np.nan\n    tau_xy[~mask] = np.nan\n\n    # Principal stress difference and angle\n    sigma_avg = 0.5 * (sigma_xx + sigma_yy)\n    R_mohr = np.sqrt(((sigma_xx - sigma_yy) / 2) ** 2 + tau_xy**2)\n    sigma1 = sigma_avg + R_mohr\n    sigma2 = sigma_avg - R_mohr\n    principal_diff = sigma1 - sigma2\n    theta_p = 0.5 * np.arctan2(2 * tau_xy, sigma_xx - sigma_yy)\n\n    # Mask again\n    principal_diff[~mask] = np.nan\n    theta_p[~mask] = np.nan\n\n    height, width = sigma_xx.shape\n    n_wavelengths = len(wavelengths_nm)\n\n    synthetic_images = np.empty((height, width, n_wavelengths, 4))  # wavelengths, 4 polarizer angles\n\n    # Use incoming light fully S1 polarized (standard setup)\n    nu = 1.0  # Solid sample\n\n    for i, lambda_light in tqdm(enumerate(wavelengths_nm)):\n        # Generate four-step polarimetry images using Mueller matrix approach\n        I0_pol, I45_pol, I90_pol, I135_pol = simulate_four_step_polarimetry(\n            sigma_xx, sigma_yy, tau_xy, C[i], nu, thickness, lambda_light, S_i_hat\n        )\n\n        synthetic_images[:, :, i, 0] = I0_pol\n        synthetic_images[:, :, i, 1] = I45_pol\n        synthetic_images[:, :, i, 2] = I90_pol\n        synthetic_images[:, :, i, 3] = I135_pol\n\n    return (\n        synthetic_images,\n        principal_diff,\n        theta_p,\n        sigma_xx,\n        sigma_yy,\n        tau_xy,\n    )\n</code></pre>"},{"location":"reference/generate/point_load/#photoelastimetry.generate.point_load.post_process_synthetic_data","title":"<code>post_process_synthetic_data(X, Y, principal_diff, theta_p, sigma_xx, sigma_yy, tau_xy, S_i_hat, t_sample, C, lambda_light, P, outname)</code>","text":"<p>Post-process and visualize synthetic Boussinesq data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array - like</code> <p>Coordinate grids</p> required <code>Y</code> <code>array - like</code> <p>Coordinate grids</p> required <code>principal_diff</code> <code>array - like</code> <p>Principal stress difference</p> required <code>theta_p</code> <code>array - like</code> <p>Principal stress angle</p> required <code>sigma_xx</code> <code>array - like</code> <p>Stress components</p> required <code>sigma_yy</code> <code>array - like</code> <p>Stress components</p> required <code>tau_xy</code> <code>array - like</code> <p>Stress components</p> required <code>S_i_hat</code> <code>array - like</code> <p>Incoming normalised Stokes vector</p> required <code>t_sample</code> <code>float</code> <p>Sample thickness (m)</p> required <code>C</code> <code>float</code> <p>Stress-optic coefficient (1/Pa)</p> required <code>lambda_light</code> <code>float</code> <p>Wavelength (m)</p> required <code>P</code> <code>float</code> <p>Point load (N)</p> required <code>outname</code> <code>str</code> <p>Output filename</p> required Source code in <code>photoelastimetry/generate/point_load.py</code> <pre><code>def post_process_synthetic_data(  # pragma: no cover\n    X, Y, principal_diff, theta_p, sigma_xx, sigma_yy, tau_xy, S_i_hat, t_sample, C, lambda_light, P, outname\n):\n    \"\"\"\n    Post-process and visualize synthetic Boussinesq data.\n\n    Parameters\n    ----------\n    X, Y : array-like\n        Coordinate grids\n    principal_diff : array-like\n        Principal stress difference\n    theta_p : array-like\n        Principal stress angle\n    sigma_xx, sigma_yy, tau_xy : array-like\n        Stress components\n    S_i_hat : array-like\n        Incoming normalised Stokes vector\n    t_sample : float\n        Sample thickness (m)\n    C : float\n        Stress-optic coefficient (1/Pa)\n    lambda_light : float\n        Wavelength (m)\n    P : float\n        Point load (N)\n    outname : str\n        Output filename\n    \"\"\"\n    plt.figure(figsize=(12, 12), layout=\"constrained\")\n\n    # Calculate retardation\n    retardation = (2 * np.pi * t_sample * C * principal_diff) / lambda_light\n    f_sigma = lambda_light / (2 * C * t_sample)  # material fringe value\n    fringe_order = principal_diff / f_sigma  # N = (\u03c31 - \u03c32)/f_\u03c3\n\n    # Photoelastic parameters\n    # For circular polariscope (dark field): I \u221d sin\u00b2(\u03b4/2) where \u03b4 is retardation\n    intensity_dark = np.sin(retardation / 2) ** 2  # Dark field intensity\n\n    # For isoclinic lines, we need the extinction angle in plane polariscope\n    isoclinic_angle = theta_p  # Principal stress angle\n\n    # Generate four-step polarimetry images using Mueller matrix approach\n    nu = 1.0  # Solid sample\n    I0_pol, I45_pol, I90_pol, I135_pol = simulate_four_step_polarimetry(\n        sigma_xx, sigma_yy, tau_xy, C, nu, t_sample, lambda_light, S_i_hat\n    )\n\n    # Calculate Stokes parameters from polarimetry\n    S0, S1, S2 = compute_stokes_components(I0_pol, I45_pol, I90_pol, I135_pol)\n    S1_hat, S2_hat = compute_normalised_stokes(S0, S1, S2)\n\n    # Degree of linear polarization\n    DoLP = np.sqrt(S1_hat**2 + S2_hat**2)\n\n    # Angle of linear polarization\n    AoLP = np.mod(0.5 * np.arctan2(S2_hat, S1_hat), np.pi)\n\n    # Plot characteristic photoelastic patterns\n    plt.clf()\n\n    plt.subplot(4, 4, 1)\n    # Plot fringe order\n    max_fringe = np.nanmax(fringe_order)\n    if max_fringe &gt; 0:\n        levels = np.linspace(0, min(max_fringe, 8), 25)\n        plt.contourf(X, Y, fringe_order, levels=levels, cmap=\"plasma\", extend=\"max\")\n        plt.colorbar(label=\"Fringe Order N\", shrink=0.8)\n        # Add integer fringe contour lines (dark fringes)\n        integer_levels = np.arange(0.5, min(max_fringe, 8), 1.0)\n        plt.contour(\n            X,\n            Y,\n            fringe_order,\n            levels=integer_levels,\n            colors=\"black\",\n            linewidths=1.0,\n        )\n    plt.title(\"Isochromatic Fringes\")\n    plt.xlabel(\"x (m)\")\n    plt.ylabel(\"y (m)\")\n    plt.gca().set_aspect(\"equal\")\n\n    plt.subplot(4, 4, 2)\n    # Dark field circular polariscope\n    plt.contourf(X, Y, intensity_dark, levels=50, cmap=\"gray\")\n    plt.colorbar(label=\"Intensity\", shrink=0.8)\n    plt.title(\"Dark Field Circular\\nPolariscope\")\n    plt.xlabel(\"x (m)\")\n    plt.ylabel(\"y (m)\")\n    plt.gca().set_aspect(\"equal\")\n\n    plt.subplot(4, 4, 3)\n    # Principal stress directions (isoclinics)\n    isoclinic_angle_deg = np.rad2deg(isoclinic_angle)\n    # Wrap to [-90, 90] for better visualization\n    isoclinic_angle_deg = ((isoclinic_angle_deg + 90) % 180) - 90\n    plt.contourf(X, Y, isoclinic_angle_deg, levels=36, cmap=virino_cmap)\n    plt.colorbar(label=\"Isoclinic Angle (\u00b0)\", shrink=0.8)\n    plt.title(\"Isoclinic Lines\\n(Principal Stress Direction)\")\n    plt.xlabel(\"x (m)\")\n    plt.ylabel(\"y (m)\")\n    plt.gca().set_aspect(\"equal\")\n\n    plt.subplot(4, 4, 4)\n    plt.contourf(X, Y, DoLP, cmap=\"viridis\")\n    plt.colorbar(label=\"DoLP\", shrink=0.8)\n    plt.title(\"Degree of Linear\\nPolarization\")\n    plt.xlabel(\"x (m)\")\n    plt.ylabel(\"y (m)\")\n    plt.gca().set_aspect(\"equal\")\n\n    plt.subplot(4, 4, 5)\n    plt.contourf(X, Y, AoLP, levels=36, cmap=virino_cmap, vmin=0, vmax=np.pi)\n    plt.colorbar(label=\"AoLP (rad)\", shrink=0.8)\n    plt.title(\"Angle of Linear\\nPolarization\")\n    plt.xlabel(\"x (m)\")\n    plt.ylabel(\"y (m)\")\n    plt.gca().set_aspect(\"equal\")\n\n    # Second row: Four-step polarimetry images\n    polarizer_angles = [\"0\u00b0\", \"45\u00b0\", \"90\u00b0\", \"135\u00b0\"]\n    polarimetry_images = [I0_pol, I45_pol, I90_pol, I135_pol]\n\n    for i, (img, angle) in enumerate(zip(polarimetry_images, polarizer_angles)):\n        plt.subplot(4, 4, 6 + i)\n        plt.contourf(X, Y, img, levels=50, cmap=\"gray\")\n        plt.colorbar(label=\"Intensity\", shrink=0.8)\n        plt.title(f\"Linear Polarizer at {angle}\")\n        plt.xlabel(\"x (m)\")\n        plt.ylabel(\"y (m)\")\n        plt.gca().set_aspect(\"equal\")\n\n    # Add intensity range plot\n    plt.subplot(4, 4, 10)\n    intensity_range = np.maximum.reduce(polarimetry_images) - np.minimum.reduce(polarimetry_images)\n    plt.contourf(X, Y, intensity_range, levels=50, cmap=\"hot\")\n    plt.colorbar(label=\"Intensity Range\", shrink=0.8)\n    plt.title(\"Polarimetric Contrast\\n(Max - Min Intensity)\")\n    plt.xlabel(\"x (m)\")\n    plt.ylabel(\"y (m)\")\n    plt.gca().set_aspect(\"equal\")\n\n    # Third row: Stress components\n    plt.subplot(4, 4, 11)\n    sigma_xx_MPa = sigma_xx / 1e6  # Convert to MPa\n    sigma_xx_max = np.nanmax(np.abs(sigma_xx_MPa))\n    if sigma_xx_max &gt; 0:\n        plt.pcolormesh(\n            X,\n            Y,\n            sigma_xx_MPa,\n            cmap=\"RdBu_r\",\n            norm=SymLogNorm(linthresh=sigma_xx_max / 1e3, vmin=-sigma_xx_max, vmax=sigma_xx_max),\n        )\n    plt.colorbar(label=\"\u03c3_xx (MPa)\", shrink=0.8)\n    plt.title(\"Horizontal Stress \u03c3_xx\")\n    plt.xlabel(\"x (m)\")\n    plt.ylabel(\"y (m)\")\n    plt.gca().set_aspect(\"equal\")\n\n    plt.subplot(4, 4, 12)\n    sigma_yy_MPa = sigma_yy / 1e6\n    sigma_yy_max = np.nanmax(np.abs(sigma_yy_MPa))\n    if sigma_yy_max &gt; 0:\n        plt.pcolormesh(\n            X,\n            Y,\n            sigma_yy_MPa,\n            cmap=\"RdBu_r\",\n            norm=SymLogNorm(\n                linthresh=sigma_yy_max / 1e3,\n                vmin=-sigma_yy_max,\n                vmax=sigma_yy_max,\n            ),\n        )\n    plt.colorbar(label=\"\u03c3_yy (MPa)\", shrink=0.8)\n    plt.title(\"Vertical Stress \u03c3_yy\")\n    plt.xlabel(\"x (m)\")\n    plt.ylabel(\"y (m)\")\n    plt.gca().set_aspect(\"equal\")\n\n    plt.subplot(4, 4, 13)\n    tau_xy_MPa = tau_xy / 1e6\n    tau_xy_max = np.nanmax(np.abs(tau_xy_MPa))\n    if tau_xy_max &gt; 0:\n        plt.pcolormesh(\n            X,\n            Y,\n            tau_xy_MPa,\n            cmap=\"RdBu_r\",\n            norm=SymLogNorm(linthresh=tau_xy_max / 1e3, vmin=-tau_xy_max, vmax=tau_xy_max),\n        )\n    plt.colorbar(label=\"\u03c4_xy (MPa)\", shrink=0.8)\n    plt.title(\"Shear Stress \u03c4_xy\")\n    plt.xlabel(\"x (m)\")\n    plt.ylabel(\"y (m)\")\n    plt.gca().set_aspect(\"equal\")\n\n    plt.subplot(4, 4, 14)\n    principal_diff_MPa = principal_diff / 1e6  # Convert to MPa\n    max_diff = np.nanmax(np.abs(principal_diff_MPa))\n    if max_diff &gt; 0:\n        plt.pcolormesh(\n            X,\n            Y,\n            principal_diff_MPa,\n            cmap=\"plasma\",\n            norm=LogNorm(vmax=max_diff, vmin=1e-4 * max_diff),\n        )\n    plt.colorbar(label=\"\u03c3\u2081 - \u03c3\u2082 (MPa)\", shrink=0.8)\n    plt.title(\"Principal Stress\\nDifference\")\n    plt.xlabel(\"x (m)\")\n    plt.ylabel(\"y (m)\")\n    plt.gca().set_aspect(\"equal\")\n\n    plt.subplot(4, 4, 15)\n    max_retardation = np.nanmax(np.abs(retardation))\n    if max_retardation &gt; 0:\n        plt.pcolormesh(\n            X,\n            Y,\n            retardation,\n            cmap=\"plasma\",\n            norm=LogNorm(vmin=1e-4 * max_retardation, vmax=max_retardation),\n        )\n    plt.colorbar(label=\"Retardation\", shrink=0.8)\n    plt.title(\"Retardation\")\n    plt.xlabel(\"x (m)\")\n    plt.ylabel(\"y (m)\")\n    plt.gca().set_aspect(\"equal\")\n\n    # Summary statistics\n    plt.subplot(4, 4, 16)\n    n = X.shape[0]\n    center_x, center_y = n // 2, n // 2\n    plt.text(\n        0.1,\n        0.8,\n        f\"Load: {P:.0f} N\",\n        fontsize=12,\n        transform=plt.gca().transAxes,\n    )\n    plt.text(\n        0.1,\n        0.7,\n        f\"Max Fringe Order: {max_fringe:.2f}\",\n        fontsize=10,\n        transform=plt.gca().transAxes,\n    )\n    plt.text(\n        0.1,\n        0.6,\n        f\"Max \u03c3\u2081-\u03c3\u2082: {max_diff:.2f} MPa\",\n        fontsize=10,\n        transform=plt.gca().transAxes,\n    )\n    plt.text(\n        0.1,\n        0.5,\n        f\"Center \u03c3\u2093\u2093: {sigma_xx[center_y, center_x]/1e6:.2f} MPa\",\n        fontsize=10,\n        transform=plt.gca().transAxes,\n    )\n    plt.text(\n        0.1,\n        0.4,\n        f\"Center \u03c3\u1d67\u1d67: {sigma_yy[center_y, center_x]/1e6:.2f} MPa\",\n        fontsize=10,\n        transform=plt.gca().transAxes,\n    )\n    plt.text(\n        0.1,\n        0.3,\n        f\"Material f_\u03c3: {f_sigma/1e6:.1f} MPa\",\n        fontsize=10,\n        transform=plt.gca().transAxes,\n    )\n    plt.text(\n        0.1,\n        0.2,\n        f\"Thickness: {t_sample*1000:.0f} mm\",\n        fontsize=10,\n        transform=plt.gca().transAxes,\n    )\n    plt.text(\n        0.1,\n        0.1,\n        f\"Wavelength: {lambda_light*1e9:.0f} nm\",\n        fontsize=10,\n        transform=plt.gca().transAxes,\n    )\n    plt.title(\"Experiment\\nParameters\")\n    plt.gca().set_xlim(0, 1)\n    plt.gca().set_ylim(0, 1)\n    plt.gca().axis(\"off\")\n\n    plt.savefig(outname)\n</code></pre>"},{"location":"reference/generate/strip_load/","title":"generate.strip_load","text":"<p>Uniform strip-load stress field and synthetic polarimetry generation.</p>"},{"location":"reference/generate/strip_load/#photoelastimetry.generate.strip_load","title":"<code>strip_load</code>","text":""},{"location":"reference/generate/strip_load/#photoelastimetry.generate.strip_load-functions","title":"Functions","text":""},{"location":"reference/generate/strip_load/#photoelastimetry.generate.strip_load.strip_load_stress_cartesian","title":"<code>strip_load_stress_cartesian(X, Y, p, a)</code>","text":"<p>Analytical solution for a uniform strip load on an elastic half-space.</p> <p>Computes the stress field in a semi-infinite elastic solid subjected to a uniform normal pressure p distributed over a strip of width 2a.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array - like</code> <p>X coordinates (horizontal position). Load is centered at x=0.</p> required <code>Y</code> <code>array - like</code> <p>Y coordinates (depth, positive downward from surface).</p> required <code>p</code> <code>float</code> <p>Uniform pressure magnitude (Pa).</p> required <code>a</code> <code>float</code> <p>Half-width of the loaded strip (m).</p> required <p>Returns:</p> Name Type Description <code>sigma_xx</code> <code>array - like</code> <p>Normal stress in x direction (Pa).</p> <code>sigma_yy</code> <code>array - like</code> <p>Normal stress in y direction (Pa).</p> <code>tau_xy</code> <code>array - like</code> <p>Shear stress (Pa).</p> Notes <p>We use the solution given by Timoshenko and Goodier (Theory of Elasticity). Using angles theta1 and theta2 subtended by the ends of the load.</p> <p>Coordinate system: - y is positive downward. - Load is applied from x = -a to x = +a at y = 0.</p> Source code in <code>photoelastimetry/generate/strip_load.py</code> <pre><code>def strip_load_stress_cartesian(X, Y, p, a):\n    \"\"\"\n    Analytical solution for a uniform strip load on an elastic half-space.\n\n    Computes the stress field in a semi-infinite elastic solid subjected to a\n    uniform normal pressure p distributed over a strip of width 2a.\n\n    Parameters\n    ----------\n    X : array-like\n        X coordinates (horizontal position).\n        Load is centered at x=0.\n    Y : array-like\n        Y coordinates (depth, positive downward from surface).\n    p : float\n        Uniform pressure magnitude (Pa).\n    a : float\n        Half-width of the loaded strip (m).\n\n    Returns\n    -------\n    sigma_xx : array-like\n        Normal stress in x direction (Pa).\n    sigma_yy : array-like\n        Normal stress in y direction (Pa).\n    tau_xy : array-like\n        Shear stress (Pa).\n\n    Notes\n    -----\n    We use the solution given by Timoshenko and Goodier (Theory of Elasticity).\n    Using angles theta1 and theta2 subtended by the ends of the load.\n\n    Coordinate system:\n    - y is positive downward.\n    - Load is applied from x = -a to x = +a at y = 0.\n    \"\"\"\n\n    # Angles from vertical (y-axis) to the vectors connecting point (x,y)\n    # to the edges of the strip (-a, 0) and (+a, 0).\n    # theta = arctan2(dx, dy) gives angle from vertical.\n\n    # Angle to x = -a\n    theta1 = np.arctan2(X + a, Y)\n\n    # Angle to x = +a\n    theta2 = np.arctan2(X - a, Y)\n\n    # Alpha is the included angle\n    alpha = theta1 - theta2\n\n    # Beta is the angle of the bisector\n    two_beta = theta1 + theta2\n\n    # Stress formulas (Compressive is negative)\n    # sigma_x = -p/pi * (alpha - sin(alpha)*cos(2*beta))\n    # sigma_y = -p/pi * (alpha + sin(alpha)*cos(2*beta))\n    # tau_xy  = -p/pi * (sin(alpha)*sin(2*beta))\n\n    factor = p / np.pi\n\n    sin_alpha = np.sin(alpha)\n    cos_2beta = np.cos(two_beta)\n    sin_2beta = np.sin(two_beta)\n\n    sigma_xx = factor * (alpha - sin_alpha * cos_2beta)\n    sigma_yy = factor * (alpha + sin_alpha * cos_2beta)\n    tau_xy = factor * (sin_alpha * sin_2beta)\n\n    # Clean up above surface\n    above_surface = Y &lt; 0\n    sigma_xx[above_surface] = 0\n    sigma_yy[above_surface] = 0\n    tau_xy[above_surface] = 0\n\n    return sigma_xx, sigma_yy, tau_xy\n</code></pre>"},{"location":"reference/generate/strip_load/#photoelastimetry.generate.strip_load.generate_synthetic_strip_load","title":"<code>generate_synthetic_strip_load(X, Y, p, a, S_i_hat, mask, wavelengths_nm, thickness, C, polarisation_efficiency)</code>","text":"<p>Generate synthetic Strip Load data for validation.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array - like</code> <p>Coordinate grids</p> required <code>Y</code> <code>array - like</code> <p>Coordinate grids</p> required <code>p</code> <code>float</code> <p>Pressure (Pa)</p> required <code>a</code> <code>float</code> <p>Half-width of strip (m)</p> required <code>S_i_hat</code> <code>array - like</code> <p>Incoming normalised Stokes vector</p> required <code>mask</code> <code>array - like</code> <p>Boolean mask for valid region</p> required <code>wavelengths_nm</code> <code>array - like</code> <p>Wavelengths in meters</p> required <code>thickness</code> <code>float</code> <p>Sample thickness (m)</p> required <code>C</code> <code>array - like</code> <p>Stress-optic coefficients for each wavelength</p> required <code>polarisation_efficiency</code> <code>float</code> <p>Polarisation efficiency (0-1)</p> required <p>Returns:</p> Name Type Description <code>synthetic_images</code> <code>array - like</code> <p>Generated synthetic images [height, width, n_wavelengths, 4]</p> <code>principal_diff</code> <code>array - like</code> <p>Principal stress difference</p> <code>theta_p</code> <code>array - like</code> <p>Principal stress angle</p> <code>sigma_xx, sigma_yy, tau_xy : array-like</code> <p>Stress components</p> Source code in <code>photoelastimetry/generate/strip_load.py</code> <pre><code>def generate_synthetic_strip_load(\n    X, Y, p, a, S_i_hat, mask, wavelengths_nm, thickness, C, polarisation_efficiency\n):\n    \"\"\"\n    Generate synthetic Strip Load data for validation.\n\n    Parameters\n    ----------\n    X, Y : array-like\n        Coordinate grids\n    p : float\n        Pressure (Pa)\n    a : float\n        Half-width of strip (m)\n    S_i_hat : array-like\n        Incoming normalised Stokes vector\n    mask : array-like\n        Boolean mask for valid region\n    wavelengths_nm : array-like\n        Wavelengths in meters\n    thickness : float\n        Sample thickness (m)\n    C : array-like\n        Stress-optic coefficients for each wavelength\n    polarisation_efficiency : float\n        Polarisation efficiency (0-1)\n\n    Returns\n    -------\n    synthetic_images : array-like\n        Generated synthetic images [height, width, n_wavelengths, 4]\n    principal_diff : array-like\n        Principal stress difference\n    theta_p : array-like\n        Principal stress angle\n    sigma_xx, sigma_yy, tau_xy : array-like\n        Stress components\n    \"\"\"\n    # Get stress components directly\n    sigma_xx, sigma_yy, tau_xy = strip_load_stress_cartesian(X, Y, p, a)\n\n    # Mask outside the valid region\n    sigma_xx[~mask] = np.nan\n    sigma_yy[~mask] = np.nan\n    tau_xy[~mask] = np.nan\n\n    # Principal stress difference and angle\n    # sigma_avg = 0.5 * (sigma_xx + sigma_yy)\n    # R_mohr = np.sqrt(((sigma_xx - sigma_yy) / 2) ** 2 + tau_xy**2)\n    # sigma1 = sigma_avg + R_mohr\n    # sigma2 = sigma_avg - R_mohr\n    # principal_diff = sigma1 - sigma2\n\n    principal_diff = np.sqrt((sigma_xx - sigma_yy) ** 2 + 4 * tau_xy**2)\n    theta_p = 0.5 * np.arctan2(2 * tau_xy, sigma_xx - sigma_yy)\n\n    # Mask again\n    principal_diff[~mask] = np.nan\n    theta_p[~mask] = np.nan\n\n    height, width = sigma_xx.shape\n    n_wavelengths = len(wavelengths_nm)\n\n    synthetic_images = np.empty((height, width, n_wavelengths, 4))\n\n    # Use incoming light fully S1 polarized (standard setup)\n    nu = 1.0  # Solid sample\n\n    for i, lambda_light in tqdm(enumerate(wavelengths_nm)):\n        # Generate four-step polarimetry images using Mueller matrix approach\n        # Note: We pass polarisation_efficiency if the simulator supports it?\n        # The current simulate_four_step_polarimetry signature in point_load usage is:\n        # simulate_four_step_polarimetry(sigma_xx, sigma_yy, tau_xy, C[i], nu, thickness, lambda_light, S_i_hat)\n        # It doesn't seem to take polarisation_efficiency explicitly in the function call in point_load.py.\n        # I will check simulate_four_step_polarimetry definition if needed, but for now stick to interface.\n\n        I0_pol, I45_pol, I90_pol, I135_pol = simulate_four_step_polarimetry(\n            sigma_xx, sigma_yy, tau_xy, C[i], nu, thickness, lambda_light, S_i_hat\n        )\n\n        synthetic_images[:, :, i, 0] = I0_pol\n        synthetic_images[:, :, i, 1] = I45_pol\n        synthetic_images[:, :, i, 2] = I90_pol\n        synthetic_images[:, :, i, 3] = I135_pol\n\n    return (\n        synthetic_images,\n        principal_diff,\n        theta_p,\n        sigma_xx,\n        sigma_yy,\n        tau_xy,\n    )\n</code></pre>"},{"location":"user/","title":"User Documentation","text":"<p>This area is organized by tasks, not by module internals.</p>"},{"location":"user/#workflow-chooser","title":"Workflow Chooser","text":"<ul> <li>Start from raw camera <code>.raw</code> frames:</li> <li>demosaic-raw workflow</li> <li>then image-to-stress workflow</li> <li>Start from an existing image stack (<code>.tiff</code>/<code>.npy</code>):</li> <li>image-to-stress workflow</li> <li>Start from an existing stress map (<code>[H, W, 3]</code>):</li> <li>stress-to-image workflow</li> <li>Need material/optics calibration first:</li> <li>calibration workflow</li> </ul>"},{"location":"user/#core-pages","title":"Core Pages","text":"<ul> <li>Installation</li> <li>Quickstart</li> <li>Configuration Reference</li> <li>Python API Workflow</li> <li>Troubleshooting</li> </ul>"},{"location":"user/#data-shape-conventions","title":"Data Shape Conventions","text":"<ul> <li>Stress map: <code>[H, W, 3]</code> in order <code>[sigma_xx, sigma_yy, sigma_xy]</code> unless you set a legacy stress order.</li> <li>Polarimetric stack: <code>[H, W, n_wavelengths, 4]</code> where the last axis is analyzer angles <code>[0, 45, 90, 135]</code>.</li> </ul>"},{"location":"user/configuration/","title":"Configuration Reference","text":"<p>This is the canonical reference for CLI JSON5 parameters.</p>"},{"location":"user/configuration/#conventions","title":"Conventions","text":"<ul> <li>Wavelengths accept meters or nanometers:</li> <li>values <code>&gt; 1e-6</code> are interpreted as nanometers and converted to meters</li> <li><code>S_i_hat</code> can have length 2 or 3:</li> <li><code>[S1_hat, S2_hat]</code> or <code>[S1_hat, S2_hat, S3_hat]</code></li> <li>Stress map default order is <code>[sigma_xx, sigma_yy, sigma_xy]</code></li> </ul>"},{"location":"user/configuration/#parameter-precedence","title":"Parameter Precedence","text":""},{"location":"user/configuration/#image-to-stress","title":"image-to-stress","text":"<ul> <li>Input source: either <code>folderName</code> or <code>input_filename</code> is required</li> <li>If <code>calibration_file</code> is set:</li> <li>missing <code>C</code>, <code>S_i_hat</code>, <code>wavelengths</code> are filled from the profile</li> <li>blank correction is applied</li> <li>For output path precedence:</li> <li>if <code>output_filename</code> exists in JSON, it takes precedence over CLI <code>--output</code></li> </ul>"},{"location":"user/configuration/#stress-to-image","title":"stress-to-image","text":"<ul> <li>Optional <code>p_filename</code> loads fallback parameters from a second JSON5 file</li> <li>Precedence order:</li> <li>explicit keys in current params</li> <li>fallback keys from <code>p_filename</code></li> <li>calibration profile values (<code>C</code>, <code>S_i_hat</code>, <code>wavelengths</code>) if <code>calibration_file</code> is set</li> </ul>"},{"location":"user/configuration/#image-to-stress-keys","title":"image-to-stress Keys","text":"<p>Required (directly or via calibration):</p> <ul> <li><code>thickness</code></li> <li><code>wavelengths</code></li> <li><code>C</code></li> <li><code>S_i_hat</code></li> <li>plus one input source: <code>folderName</code> or <code>input_filename</code></li> </ul> <p>Common optional keys:</p> <ul> <li><code>output_filename</code></li> <li><code>crop</code>: <code>[x1, x2, y1, y2]</code></li> <li><code>binning</code></li> <li><code>debug</code></li> </ul> <p>Seeding keys:</p> <ul> <li><code>seeding.n_max</code></li> <li><code>seeding.sigma_max</code></li> </ul> <p>Disorder Correction keys:</p> <p>Optional block <code>correction</code>:</p> <ul> <li><code>correction.enabled</code>: boolean (default <code>false</code>)</li> <li><code>correction.order_param</code>: float, [0, 1] (order parameter |m|)</li> <li><code>correction.N</code>: float (number of grain encounters)</li> <li><code>correction.d</code>: float (particle diameter, used to estimate N if N is missing)</li> </ul> <p>Optimisation keys:</p> <ul> <li><code>knot_spacing</code></li> <li><code>spline_degree</code></li> <li><code>boundary_mask_file</code></li> <li><code>boundary_values_files</code></li> <li><code>boundary_weight</code></li> <li><code>regularisation_weight</code> (alias <code>regularization_weight</code>)</li> <li><code>regularisation_order</code></li> <li><code>external_potential_file</code></li> <li><code>external_potential_gradient</code> (<code>[dVdx, dVdy]</code>)</li> <li><code>max_iterations</code></li> <li><code>tolerance</code></li> <li><code>verbose</code></li> <li><code>debug</code></li> </ul> <p>Not supported:</p> <ul> <li><code>solver</code></li> <li><code>global_solver</code></li> <li><code>global_mean_stress</code></li> </ul>"},{"location":"user/configuration/#stress-to-image-keys","title":"stress-to-image Keys","text":"<p>Required:</p> <ul> <li><code>stress_filename</code> (legacy alias: <code>s_filename</code>)</li> <li><code>thickness</code> (legacy alias: <code>t</code>)</li> <li><code>wavelengths</code> (legacy alias: <code>lambda_light</code>)</li> <li><code>C</code></li> </ul> <p>Optional:</p> <ul> <li><code>S_i_hat</code></li> <li><code>calibration_file</code></li> <li><code>stress_order</code>: <code>xx_yy_xy</code> (default) or <code>xy_yy_xx</code> (legacy)</li> <li><code>scattering</code></li> <li><code>output_filename</code></li> <li><code>p_filename</code> (fallback param file)</li> </ul>"},{"location":"user/configuration/#demosaic-raw-cli-flags","title":"demosaic-raw CLI Flags","text":"<ul> <li>positional: <code>input_file</code></li> <li><code>--width</code> (default <code>4096</code>)</li> <li><code>--height</code> (default <code>3000</code>)</li> <li><code>--dtype</code> (<code>uint8</code> or <code>uint16</code>)</li> <li><code>--output-prefix</code></li> <li><code>--format</code> (<code>tiff</code> or <code>png</code>)</li> <li><code>--all</code> (recursive processing)</li> <li><code>--mode</code> (<code>auto</code>, <code>single</code>, <code>average</code>, <code>series</code>)</li> <li><code>--average-method</code> (<code>mean</code> or <code>median</code>)</li> <li><code>--start</code> (frame start index, inclusive)</li> <li><code>--stop</code> (frame stop index, exclusive)</li> <li><code>--step</code> (frame stride, default <code>1</code>)</li> </ul> <p>Notes:</p> <ul> <li><code>--mode auto</code> chooses:</li> <li><code>single</code> for a <code>.raw</code> input file</li> <li><code>average</code> for a recording directory</li> <li>Recording directory mode expects <code>0000000/frame*.raw</code>.</li> <li>Metadata is auto-loaded from <code>recordingMetadata.json</code> when available.</li> </ul>"},{"location":"user/configuration/#calibrate-photoelastimetry-keys","title":"calibrate-photoelastimetry Keys","text":"<p>Required:</p> <ul> <li><code>method</code>: <code>brazilian_disk</code> or <code>coupon_test</code></li> <li><code>wavelengths</code></li> <li><code>thickness</code></li> <li><code>geometry</code> (method-specific)</li> <li><code>load_steps</code></li> </ul> <p>Method-specific required geometry:</p> <ul> <li><code>brazilian_disk</code>: <code>radius_m</code>, <code>center_px</code>, <code>pixels_per_meter</code></li> <li><code>coupon_test</code>: <code>gauge_roi_px</code>, <code>coupon_width_m</code></li> </ul> <p>Common optional keys:</p> <ul> <li><code>dark_frame_file</code> + <code>blank_frame_file</code> (both or neither)</li> <li><code>fit.max_points</code>, <code>fit.seed</code>, <code>fit.loss</code>, <code>fit.f_scale</code>, <code>fit.max_nfev</code></li> <li><code>fit.initial_C</code>, <code>fit.initial_S_i_hat</code></li> <li><code>fit.s3_identifiability_threshold</code>, <code>fit.prior_weight</code>, <code>fit.c_relative_bounds</code></li> <li><code>output_profile</code>, <code>output_report</code>, <code>output_diagnostics</code></li> </ul> <p>Load step input notes:</p> <ul> <li>Each <code>load_steps[i].image_file</code> may be either:</li> <li>a demosaiced stack (<code>[H, W, n_wavelengths, 4]</code>), or</li> <li>a raw frame (<code>.raw</code>) with nearby <code>recordingMetadata.json</code></li> <li>Raw calibration inputs are demosaiced internally to <code>[H, W, 3, 4]</code> using channels <code>R, G1, B</code>.</li> </ul>"},{"location":"user/configuration/#calibrate-photoelastimetry-cli-flags","title":"calibrate-photoelastimetry CLI Flags","text":"<ul> <li>positional: <code>json_filename</code></li> <li><code>--interactive</code> (launch click-based geometry wizard)</li> <li><code>--save-config &lt;path&gt;</code> (write updated config after interactive geometry selection)</li> </ul>"},{"location":"user/installation/","title":"Installation","text":""},{"location":"user/installation/#requirements","title":"Requirements","text":"<ul> <li>Python <code>&gt;=3.9</code></li> <li><code>pip</code></li> </ul>"},{"location":"user/installation/#install-from-pypi","title":"Install From PyPI","text":"<pre><code>pip install photoelastimetry\n</code></pre>"},{"location":"user/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>image-to-stress --help\nstress-to-image --help\ndemosaic-raw --help\ncalibrate-photoelastimetry --help\n</code></pre>"},{"location":"user/installation/#install-from-source-for-local-edits","title":"Install From Source (for local edits)","text":"<pre><code>git clone https://github.com/benjym/photoelastimetry.git\ncd photoelastimetry\npip install -e .\n</code></pre> <p>For contributor setup (tests, docs, style tools), use Developer Setup.</p>"},{"location":"user/python-api/","title":"Python API Workflow","text":"<p>Use Python when you want scripted pipelines or notebook workflows.</p>"},{"location":"user/python-api/#invert-images-to-stress","title":"Invert Images to Stress","text":"<pre><code>import json5\nfrom photoelastimetry.main import image_to_stress\n\nwith open(\"params.json5\", \"r\") as f:\n    params = json5.load(f)\n\nstress = image_to_stress(params)\nprint(stress.shape)  # [H, W, 3]\n</code></pre>"},{"location":"user/python-api/#forward-simulate-images-from-stress","title":"Forward-Simulate Images from Stress","text":"<pre><code>import json5\nfrom photoelastimetry.main import stress_to_image\n\nwith open(\"forward.json5\", \"r\") as f:\n    params = json5.load(f)\n\nsynthetic = stress_to_image(params)\nprint(synthetic.shape)  # [H, W, n_wavelengths, 4]\n</code></pre>"},{"location":"user/python-api/#run-calibration-in-python","title":"Run Calibration in Python","text":"<pre><code>import json5\nfrom photoelastimetry.calibrate import run_calibration\n\nwith open(\"calibration.json5\", \"r\") as f:\n    config = json5.load(f)\n\nresult = run_calibration(config)\nprint(result[\"profile_file\"])\n</code></pre>"},{"location":"user/python-api/#direct-mean-stress-recovery-advanced","title":"Direct Mean-Stress Recovery (advanced)","text":"<pre><code>import numpy as np\nfrom photoelastimetry.optimise import stress_to_principal_invariants, recover_mean_stress\n\ninitial_stress = np.load(\"seeded_stress.npy\")  # [H, W, 3]\ndelta_sigma, theta = stress_to_principal_invariants(initial_stress)\n\nwrapper, coeffs = recover_mean_stress(\n    delta_sigma,\n    theta,\n    knot_spacing=8,\n    max_iterations=200,\n    tolerance=1e-8,\n    verbose=True,\n)\n\nsigma_xx, sigma_yy, sigma_xy = wrapper.get_stress_fields(coeffs)\n</code></pre> <p>For parameter details and key aliases, use the canonical Configuration Reference.</p>"},{"location":"user/quickstart/","title":"Quickstart","text":"<p>This quickstart runs a complete forward+inverse cycle using local synthetic data.</p>"},{"location":"user/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Installed package (<code>pip install photoelastimetry</code>)</li> <li>Shell with <code>python</code> and CLI scripts on <code>PATH</code></li> </ul>"},{"location":"user/quickstart/#1-create-a-working-directory","title":"1. Create a Working Directory","text":"<pre><code>mkdir -p quickstart\ncd quickstart\n</code></pre>"},{"location":"user/quickstart/#2-create-a-synthetic-stress-field","title":"2. Create a Synthetic Stress Field","text":"<pre><code>python - &lt;&lt;'PY'\nimport numpy as np\nh, w = 96, 96\ny, x = np.indices((h, w), dtype=float)\ns_xx = 2.0e6 + 1.0e5 * (x / w)\ns_yy = 1.5e6 + 8.0e4 * (y / h)\ns_xy = 2.5e4 * np.sin(2*np.pi*x/w) * np.sin(2*np.pi*y/h)\nstress = np.stack([s_xx, s_yy, s_xy], axis=-1)\nnp.save(\"stress.npy\", stress)\nPY\n</code></pre>"},{"location":"user/quickstart/#3-generate-synthetic-polarimetric-images","title":"3. Generate Synthetic Polarimetric Images","text":"<p>Create <code>forward.json5</code>:</p> <pre><code>{\n  stress_filename: \"stress.npy\",\n  thickness: 0.01,\n  wavelengths: [650, 550, 450],\n  C: [3e-9, 3e-9, 3e-9],\n  S_i_hat: [1.0, 0.0, 0.0],\n  output_filename: \"synthetic_stack.tiff\"\n}\n</code></pre> <p>Run:</p> <pre><code>stress-to-image forward.json5\n</code></pre> <p>Expected output:</p> <ul> <li><code>synthetic_stack.tiff</code> (<code>[H, W, 3, 4]</code>)</li> </ul>"},{"location":"user/quickstart/#4-invert-images-back-to-stress","title":"4. Invert Images Back to Stress","text":"<p>Create <code>inverse.json5</code>:</p> <pre><code>{\n  input_filename: \"synthetic_stack.tiff\",\n  thickness: 0.01,\n  wavelengths: [650, 550, 450],\n  C: [3e-9, 3e-9, 3e-9],\n  S_i_hat: [1.0, 0.0, 0.0],\n  knot_spacing: 8,\n  max_iterations: 120,\n  debug: false,\n  output_filename: \"recovered_stress.tiff\"\n}\n</code></pre> <p>Run:</p> <pre><code>image-to-stress inverse.json5\n</code></pre> <p>Expected output:</p> <ul> <li><code>recovered_stress.tiff</code> (<code>[H, W, 3]</code>)</li> </ul>"},{"location":"user/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Use the full image-to-stress workflow</li> <li>Learn all accepted keys in Configuration Reference</li> </ul>"},{"location":"user/troubleshooting/","title":"Troubleshooting","text":""},{"location":"user/troubleshooting/#image-to-stress","title":"image-to-stress","text":""},{"location":"user/troubleshooting/#error-missing-c-thickness-wavelengths-or-s_i_hat","title":"Error: missing <code>C</code>, <code>thickness</code>, <code>wavelengths</code>, or <code>S_i_hat</code>","text":"<ul> <li>Provide keys directly in JSON5, or provide <code>calibration_file</code> that contains them.</li> </ul>"},{"location":"user/troubleshooting/#error-boundary-file-shape-mismatch","title":"Error: boundary file shape mismatch","text":"<ul> <li>Boundary mask/value files must match the loaded image size exactly (<code>H x W</code>).</li> </ul>"},{"location":"user/troubleshooting/#error-use-either-external_potential_file-or-external_potential_gradient-not-both","title":"Error: <code>Use either external_potential_file or external_potential_gradient, not both</code>","text":"<ul> <li>Keep only one potential input mechanism.</li> </ul>"},{"location":"user/troubleshooting/#error-deprecated-solver-configuration-keys","title":"Error: deprecated solver configuration keys","text":"<ul> <li>Remove <code>solver</code>, <code>global_solver</code>, and <code>global_mean_stress</code> keys.</li> </ul>"},{"location":"user/troubleshooting/#stress-values-seem-too-low-underestimated","title":"Stress values seem too low (underestimated)","text":"<ul> <li>In disordered granular systems with fixed thickness, vector cancellation can reduce the measured retardation.</li> <li>Enable the disorder correction by adding a <code>correction</code> block to your JSON config:   <pre><code>\"correction\": {\n  \"enabled\": true,\n  \"order_param\": 0.5, // |m|: 0.0 (random) to 1.0 (aligned)\n  \"N\": 10.0 // approx 1.5 * nu * H / d\n}\n</code></pre></li> <li>Adjust <code>order_param</code> and <code>N</code> based on particle properties and expected transmission behavior.</li> </ul>"},{"location":"user/troubleshooting/#stress-to-image","title":"stress-to-image","text":""},{"location":"user/troubleshooting/#error-missing-stress-map-path","title":"Error: missing stress map path","text":"<ul> <li>Use <code>stress_filename</code> (or legacy <code>s_filename</code>).</li> </ul>"},{"location":"user/troubleshooting/#error-c-length-mismatch","title":"Error: <code>C</code> length mismatch","text":"<ul> <li><code>C</code> must be scalar or same length as wavelength count.</li> </ul>"},{"location":"user/troubleshooting/#error-unsupported-output-extension","title":"Error: unsupported output extension","text":"<ul> <li>Use <code>.tiff/.tif/.npy/.raw</code> for stacks or <code>.png/.jpg/.jpeg</code> for plots.</li> </ul>"},{"location":"user/troubleshooting/#demosaic-raw","title":"demosaic-raw","text":""},{"location":"user/troubleshooting/#file-size-mismatch","title":"File size mismatch","text":"<ul> <li>Verify width, height, dtype, and raw packing assumptions.</li> <li>If available, prefer <code>recordingMetadata.json</code> so pixel format and dimensions are read from capture metadata.</li> </ul>"},{"location":"user/troubleshooting/#unsupported-pixelformat","title":"Unsupported <code>pixelFormat</code>","text":"<ul> <li>Use supported Bayer PFNC codes, or provide <code>--dtype</code> explicitly for manual decoding.</li> </ul>"},{"location":"user/troubleshooting/#modeinput-mismatch","title":"Mode/input mismatch","text":"<ul> <li><code>Mode 'single' requires a .raw file input, not a directory</code>:</li> <li>switch to <code>--mode average</code> or <code>--mode series</code> for recording folders.</li> <li><code>Mode 'average' requires a directory input</code>:</li> <li>pass a recording directory containing <code>0000000/frame*.raw</code>.</li> </ul>"},{"location":"user/troubleshooting/#frame-range-selects-no-files","title":"Frame range selects no files","text":"<ul> <li>If you see <code>No .raw files selected after applying frame range...</code>, loosen <code>--start/--stop/--step</code>.</li> </ul>"},{"location":"user/troubleshooting/#calibration","title":"calibration","text":""},{"location":"user/troubleshooting/#error-not-enough-load-steps","title":"Error: not enough load steps","text":"<ul> <li>Need at least 4 total, with at least one near-zero load and three non-zero loads.</li> </ul>"},{"location":"user/troubleshooting/#error-image-stack-shape-mismatch","title":"Error: image stack shape mismatch","text":"<ul> <li>Every calibration frame (all load steps, dark, blank) must have identical shape <code>[H, W, n_wavelengths, 4]</code>.</li> <li>If using raw load-step frames, they are first demosaiced to <code>[H, W, 3, 4]</code>; all steps must match after this conversion.</li> </ul>"},{"location":"user/troubleshooting/#error-incomplete-darkblank-settings","title":"Error: incomplete dark/blank settings","text":"<ul> <li>Provide both <code>dark_frame_file</code> and <code>blank_frame_file</code>, or neither.</li> </ul>"},{"location":"user/troubleshooting/#raw-calibration-input-errors","title":"Raw calibration input errors","text":"<ul> <li>If a raw <code>image_file</code> fails with missing metadata, add/verify adjacent <code>recordingMetadata.json</code>.</li> </ul>"},{"location":"user/troubleshooting/#interactive-geometry-does-not-open","title":"Interactive geometry does not open","text":"<ul> <li>Ensure a GUI backend is available for matplotlib.</li> <li>In headless environments, set geometry manually in JSON instead of <code>--interactive</code>.</li> </ul>"},{"location":"user/troubleshooting/#fit-quality-is-poor-for-beginners","title":"Fit quality is poor for beginners","text":"<ul> <li>Open the generated <code>*_fit.png</code> diagnostics plot and inspect residual maps inside the ROI.</li> <li>If residuals are large or structured, re-run with <code>--interactive</code> and re-pick geometry.</li> </ul>"},{"location":"user/troubleshooting/#general-debug-checklist","title":"General Debug Checklist","text":"<ul> <li>Confirm all paths are relative to your current working directory (or use absolute paths).</li> <li>Verify data shape conventions before running the CLI.</li> <li>Run commands with <code>--help</code> to confirm flags and expected input format.</li> </ul>"},{"location":"user/workflows/calibration/","title":"Workflow: calibrate-photoelastimetry","text":"<p>Fit calibration profile values (<code>C</code>, <code>S_i_hat</code>, blank correction) from known-load image data.</p>"},{"location":"user/workflows/calibration/#prerequisites","title":"Prerequisites","text":"<ul> <li>Calibration input for each load step can be either:</li> <li>a stack with shape <code>[H, W, n_wavelengths, 4]</code> (<code>.npy/.tiff/.tif</code>), or</li> <li>a single raw frame (<code>.raw</code>) plus nearby <code>recordingMetadata.json</code></li> <li>For raw-frame input:</li> <li>metadata is auto-loaded from <code>recordingMetadata.json</code></li> <li>frame is demosaiced internally to <code>[H, W, 3, 4]</code> (RGB = <code>R, G1, B</code>)</li> <li>At least 4 load steps total:</li> <li>at least 1 no-load step (<code>load ~= 0</code>)</li> <li>at least 3 non-zero load steps</li> <li>Method-specific geometry:</li> <li><code>brazilian_disk</code>: <code>radius_m</code>, <code>center_px</code>, <code>pixels_per_meter</code></li> <li><code>coupon_test</code>: <code>gauge_roi_px</code>, <code>coupon_width_m</code></li> </ul>"},{"location":"user/workflows/calibration/#example-config-brazilian-disk","title":"Example Config (Brazilian disk)","text":"<pre><code>{\n  method: \"brazilian_disk\",\n  wavelengths: [650, 550, 450],\n  thickness: 0.01,\n  geometry: {\n    radius_m: 0.01,\n    center_px: [256, 256],\n    pixels_per_meter: 20000,\n    edge_margin_fraction: 0.9,\n    contact_exclusion_fraction: 0.12\n  },\n  load_steps: [\n    {load: 0.0, image_file: \"calib/load_000.npy\"},\n    {load: 150.0, image_file: \"calib/load_150.npy\"},\n    {load: 300.0, image_file: \"calib/load_300.npy\"},\n    {load: 450.0, image_file: \"calib/load_450.npy\"}\n  ],\n  dark_frame_file: \"calib/dark.npy\",\n  blank_frame_file: \"calib/blank.npy\",\n  output_profile: \"calib/profile.json5\",\n  output_report: \"calib/report.md\",\n  output_diagnostics: \"calib/diagnostics.npz\"\n}\n</code></pre>"},{"location":"user/workflows/calibration/#command","title":"Command","text":"<pre><code>calibrate-photoelastimetry calibration.json5\n</code></pre> <p>Interactive geometry setup:</p> <pre><code>calibrate-photoelastimetry calibration.json5 --interactive --save-config calib/calibration_updated.json\n</code></pre> <p>In interactive mode: - <code>brazilian_disk</code>:   - left-click multiple points on the disk circumference (at least 3)   - a fitted circle overlay updates live as you add points   - ROI overlay and <code>roi_pixels</code> count update live   - right-click to undo the last point   - click <code>Done</code> when the overlay circle matches (or <code>Reset</code> to start over)   - <code>Done</code> is blocked if ROI would be empty for the current circle - <code>coupon_test</code>: click top-left, then bottom-right corners of the gauge ROI</p>"},{"location":"user/workflows/calibration/#expected-outputs","title":"Expected Outputs","text":"<ul> <li>Calibration profile JSON5 (<code>output_profile</code>)</li> <li>Markdown report (<code>output_report</code>)</li> <li>Diagnostics archive (<code>output_diagnostics</code>)</li> <li>Diagnostics figure PNG (<code>&lt;output_report stem&gt;_fit.png</code>)</li> </ul>"},{"location":"user/workflows/calibration/#use-the-profile-in-inversion","title":"Use the Profile in Inversion","text":"<pre><code>{\n  input_filename: \"experiment_stack.tiff\",\n  thickness: 0.01,\n  calibration_file: \"calib/profile.json5\",\n  output_filename: \"recovered_stress.tiff\"\n}\n</code></pre> <p><code>image-to-stress</code> fills missing <code>C</code>, <code>S_i_hat</code>, and <code>wavelengths</code> from the profile and applies blank correction automatically.</p>"},{"location":"user/workflows/calibration/#common-failure-modes","title":"Common Failure Modes","text":"<ul> <li><code>Calibration requires at least 4 load_steps</code>:</li> <li>add enough load steps</li> <li><code>at least one no-load</code> / <code>at least three non-zero</code> errors:</li> <li>rebalance load list</li> <li><code>Provide both dark_frame_file and blank_frame_file, or neither</code>:</li> <li>specify both or remove both</li> <li>Shape mismatch across calibration images:</li> <li>make all load-step images exactly the same post-load shape</li> <li>for raw inputs, ensure all captures share dimensions and pixel format</li> <li>Raw load step fails to decode:</li> <li>verify <code>recordingMetadata.json</code> exists near each raw frame and includes valid pixel metadata</li> </ul>"},{"location":"user/workflows/calibration/#beginner-checklist","title":"Beginner Checklist","text":"<ol> <li>Start with one no-load frame and at least three non-zero load frames.</li> <li>Verify all calibration inputs are the same capture geometry and dimensions.</li> <li>Run once with <code>--interactive</code> to set geometry visually.</li> <li>Check the diagnostics plot (<code>*_fit.png</code>):</li> <li>measured vs synthetic maps should look qualitatively similar</li> <li>residual maps should be small and structure-free in the ROI</li> <li>If residuals are structured:</li> <li>revisit geometry clicks</li> <li>verify load magnitudes and thickness units</li> <li>include dark/blank correction frames if available</li> </ol>"},{"location":"user/workflows/demosaic-raw/","title":"Workflow: demosaic-raw","text":"<p>Convert raw polarimetric Bayer files into channel-separated outputs.</p>"},{"location":"user/workflows/demosaic-raw/#prerequisites","title":"Prerequisites","text":"<ul> <li>Input can be:</li> <li>one raw frame file (for single-frame processing), or</li> <li>one recording directory containing <code>0000000/frame*.raw</code></li> <li>Metadata can come from:</li> <li><code>recordingMetadata.json</code> (auto-loaded when available), or</li> <li>explicit <code>--width</code>/<code>--height</code> and optional <code>--dtype</code></li> </ul>"},{"location":"user/workflows/demosaic-raw/#single-file-command","title":"Single File Command","text":"<pre><code>demosaic-raw frame.raw --width 2448 --height 2048 --dtype uint16 --format tiff\n</code></pre>"},{"location":"user/workflows/demosaic-raw/#recording-directory-commands","title":"Recording Directory Commands","text":"<pre><code># auto mode for a directory defaults to averaging\ndemosaic-raw capture_dir/ --format png\n\n# explicit average mode\ndemosaic-raw capture_dir/ --mode average --average-method median --format tiff\n\n# explicit time-series mode\ndemosaic-raw capture_dir/ --mode series --format png\n</code></pre>"},{"location":"user/workflows/demosaic-raw/#frame-range-selection","title":"Frame Range Selection","text":"<p>Use <code>--start</code> (inclusive), <code>--stop</code> (exclusive), and <code>--step</code>:</p> <pre><code>demosaic-raw capture_dir/ --mode average --start 10 --stop 50 --step 2\ndemosaic-raw capture_dir/ --mode series --start 0 --stop 20\n</code></pre> <p>For recursive <code>--all</code>, range selection is also applied to the discovered <code>.raw</code> list.</p>"},{"location":"user/workflows/demosaic-raw/#output-formats","title":"Output Formats","text":"<ul> <li><code>--format tiff</code>:</li> <li>writes <code>&lt;prefix&gt;_demosaiced.tiff</code></li> <li><code>--format png</code>:</li> <li>writes <code>&lt;prefix&gt;_0deg.png</code>, <code>&lt;prefix&gt;_45deg.png</code>, <code>&lt;prefix&gt;_90deg.png</code>, <code>&lt;prefix&gt;_135deg.png</code></li> </ul>"},{"location":"user/workflows/demosaic-raw/#output-location-defaults","title":"Output Location Defaults","text":"<ul> <li>Single file input:</li> <li>output prefix defaults to input filename stem</li> <li>Recording directory with <code>--mode average</code> (or <code>--mode auto</code>):</li> <li>outputs under <code>&lt;recording_dir&gt;/average/</code></li> <li>Recording directory with <code>--mode series</code>:</li> <li>outputs under <code>&lt;recording_dir&gt;/series/</code></li> </ul>"},{"location":"user/workflows/demosaic-raw/#common-failure-modes","title":"Common Failure Modes","text":"<ul> <li><code>When using --all flag, input_file must be a directory</code>:</li> <li>pass a directory path with <code>--all</code></li> <li><code>Mode 'single' requires a .raw file input, not a directory</code>:</li> <li>use <code>--mode average</code> or <code>--mode series</code> for recording directories</li> <li><code>Mode 'average' requires a directory input</code>:</li> <li>provide a recording directory for averaging</li> <li><code>No .raw files selected after applying frame range...</code>:</li> <li>adjust <code>--start/--stop/--step</code> so at least one frame is selected</li> <li>File size mismatch errors:</li> <li>verify metadata and/or <code>--width</code>, <code>--height</code>, <code>--dtype</code> match capture settings</li> <li>Unsupported <code>pixelFormat</code>:</li> <li>use one of the supported Bayer 8/10/12 PFNC codes documented by the CLI and IO module</li> </ul>"},{"location":"user/workflows/image-to-stress/","title":"Workflow: image-to-stress","text":"<p>Convert polarimetric image data into a stress map.</p>"},{"location":"user/workflows/image-to-stress/#prerequisites","title":"Prerequisites","text":"<ul> <li>Input data as either:</li> <li>raw capture folder (<code>folderName</code>) containing <code>recordingMetadata.json</code> and <code>0000000/frame*.raw</code>, or</li> <li>prepared image stack file (<code>input_filename</code>) with shape <code>[H, W, n_wavelengths, 4]</code></li> <li>Material/optics parameters provided directly (<code>C</code>, <code>thickness</code>, <code>wavelengths</code>, <code>S_i_hat</code>) or through <code>calibration_file</code></li> </ul>"},{"location":"user/workflows/image-to-stress/#minimal-config-input-stack","title":"Minimal Config (input stack)","text":"<pre><code>{\n  input_filename: \"synthetic_stack.tiff\",\n  thickness: 0.01,\n  wavelengths: [650, 550, 450],\n  C: [3e-9, 3e-9, 3e-9],\n  S_i_hat: [1.0, 0.0, 0.0],\n  output_filename: \"recovered_stress.tiff\"\n}\n</code></pre>"},{"location":"user/workflows/image-to-stress/#command","title":"Command","text":"<pre><code>image-to-stress params.json5\n</code></pre> <p>Optional CLI output override:</p> <pre><code>image-to-stress params.json5 --output recovered_stress.tiff\n</code></pre>"},{"location":"user/workflows/image-to-stress/#expected-outputs","title":"Expected Outputs","text":"<ul> <li>Stress map file (<code>[H, W, 3]</code>) when <code>output_filename</code> or <code>--output</code> is set</li> <li>Optional debug files when <code>debug: true</code></li> </ul>"},{"location":"user/workflows/image-to-stress/#commonly-used-controls","title":"Commonly Used Controls","text":"<ul> <li><code>crop</code>: <code>[x1, x2, y1, y2]</code></li> <li><code>binning</code>: integer spatial binning factor</li> <li>Seeding controls:</li> <li><code>seeding.n_max</code></li> <li><code>seeding.sigma_max</code></li> <li>Correction for random stress orientation:</li> <li><code>correction</code> block with <code>enabled: true</code>, <code>order_param</code>, and <code>N</code> or <code>d</code></li> <li>Optimisation controls:</li> <li><code>knot_spacing</code>, <code>spline_degree</code></li> <li><code>max_iterations</code>, <code>tolerance</code></li> <li><code>boundary_mask_file</code>, <code>boundary_values_files</code>, <code>boundary_weight</code></li> <li><code>regularisation_weight</code> (or alias <code>regularization_weight</code>)</li> <li><code>external_potential_file</code> or <code>external_potential_gradient</code></li> </ul> <p>All keys are documented in Configuration Reference.</p>"},{"location":"user/workflows/image-to-stress/#common-failure-modes","title":"Common Failure Modes","text":"<ul> <li><code>Missing stress-optic coefficient 'C'</code>:</li> <li>add <code>C</code> or provide <code>calibration_file</code> with <code>C</code></li> <li><code>Missing sample thickness 'thickness'</code>:</li> <li>set <code>thickness</code></li> <li><code>Either 'folderName' or 'input_filename' must be specified</code>:</li> <li>set one input source</li> <li><code>Use either external_potential_file or external_potential_gradient, not both</code>:</li> <li>keep only one of the two keys</li> <li><code>Boundary mask shape must be ...</code>:</li> <li>ensure boundary files match image dimensions</li> <li><code>`solver</code>is no longer supported`:</li> <li>remove deprecated solver selection keys</li> </ul>"},{"location":"user/workflows/stress-to-image/","title":"Workflow: stress-to-image","text":"<p>Generate synthetic polarimetric image data from a stress map.</p>"},{"location":"user/workflows/stress-to-image/#prerequisites","title":"Prerequisites","text":"<ul> <li>Stress map file with shape <code>[H, W, 3]</code></li> <li>Material/optics parameters:</li> <li><code>thickness</code></li> <li><code>wavelengths</code> (or legacy <code>lambda_light</code>)</li> <li><code>C</code> (scalar or per-wavelength)</li> <li>optional <code>S_i_hat</code></li> </ul>"},{"location":"user/workflows/stress-to-image/#minimal-config","title":"Minimal Config","text":"<pre><code>{\n  stress_filename: \"stress.npy\",\n  thickness: 0.01,\n  wavelengths: [650, 550, 450],\n  C: [3e-9, 3e-9, 3e-9],\n  S_i_hat: [1.0, 0.0, 0.0],\n  output_filename: \"synthetic_stack.tiff\"\n}\n</code></pre>"},{"location":"user/workflows/stress-to-image/#command","title":"Command","text":"<pre><code>stress-to-image params.json5\n</code></pre>"},{"location":"user/workflows/stress-to-image/#output-modes","title":"Output Modes","text":"<ul> <li>Stack output (<code>.tiff/.tif/.npy/.raw</code>): full <code>[H, W, n_wavelengths, 4]</code> synthetic data</li> <li>Plot output (<code>.png/.jpg/.jpeg</code>): 2-panel fringe/isoclinic visual</li> </ul> <p>Example plot output config:</p> <pre><code>{\n  stress_filename: \"stress.npy\",\n  thickness: 0.01,\n  wavelengths: [550],\n  C: 3e-9,\n  output_filename: \"fringe.png\"\n}\n</code></pre>"},{"location":"user/workflows/stress-to-image/#common-failure-modes","title":"Common Failure Modes","text":"<ul> <li><code>Missing stress map path</code>:</li> <li>provide <code>stress_filename</code> (or legacy <code>s_filename</code>)</li> <li><code>Missing wavelengths</code>:</li> <li>provide <code>wavelengths</code> or legacy <code>lambda_light</code></li> <li><code>C must be scalar or length N</code>:</li> <li>align <code>C</code> length with wavelength count</li> <li><code>Unsupported output extension</code>:</li> <li>use one of the supported extensions above</li> <li><code>S_i_hat must have length 2 or 3</code>:</li> <li>pass <code>[S1_hat, S2_hat]</code> or <code>[S1_hat, S2_hat, S3_hat]</code></li> </ul>"}]}